"""
AI Node Analyzer Blender Add-on

This addon allows users to analyze selected nodes in Blender's node editors
(Geometry Nodes, Shader Nodes, Compositor Nodes) with AI assistance.
It also includes a backend server to enable communication with external applications.
"""
import bpy
import bmesh
import threading
import json
import requests
import socket
import time
import traceback
import io
from contextlib import redirect_stdout
from bpy.app.translations import pgettext_iface
from bpy.props import (
    StringProperty,
    EnumProperty,
    BoolProperty,
    FloatProperty,
    IntProperty,
    CollectionProperty,
    PointerProperty
)
from bpy.types import (
    Panel,
    Operator,
    AddonPreferences,
    PropertyGroup,
    Text
)
from mathutils import Vector
import os
import tempfile
import sys
from urllib.parse import urlparse

# åŠ¨æ€å¯¼å…¥åç«¯æœåŠ¡å™¨
server_manager = None

system_message_presets_cache = []
default_question_presets_cache = []
provider_configs_cache = {}

def get_output_detail_instruction(settings):
    try:
        lvl = getattr(settings, 'output_detail_level', 'medium')
        if lvl == 'simple':
            return getattr(settings, 'prompt_simple', '') or ''
        if lvl == 'medium':
            return getattr(settings, 'prompt_medium', '') or ''
        if lvl == 'detailed':
            return getattr(settings, 'prompt_detailed', '') or ''
        return ''
    except Exception:
        return ''

def clean_markdown(text):
    try:
        import re
        s = text
        s = s.replace('\r\n', '\n').replace('\r', '\n')
        s = re.sub(r'[ \t]+\n', '\n', s)          # è¡Œå°¾ç©ºç™½
        s = re.sub(r'\n{3,}', '\n\n', s)          # è¿‡å¤šç©ºè¡Œ
        s = re.sub(r'^[ \t]+', '', s, flags=re.MULTILINE)  # è¡Œé¦–ç©ºç™½
        s = re.sub(r'```+\s*', '```', s)          # å¤šä½™åå¼•å·
        s = re.sub(r'(#){2,}\s*', r'## ', s)      # å¤šçº§æ ‡é¢˜è§„èŒƒåŒ–ä¸ºäºŒçº§
        return s
    except Exception:
        return text

def get_text_items(self, context):
    try:
        import bpy
        items = []
        names = [t.name for t in bpy.data.texts]
        for n in names:
            items.append((n, n, n))
        if not items:
            items = [('AINodeAnalysisResult', 'AINodeAnalysisResult', 'AINodeAnalysisResult')]
        return items
    except Exception:
        return [('AINodeAnalysisResult', 'AINodeAnalysisResult', 'AINodeAnalysisResult')]

def get_identity_items(self, context):
    items = []
    for idx, it in enumerate(system_message_presets_cache):
        label = it.get('label', f'Preset {idx+1}')
        key = f"preset_{idx}"
        items.append((key, label, label))
    if not items:
        items = [('default', "é»˜è®¤åŠ©æ‰‹", "é»˜è®¤åŠ©æ‰‹")]
    return items

def get_provider_items(self, context):
    items = []
    if isinstance(provider_configs_cache, dict) and provider_configs_cache:
        for k in provider_configs_cache.keys():
            items.append((k, k.title(), k))
    if not items:
        items = [('DEEPSEEK', "DeepSeek", "DeepSeek"), ('OLLAMA', "Ollama", "Ollama")]
    return items

def _on_provider_update(self, context):
    """å½“AIæä¾›å•†æ›´æ”¹æ—¶ï¼Œæ›´æ–°æ¨¡å‹åˆ—è¡¨"""
    try:
        # æ›´æ–°å½“å‰æ¨¡å‹å­—æ®µ
        ain_settings = context.scene.ainode_analyzer_settings
        if ain_settings.ai_provider == 'DEEPSEEK':
            ain_settings.current_model = ain_settings.deepseek_model
            # æ›´æ–°available_modelsä¸ºå½“å‰DeepSeekæ¨¡å‹
            ain_settings.available_models = ain_settings.deepseek_model
        elif ain_settings.ai_provider == 'OLLAMA':
            ain_settings.current_model = ain_settings.ollama_model
            # æ›´æ–°available_modelsä¸ºå½“å‰Ollamaæ¨¡å‹
            ain_settings.available_models = ain_settings.ollama_model
        elif ain_settings.ai_provider == 'BIGMODEL':
            ain_settings.current_model = ain_settings.bigmodel_model
            # æ›´æ–°available_modelsä¸ºå½“å‰BigModelæ¨¡å‹
            ain_settings.available_models = ain_settings.bigmodel_model
        else:
            ain_settings.current_model = ain_settings.generic_model
            # æ›´æ–°available_modelsä¸ºå½“å‰Genericæ¨¡å‹
            ain_settings.available_models = ain_settings.generic_model

        # å¼ºåˆ¶åˆ·æ–°æ¨¡å‹åˆ—è¡¨
        if hasattr(bpy.context, 'window_manager'):
            # è§¦å‘ç•Œé¢æ›´æ–°
            for window in bpy.context.window_manager.windows:
                for area in window.screen.areas:
                    if area.type == 'NODE_EDITOR':
                        for region in area.regions:
                            if region.type == 'UI':
                                region.tag_redraw()
                                break
                        break
    except Exception as e:
        print(f"æ›´æ–°æä¾›å•†æ—¶å‡ºé”™: {e}")
        pass

def get_default_question_items(self, context):
    items = []
    for idx, it in enumerate(default_question_presets_cache):
        label = it.get('label', f'é—®é¢˜ {idx+1}')
        key = f"q_{idx}"
        items.append((key, label, label))
    if not items:
        items = [('none', "æ— é¢„è®¾", "æ— é¢„è®¾")]
    return items

def get_model_items(self, context):
    items = []
    try:
        # è·å–æ‰€æœ‰æœåŠ¡å•†çš„æ¨¡å‹åˆ—è¡¨
        all_models = set()  # ä½¿ç”¨é›†åˆé¿å…é‡å¤

        # æ·»åŠ DeepSeekæ¨¡å‹
        for model in deepseek_models_cache:
            all_models.add((model, model, f"DeepSeek: {model}"))

        # æ·»åŠ Ollamaæ¨¡å‹
        for model in ollama_models_cache:
            all_models.add((model, model, f"Ollama: {model}"))

        # æ·»åŠ BigModelæ¨¡å‹
        for model in bigmodel_models_cache:
            # æ ¹æ®æ¨¡å‹IDç¡®å®šåˆ†ç±»
            if model.startswith('glm-4.7'):
                category = "GLM-4.7"
            elif model.startswith('glm-4'):
                category = "GLM-4"
            elif model.startswith('glm-3'):
                category = "GLM-3"
            else:
                category = "BigModel"
            all_models.add((model, model, f"{category}: {model}"))

        # æ·»åŠ é€šç”¨æ¨¡å‹
        for model in generic_models_cache:
            all_models.add((model, model, f"é€šç”¨: {model}"))

        # å°†é›†åˆè½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ·»åŠ åˆ°items
        items.extend(list(all_models))

        # å¦‚æœæ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œæ·»åŠ å½“å‰è®¾ç½®çš„æ¨¡å‹
        if not items:
            current_model = ""
            if self.ai_provider == 'DEEPSEEK':
                current_model = self.deepseek_model
            elif self.ai_provider == 'OLLAMA':
                current_model = self.ollama_model
            elif self.ai_provider == 'BIGMODEL':
                current_model = self.bigmodel_model
            else:
                current_model = self.generic_model
            if current_model:
                items.append((current_model, current_model, current_model))
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œè¿”å›ç©ºåˆ—è¡¨
        print(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        pass

    if not items:
        items = [('æœªæ‰¾åˆ°æ¨¡å‹', "æœªæ‰¾åˆ°æ¨¡å‹", "æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹")]
    return items

def copy_to_clipboard(text):
    """å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿"""
    try:
        bpy.context.window_manager.clipboard = text
        return True
    except Exception as e:
        print(f"å¤åˆ¶åˆ°å‰ªè´´æ¿å¤±è´¥: {e}")
        return False

def get_response_detail_items(self, context):
    """è·å–å›ç­”ç²¾ç»†åº¦é€‰é¡¹ï¼Œæ‚¬æµ®æç¤ºæ˜¾ç¤ºå®é™…çš„promptå†…å®¹"""
    items = []

    # ç›´æ¥ä½¿ç”¨å½“å‰å®ä¾‹çš„å±æ€§å€¼ï¼Œè¿™äº›å€¼åœ¨åŠ è½½é…ç½®æ–‡ä»¶æ—¶å·²ç»è¢«æ›´æ–°
    simple_prompt = getattr(self, 'prompt_simple', 'è¯·ç®€è¦è¯´æ˜ï¼Œä¸éœ€è¦ä½¿ç”¨markdownæ ¼å¼ï¼Œç®€å•æè¿°å³å¯ã€‚')
    medium_prompt = getattr(self, 'prompt_medium', 'è¯·æŒ‰å¸¸è§„æ–¹å¼å›ç­”ï¼Œä½¿ç”¨é€‚å½“çš„markdownæ ¼å¼æ¥ç»„ç»‡å†…å®¹ã€‚')
    detailed_prompt = getattr(self, 'prompt_detailed', 'è¯·è¯¦ç»†è¯´æ˜ï¼Œä½¿ç”¨å›¾è¡¨ã€åˆ—è¡¨ã€ä»£ç å—ç­‰markdownæ ¼å¼æ¥æ¸…æ™°åœ°è¡¨è¾¾å†…å®¹ã€‚')

    items.append(('0', "ç®€çº¦", f"ç®€çº¦ - å®é™…æç¤º: {simple_prompt}"))
    items.append(('1', "é€‚ä¸­", f"é€‚ä¸­ - å®é™…æç¤º: {medium_prompt}"))
    items.append(('2', "è¯¦ç»†", f"è¯¦ç»† - å®é™…æç¤º: {detailed_prompt}"))

    return items

def _on_identity_update(self, context):
    try:
        idx = 0
        if self.identity_key.startswith("preset_"):
            idx = int(self.identity_key.split("_")[1])
        if 0 <= idx < len(system_message_presets_cache):
            val = system_message_presets_cache[idx].get('value', '')
            self.identity_text = val
            if val:
                self.system_prompt = val
    except Exception:
        pass

def _on_default_question_preset_update(self, context):
    try:
        idx = -1
        if self.default_question_preset.startswith("q_"):
            idx = int(self.default_question_preset.split("_")[1])
        if 0 <= idx < len(default_question_presets_cache):
            val = default_question_presets_cache[idx].get('value', '')
            if val:
                self.user_input = val
    except Exception:
        pass

def _on_model_change_update(self):
    """
    å½“æ¨¡å‹é€‰æ‹©æ›´æ”¹æ—¶æ›´æ–°å¯¹åº”çš„æ¨¡å‹å­—æ®µ
    """
    try:
        selected_model = self.available_models

        # æ£€æŸ¥æ‰€é€‰æ¨¡å‹æ˜¯å¦åœ¨å½“å‰æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨ä¸­
        if self.ai_provider == 'DEEPSEEK':
            if selected_model in deepseek_models_cache:
                # æ¨¡å‹å±äºå½“å‰æä¾›å•†
                self.deepseek_model = selected_model
            else:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å±äºå…¶ä»–æä¾›å•†ï¼Œå¦‚æœæ˜¯åˆ™æ›´æ–°æä¾›å•†
                if selected_model in ollama_models_cache:
                    self.ai_provider = 'OLLAMA'
                    self.ollama_model = selected_model
                elif selected_model in bigmodel_models_cache:
                    self.ai_provider = 'BIGMODEL'
                    self.bigmodel_model = selected_model
                elif selected_model in generic_models_cache:
                    # è®¾ç½®ä¸ºé€šç”¨æä¾›å•†
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…é…ç½®æ¥å†³å®šå¦‚ä½•å¤„ç†
                    self.generic_model = selected_model
        elif self.ai_provider == 'OLLAMA':
            if selected_model in ollama_models_cache:
                # æ¨¡å‹å±äºå½“å‰æä¾›å•†
                self.ollama_model = selected_model
            else:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å±äºå…¶ä»–æä¾›å•†
                if selected_model in deepseek_models_cache:
                    self.ai_provider = 'DEEPSEEK'
                    self.deepseek_model = selected_model
                elif selected_model in bigmodel_models_cache:
                    self.ai_provider = 'BIGMODEL'
                    self.bigmodel_model = selected_model
                elif selected_model in generic_models_cache:
                    # è®¾ç½®ä¸ºé€šç”¨æä¾›å•†
                    self.generic_model = selected_model
        elif self.ai_provider == 'BIGMODEL':
            if selected_model in bigmodel_models_cache:
                # æ¨¡å‹å±äºå½“å‰æä¾›å•†
                self.bigmodel_model = selected_model
            else:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å±äºå…¶ä»–æä¾›å•†
                if selected_model in deepseek_models_cache:
                    self.ai_provider = 'DEEPSEEK'
                    self.deepseek_model = selected_model
                elif selected_model in ollama_models_cache:
                    self.ai_provider = 'OLLAMA'
                    self.ollama_model = selected_model
                elif selected_model in generic_models_cache:
                    # è®¾ç½®ä¸ºé€šç”¨æä¾›å•†
                    self.generic_model = selected_model
        else:  # generic provider
            if selected_model in generic_models_cache:
                self.generic_model = selected_model
            else:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å±äºå…¶ä»–æä¾›å•†
                if selected_model in deepseek_models_cache:
                    self.ai_provider = 'DEEPSEEK'
                    self.deepseek_model = selected_model
                elif selected_model in ollama_models_cache:
                    self.ai_provider = 'OLLAMA'
                    self.ollama_model = selected_model
                elif selected_model in bigmodel_models_cache:
                    self.ai_provider = 'BIGMODEL'
                    self.bigmodel_model = selected_model

        # åŒæ—¶æ›´æ–°current_model
        self.current_model = selected_model
    except Exception as e:
        print(f"æ›´æ–°æ¨¡å‹æ—¶å‡ºé”™: {e}")

def get_auto_identity_for_node_type(tree_type):
    """
    æ ¹æ®èŠ‚ç‚¹ç±»å‹è·å–å¯¹åº”çš„èº«ä»½é¢„è®¾
    :param tree_type: èŠ‚ç‚¹æ ‘ç±»å‹ (å¦‚ 'GeometryNodeTree', 'ShaderNodeTree' ç­‰)
    :return: å¯¹åº”çš„èº«ä»½é¢„è®¾ç´¢å¼•ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    # å®šä¹‰èŠ‚ç‚¹ç±»å‹åˆ°èº«ä»½å…³é”®è¯çš„æ˜ å°„
    node_type_keywords = {
        'GeometryNodeTree': ['å‡ ä½•', 'geometry', 'Geometry'],
        'ShaderNodeTree': ['æè´¨', 'shader', 'Shader', 'è¡¨é¢', 'Surface'],
        'CompositorNodeTree': ['åˆæˆ', 'compositor', 'Compositor', 'Composite'],
        'TextureNodeTree': ['çº¹ç†', 'texture', 'Texture'],
        'WorldNodeTree': ['ç¯å¢ƒ', 'world', 'World']
    }

    keywords = node_type_keywords.get(tree_type, [])
    if not keywords:
        return None

    # åœ¨ç³»ç»Ÿæ¶ˆæ¯é¢„è®¾ä¸­æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„é¢„è®¾
    for idx, preset in enumerate(system_message_presets_cache):
        preset_value = preset.get('value', '').lower()
        preset_label = preset.get('label', '').lower()
        # æ£€æŸ¥é¢„è®¾å€¼æˆ–æ ‡ç­¾ä¸­æ˜¯å¦åŒ…å«å…³é”®è¯
        for keyword in keywords:
            if keyword.lower() in preset_value or keyword.lower() in preset_label:
                return idx

    return None

# æ¨¡å‹åˆ—è¡¨ç¼“å­˜
deepseek_models_cache = []
ollama_models_cache = []
bigmodel_models_cache = []
generic_models_cache = []


def _on_model_update(self, context):
    try:
        if self.ai_provider == 'DEEPSEEK':
            self.current_model = self.deepseek_model
        elif self.ai_provider == 'OLLAMA':
            self.current_model = self.ollama_model
        elif self.ai_provider == 'BIGMODEL':
            self.current_model = self.bigmodel_model
    except Exception:
        pass

def filter_node_description(text, level):
    try:
        data = json.loads(text)
    except Exception:
        if level == 'ULTRA_LITE':
            return "èŠ‚ç‚¹ç»“æ„å·²é‡‡é›†"
        elif level == 'LITE' or level == 'STANDARD':
            return text[:1000]
        else:
            return text
    if level == 'FULL':
        return text
    is_selected_shape = 'selected_nodes' in data or 'connections' in data
    def clean_node(node):
        node.pop('location', None)
        node.pop('width', None)
        node.pop('height', None)
        node.pop('color', None)
        node.pop('use_custom_color', None)
        node.pop('select', None)
        if level == 'ULTRA_LITE':
            minimal_name = node.get('name')
            minimal_type = node.get('type')
            node.clear()
            node['name'] = minimal_name
            node['type'] = minimal_type
            return
        if level == 'LITE':
            if isinstance(node.get('inputs'), list):
                for i in node['inputs']:
                    i.pop('identifier', None)
                node['inputs'] = [i for i in node['inputs'] if i.get('is_connected') or (i.get('default_value') is not None and i.get('default_value') != 'N/A')]
            if isinstance(node.get('outputs'), list):
                for o in node['outputs']:
                    o.pop('identifier', None)
        if node.get('group_content') and isinstance(node['group_content'].get('nodes'), list):
            for sub in node['group_content']['nodes']:
                clean_node(sub)
    nodes_array = data.get('selected_nodes') or data.get('nodes')
    if isinstance(nodes_array, list):
        for n in nodes_array:
            clean_node(n)
    if level in ('ULTRA_LITE', 'LITE'):
        for k in ('blender_version', 'addon_version', 'selected_nodes_count', 'node_tree_type'):
            data.pop(k, None)
    filtered_str = json.dumps(data, ensure_ascii=False, indent=2)
    return filtered_str

def initialize_backend():
    """åˆå§‹åŒ–åç«¯æœåŠ¡å™¨"""
    global server_manager
    try:
        # æ·»åŠ å½“å‰æ’ä»¶ç›®å½•åˆ°Pythonè·¯å¾„
        addon_dir = os.path.dirname(__file__)
        backend_dir = os.path.join(addon_dir, 'backend')

        if backend_dir not in sys.path:
            sys.path.append(backend_dir)

        # å¯¼å…¥åç«¯æœåŠ¡å™¨ - ä½¿ç”¨ç›¸å¯¹å¯¼å…¥
        from .backend import server
        server_manager = server.server_manager
        print("åç«¯æœåŠ¡å™¨æ¨¡å—åŠ è½½æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"æ— æ³•å¯¼å…¥åç«¯æœåŠ¡å™¨æ¨¡å—: {e}")
        import traceback
        traceback.print_exc()
        return False
    except Exception as e:
        print(f"åˆå§‹åŒ–åç«¯æœåŠ¡å™¨æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def send_to_backend(endpoint, data=None, method='GET'):
    """å‘åç«¯å‘é€è¯·æ±‚"""
    global server_manager
    if not server_manager or not server_manager.is_running:
        print("åç«¯æœåŠ¡å™¨æœªè¿è¡Œ")
        return None

    try:
        import requests

        url = f"http://127.0.0.1:{server_manager.port}{endpoint}"

        if method == 'POST':
            response = requests.post(url, json=data, timeout=5)
        else:
            response = requests.get(url, timeout=5)

        if response.status_code == 200:
            return response.json()
        else:
            print(f"è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"å‘é€è¯·æ±‚åˆ°åç«¯æ—¶å‡ºé”™: {e}")
        return None

def push_blender_content_to_server(context=None):
    """å°†Blenderä¸­çš„èŠ‚ç‚¹æ•°æ®æ¨é€åˆ°åç«¯æœåŠ¡å™¨ï¼ˆä¼˜å…ˆæ¨é€åŸå§‹æ•°æ®ï¼Œä¸è¿‡æ»¤ï¼‰"""
    global server_manager
    if not server_manager or not server_manager.is_running:
        print("åç«¯æœåŠ¡å™¨æœªè¿è¡Œ")
        return False

    try:
        # ä½¿ç”¨ä¼ å…¥çš„ä¸Šä¸‹æ–‡æˆ–å…¨å±€ä¸Šä¸‹æ–‡
        ctx = context if context else bpy.context

        # ä¼˜å…ˆè·å–00-åŸå§‹èŠ‚ç‚¹æ•°æ®æ–‡æœ¬å—çš„å†…å®¹ï¼ˆä¸è¿‡æ»¤ï¼‰
        import bpy
        content = ""
        if '00-åŸå§‹èŠ‚ç‚¹æ•°æ®' in bpy.data.texts:
            text_block = bpy.data.texts['00-åŸå§‹èŠ‚ç‚¹æ•°æ®']
            content = text_block.as_string()
        elif '04-èŠ‚ç‚¹æ•°æ®' in bpy.data.texts:
            # å…¼å®¹ï¼šå¦‚æœæ²¡æœ‰åŸå§‹æ•°æ®ï¼Œä½¿ç”¨è¿‡æ»¤åçš„æ•°æ®
            text_block = bpy.data.texts['04-èŠ‚ç‚¹æ•°æ®']
            content = text_block.as_string()
        elif 'AINodeRawNodeData' in bpy.data.texts:
            # å…¼å®¹æ—§çš„æ–‡æœ¬å—åç§°
            text_block = bpy.data.texts['AINodeRawNodeData']
            content = text_block.as_string()
        elif 'AINodeRefreshContent' in bpy.data.texts:
            text_block = bpy.data.texts['AINodeRefreshContent']
            content = text_block.as_string()
            # å¦‚æœæ˜¯å®Œæ•´æ¶ˆæ¯æ ¼å¼ï¼Œéœ€è¦æå–JSON
            if "èŠ‚ç‚¹ç»“æ„:" in content:
                json_start = content.find("{", content.find("èŠ‚ç‚¹ç»“æ„:"))
                if json_start != -1:
                    content = content[json_start:].strip()

        if not content:
            print("æ²¡æœ‰å¯æ¨é€çš„èŠ‚ç‚¹æ•°æ®")
            return False

        # Get metadata
        filename = bpy.path.basename(bpy.data.filepath) if bpy.data.filepath else "Untitled"
        version = bpy.app.version_string
        
        # Get node type
        node_type = "Node Tree"
        # Try to infer from content header or context
        # Simple heuristic: check context or default
        try:
            if hasattr(ctx, 'space_data') and hasattr(ctx.space_data, 'tree_type'):
                 node_type = ctx.space_data.tree_type
            else:
                # Fallback: check all areas using global context (safest for window iteration)
                wm = getattr(ctx, 'window_manager', bpy.context.window_manager)
                for win in wm.windows:
                    for area in win.screen.areas:
                        if area.type == 'NODE_EDITOR':
                            for space in area.spaces:
                                if space.type == 'NODE_EDITOR' and space.node_tree:
                                    node_type = space.tree_type
                                    break
        except Exception:
            pass
        
        # Beautify node type
        if 'Shader' in node_type: node_type = 'Shader Nodes'
        elif 'Geometry' in node_type: node_type = 'Geometry Nodes'
        elif 'Compositor' in node_type: node_type = 'Compositor Nodes'
        elif 'Texture' in node_type: node_type = 'Texture Nodes'

        # Calculate tokens
        tokens = len(content) // 4

        # Get timestamp safely
        timestamp = 'unknown'
        try:
            if hasattr(ctx, 'view_layer') and ctx.view_layer:
                timestamp = str(ctx.view_layer.name)
        except Exception:
            pass

        # å‘é€å†…å®¹åˆ°åç«¯
        success = send_to_backend('/api/blender-data', {
            "nodes": content,
            "type": "refresh_content",
            "timestamp": timestamp,
            "filename": filename,
            "version": version,
            "node_type": node_type,
            "tokens": tokens
        }, method='POST')

        if success:
            print("æˆåŠŸæ¨é€èŠ‚ç‚¹æ•°æ®åˆ°åç«¯æœåŠ¡å™¨")
            return True
        else:
            print("æ¨é€å†…å®¹åˆ°åç«¯æœåŠ¡å™¨å¤±è´¥")
            return False
    except Exception as e:
        print(f"æ¨é€å†…å®¹æ—¶å‡ºé”™: {e}")
        return False

# æ’ä»¶åŸºæœ¬ä¿¡æ¯
bl_info = {
    "name": "AI Node Analyzer",
    "author": "Assistant",
    "version": (1, 0, 0),
    "blender": (4, 2, 0),
    "location": "Node Editor > Sidebar > AI Node Analyzer",
    "description": "Analyze selected nodes with AI assistance",
    "category": "Node",
    "doc_url": "https://github.com/your-repo/ainode-analyzer",
}

def _save_ai_params_to_config_from_context(context):
    try:
        ain_settings = context.scene.ainode_analyzer_settings
    except Exception:
        if bpy.data.scenes:
            ain_settings = bpy.data.scenes[0].ainode_analyzer_settings
        else:
            return
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    existing_config = {}
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                existing_config = json.load(f)
        except Exception:
            existing_config = {}
    if 'ai' not in existing_config:
        existing_config['ai'] = {}
    existing_config['ai']['temperature'] = ain_settings.temperature
    existing_config['ai']['top_p'] = ain_settings.top_p
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(existing_config, f, indent=4, ensure_ascii=False)
    except Exception:
        pass

def _on_temperature_update(self, context):
    _save_ai_params_to_config_from_context(context)

def _on_top_p_update(self, context):
    _save_ai_params_to_config_from_context(context)

 

# æ’ä»¶åå¥½è®¾ç½®é¢æ¿
class AINodeAnalyzerPreferences(AddonPreferences):
    bl_idname = __name__

    def draw(self, context):
        layout = self.layout
        col = layout.column()
        col.label(text="AI Node Analyzer Preferences")
        col.separator()

# ä¸»è¦é¢æ¿
class NODE_PT_ai_analyzer(Panel):
    bl_label = "AIèŠ‚ç‚¹åˆ†æå™¨"
    bl_idname = "NODE_PT_ai_analyzer"
    bl_space_type = 'NODE_EDITOR'
    bl_region_type = 'UI'
    bl_category = "AI Node Analyzer"

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # é¡¶éƒ¨çŠ¶æ€ä¿¡æ¯è¡Œ - ä½¿ç”¨æ›´æ•´é½çš„å¸ƒå±€
        top_row = layout.row(align=True)
        node_type_display = "æœªçŸ¥"
        current_tree_type = None
        if context.space_data and hasattr(context.space_data, 'tree_type'):
            current_tree_type = context.space_data.tree_type
            if current_tree_type == 'GeometryNodeTree':
                node_type_display = "å‡ ä½•èŠ‚ç‚¹"
            elif current_tree_type == 'ShaderNodeTree':
                node_type_display = "æè´¨èŠ‚ç‚¹"
            elif current_tree_type == 'CompositorNodeTree':
                node_type_display = "åˆæˆèŠ‚ç‚¹"
            elif current_tree_type == 'TextureNodeTree':
                node_type_display = "çº¹ç†èŠ‚ç‚¹"
            elif current_tree_type == 'WorldNodeTree':
                node_type_display = "ç¯å¢ƒèŠ‚ç‚¹"

        # æ˜¾ç¤ºå½“å‰èŠ‚ç‚¹ç±»å‹
        top_row.label(text=f"èŠ‚ç‚¹: {node_type_display}")

        # æ·»åŠ ä¸€ä¸ªåˆ†éš”ç¬¦ï¼Œå°†èŠ‚ç‚¹ç±»å‹ä¸èº«ä»½é¢„è®¾åˆ†å¼€
        top_row.separator(factor=1.0)

        # å°†èº«ä»½è®¾ç½®ä¸‹æ‹‰èœå•æ·»åŠ åˆ°çŠ¶æ€ä¿¡æ¯è¡Œ
        top_row.prop(ain_settings, "identity_key", text="", icon='USER')

        # æ·»åŠ ä¸€ä¸ªåˆ†éš”ç¬¦ï¼Œå°†èº«ä»½é¢„è®¾ä¸UIæ§åˆ¶æŒ‰é’®åˆ†å¼€
        top_row.separator(factor=1.0)

        # æ·»åŠ ç®€åŒ–UIå¤é€‰æŒ‰é’®
        top_row.prop(ain_settings, "simplified_ui", text="", icon='HIDE_OFF' if ain_settings.simplified_ui else 'HIDE_ON')
        # æ·»åŠ å¸®åŠ©æç¤ºå¼€å…³
        top_row.prop(ain_settings, "show_help_text", text="", icon='QUESTION' if ain_settings.show_help_text else 'INFO')

        # æ·»åŠ ä¸€ä¸ªåˆ†éš”ç¬¦ï¼Œå°†UIæ§åˆ¶æŒ‰é’®ä¸æ“ä½œæŒ‰é’®åˆ†å¼€
        top_row.separator(factor=1.0)

        # æ“ä½œæŒ‰é’®åŒºåŸŸ
        top_row.operator("node.load_config_from_file", text="", icon='FILE_REFRESH')
        top_row.operator("node.settings_popup", text="", icon='SETTINGS')

        # é¡¶éƒ¨åç«¯æœåŠ¡å™¨è¡Œ
        backend_box = layout.box()
        backend_box.label(text="åç«¯æœåŠ¡å™¨", icon='WORLD')

        # æœåŠ¡å™¨æ§åˆ¶æŒ‰é’® - ä¸€è¡Œæ˜¾ç¤ºä¸‰ä¸ªæŒ‰é’®ï¼š[å¯åŠ¨/åœæ­¢] [ç«¯å£] [ç½‘é¡µ]
        server_row = backend_box.row(align=True)
        server_row.operator("node.toggle_backend_server", text="", icon='PLAY' if not (server_manager and server_manager.is_running) else 'PAUSE')
        server_row.prop(ain_settings, "backend_port", text="ç«¯å£")
        server_row.operator("node.open_backend_webpage", text="", icon='URL')


        # åº•éƒ¨äº¤äº’å¼æ–‡æ¡£é¢æ¿ç»„+æé—®æŒ‰é’®
        bottom_box = layout.box()

        # ç®€åŒ–æ¨¡å¼ï¼šåªæ˜¾ç¤ºé—®é¢˜è¾“å…¥æ¡†å’Œæé—®æŒ‰é’®
        if ain_settings.simplified_ui:
            # é—®é¢˜è¾“å…¥è¡Œ - åŒ…å«è¾“å…¥æ¡†å’Œå³ä¾§çš„æ“ä½œæŒ‰é’®
            input_row = bottom_box.row(align=True)
            input_row.prop(ain_settings, "user_input", text="")
            # åœ¨è¾“å…¥æ¡†å³ä¾§æ·»åŠ æ¸…é™¤å’Œåˆ·æ–°æŒ‰é’®
            input_row.operator("node.clear_question", text="", icon='TRASH')
            input_row.operator("node.refresh_to_text", text="", icon='FILE_REFRESH')

            # æé—®æŒ‰é’®å•ç‹¬ä¸€è¡Œï¼Œä½¿ç”¨æ›´å¤§å°ºå¯¸ï¼Œæ ¹æ®çŠ¶æ€æ˜¾ç¤ºä¸åŒæŒ‰é’®
            ask_row = bottom_box.row()
            ask_row.scale_y = 1.5

            # æ ¹æ®å½“å‰çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„æŒ‰é’®
            if ain_settings.ai_question_status == 'PROCESSING':
                # æ˜¾ç¤ºç»ˆæ­¢æŒ‰é’®
                ask_row.operator("node.stop_ai_request", text="ç»ˆæ­¢å›ç­”", icon='X')
            else:
                # æ˜¾ç¤ºæé—®æŒ‰é’®
                ask_row.operator("node.ask_ai", text="æé—®", icon='PLAY')

            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            status_text = {
                'IDLE': "å°±ç»ª",
                'PROCESSING': "æ­£åœ¨å›ç­”...",
                'STOPPED': "å·²ç»ˆæ­¢",
                'ERROR': "é”™è¯¯"
            }.get(ain_settings.ai_question_status, "æœªçŸ¥çŠ¶æ€")

            status_row = bottom_box.row()
            status_row.label(text=f"çŠ¶æ€: {status_text}")
        else:
            # æ ‡å‡†æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰åŠŸèƒ½
            # æ ‡é¢˜è¡ŒåŒ…å«æ ‡ç­¾ã€åˆ†ææ¡†æ¶æŒ‰é’®å’Œå¤åˆå¼€å…³
            title_row = bottom_box.row()
            title_row.label(text="äº¤äº’å¼é—®ç­”", icon='QUESTION')
            title_row.operator("node.create_analysis_frame", text="", icon='FRAME_NEXT')  # ä½¿ç”¨æ›´åˆé€‚çš„å›¾æ ‡

            # é—®é¢˜è¾“å…¥è¡Œ - åŒ…å«è¾“å…¥æ¡†å’Œå³ä¾§çš„æ“ä½œæŒ‰é’®
            input_row = bottom_box.row(align=True)
            input_row.prop(ain_settings, "user_input", text="")
            # åœ¨è¾“å…¥æ¡†å³ä¾§æ·»åŠ æ¸…é™¤å’Œåˆ·æ–°æŒ‰é’®
            input_row.operator("node.clear_question", text="", icon='TRASH')
            input_row.operator("node.refresh_to_text", text="", icon='FILE_REFRESH')

            # é»˜è®¤é—®é¢˜ä¸‹æ‹‰èœå• - ç§»åˆ°é—®é¢˜è¾“å…¥è¡Œä¸‹æ–¹
            preset_row = bottom_box.row()
            preset_row.prop(ain_settings, "default_question_preset", text="é»˜è®¤é—®é¢˜")

            # ç²¾åº¦æ§åˆ¶è¡Œ - èŠ‚ç‚¹ç²¾ç»†åº¦å’Œå›ç­”ç²¾ç»†åº¦æ”¾åœ¨åŒä¸€è¡Œ
            detail_row = bottom_box.row(align=True)
            # èŠ‚ç‚¹ç²¾ç»†åº¦
            node_detail_enum = ain_settings.node_detail_level
            node_detail_labels = ["æç®€", "ç®€åŒ–", "å¸¸è§„", "å®Œæ•´"]
            current_node_label = node_detail_labels[node_detail_enum] if 0 <= node_detail_enum < len(node_detail_labels) else "æœªçŸ¥"

            # åˆ›å»ºä¸€ä¸ªåŒ…å«èŠ‚ç‚¹ç²¾ç»†åº¦å’Œå¤åˆ¶åŠŸèƒ½çš„å­è¡Œ
            node_detail_subrow = detail_row.row(align=True)
            node_detail_subrow.prop(ain_settings, "node_detail_level", text=f"èŠ‚ç‚¹ç²¾ç»†åº¦({current_node_label})")
            # æ·»åŠ ä¸€ä¸ªæŒ‰é’®ç”¨äºå¤åˆ¶èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿ï¼ˆæ™®é€šç‚¹å‡»å¤åˆ¶é€‰ä¸­ï¼ŒAlt+ç‚¹å‡»å¤åˆ¶å…¨éƒ¨ï¼‰
            copy_btn = node_detail_subrow.operator("node.copy_nodes_to_clipboard", text="", icon='COPY_ID')

            # å›ç­”ç²¾ç»†åº¦
            response_detail_enum = ain_settings.response_detail_level
            response_detail_labels = ["ç®€çº¦", "é€‚ä¸­", "è¯¦ç»†"]
            current_label = response_detail_labels[response_detail_enum] if 0 <= response_detail_enum < len(response_detail_labels) else "æœªçŸ¥"
            # è·å–å½“å‰çº§åˆ«çš„å®é™…promptï¼ˆä½¿ç”¨output_detail_presetså˜é‡ï¼‰
            prompt_texts = [
                ain_settings.prompt_simple,
                ain_settings.prompt_medium,
                ain_settings.prompt_detailed
            ]
            current_prompt = prompt_texts[response_detail_enum] if 0 <= response_detail_enum < len(prompt_texts) else "æœªè®¾ç½®"
            # æˆªå–æç¤ºæ–‡æœ¬çš„å‰10ä¸ªå­—ç¬¦ä½œä¸ºè¡¥å……æ˜¾ç¤º
            preview_text = current_prompt[:10] + "..." if len(current_prompt) > 10 else current_prompt
            detail_row.prop(ain_settings, "response_detail_level", text=f"å›ç­”ç²¾ç»†åº¦({current_label}) - {preview_text}")

            # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰èœå• - ç§»åŠ¨åˆ°æé—®æŒ‰é’®ä¸Šæ–¹
            model_row = bottom_box.row()
            model_row.prop(ain_settings, "available_models", text="æ¨¡å‹")

            # ç¬¬ä¸‰è¡Œï¼šæé—®æŒ‰é’®å•ç‹¬ä¸€è¡Œï¼Œæ ¹æ®çŠ¶æ€æ˜¾ç¤ºä¸åŒæŒ‰é’®
            ask_row = bottom_box.row()
            ask_row.scale_y = 1.5

            # æ ¹æ®å½“å‰çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„æŒ‰é’®
            if ain_settings.ai_question_status == 'PROCESSING':
                # æ˜¾ç¤ºç»ˆæ­¢æŒ‰é’®
                ask_row.operator("node.stop_ai_request", text="ç»ˆæ­¢å›ç­”", icon='X')
            else:
                # æ˜¾ç¤ºæé—®æŒ‰é’®
                ask_row.operator("node.ask_ai", text="æé—®", icon='PLAY')

            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            status_text = {
                'IDLE': "å°±ç»ª",
                'PROCESSING': "æ­£åœ¨å›ç­”...",
                'STOPPED': "å·²ç»ˆæ­¢",
                'ERROR': "é”™è¯¯"
            }.get(ain_settings.ai_question_status, "æœªçŸ¥çŠ¶æ€")

            status_row = bottom_box.row()
            status_row.label(text=f"çŠ¶æ€: {status_text}")

            # å¸®åŠ©æç¤ºä¿¡æ¯ - å¯æŠ˜å 
            if ain_settings.show_help_text:
                help_box = bottom_box.box()
                help_col = help_box.column(align=True)
                help_col.label(text="ğŸ’¡ ä½¿ç”¨æç¤º:", icon='INFO')
                help_col.label(text="â€¢ é€‰æ‹©èŠ‚ç‚¹åç‚¹å‡»'æé—®'å‘AIè¯¢é—®")
                help_col.label(text="â€¢ ä½¿ç”¨'åˆ†ææ¡†æ¶'ç¡®å®šåˆ†æèŒƒå›´")
                help_col.label(text="â€¢ å¯é€šè¿‡'ç®€åŒ–UI'æŒ‰é’®éšè—éå¿…è¦å…ƒç´ ")

# å¿«é€Ÿå¤åˆ¶é¢æ¿
class NODE_PT_quick_copy(Panel):
    bl_label = "å¿«é€Ÿå¤åˆ¶"
    bl_idname = "NODE_PT_quick_copy"
    bl_space_type = 'NODE_EDITOR'
    bl_region_type = 'UI'
    bl_category = "AI Node Analyzer"
    bl_options = {'DEFAULT_CLOSED'}

    def draw(self, context):
        layout = self.layout
        ain_settings = context.scene.ainode_analyzer_settings

        # æ˜¾ç¤º4ä¸ªéƒ¨åˆ†çš„å›¾æ ‡+æ–‡æœ¬æŒ‰é’® - å¹³å‡æ’å¸ƒ
        # ä½¿ç”¨2x2ç½‘æ ¼å¸ƒå±€
        col = layout.column(align=True)
        
        # æ£€æŸ¥æ¯ä¸ªéƒ¨åˆ†æ˜¯å¦è¢«é€‰ä¸­
        selected_parts = {item.part_name for item in ain_settings.selected_text_parts}
        
        # ç¬¬ä¸€è¡Œï¼šè¾“å‡ºè¯¦ç»†ç¨‹åº¦ + ç³»ç»Ÿæç¤ºè¯
        row1 = col.row(align=True)
        row1.scale_x = 1.0
        row1.scale_y = 1.2
        
        # è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯
        op1 = row1.operator("node.copy_text_part", text="è¾“å‡º", icon='OUTPUT', depress=('output_detail' in selected_parts))
        op1.part = 'output_detail'
        
        # ç³»ç»Ÿæç¤ºè¯
        op2 = row1.operator("node.copy_text_part", text="ç”¨æˆ·", icon='USER', depress=('system_prompt' in selected_parts))
        op2.part = 'system_prompt'
        
        # ç¬¬äºŒè¡Œï¼šç”¨æˆ·é—®é¢˜ + èŠ‚ç‚¹æ•°æ®
        row2 = col.row(align=True)
        row2.scale_x = 1.0
        row2.scale_y = 1.2
        
        # ç”¨æˆ·é—®é¢˜
        op3 = row2.operator("node.copy_text_part", text="é—®é¢˜", icon='QUESTION', depress=('user_question' in selected_parts))
        op3.part = 'user_question'
        
        # èŠ‚ç‚¹æ•°æ®
        op4 = row2.operator("node.copy_text_part", text="èŠ‚ç‚¹", icon='NODETREE', depress=('node_data' in selected_parts))
        op4.part = 'node_data'

        # å¤åˆ¶æŒ‰é’®
        layout.separator()
        copy_row = layout.row()
        copy_row.alignment = 'CENTER'
        copy_row.scale_y = 1.2
        copy_row.operator("node.copy_active_text", text="å¤åˆ¶é€‰ä¸­éƒ¨åˆ†", icon='COPY_ID')
        
        # æ˜¾ç¤ºå½“å‰é€‰ä¸­çš„éƒ¨åˆ†æ•°é‡
        selected_count = len(ain_settings.selected_text_parts)
        if selected_count > 0:
            layout.separator()
            info_row = layout.row()
            info_row.alignment = 'CENTER'
            info_row.label(text=f"å·²é€‰ä¸­ {selected_count} ä¸ªéƒ¨åˆ†")

# MCP é¢æ¿
class BLENDERMCP_PT_Panel(bpy.types.Panel):
    bl_label = "AI Node MCP"
    bl_idname = "BLENDERMCP_PT_Panel"
    bl_space_type = 'NODE_EDITOR'
    bl_region_type = 'UI'
    bl_category = "AI Node Analyzer"
    bl_options = {'DEFAULT_CLOSED'}

    def draw(self, context):
        layout = self.layout
        scene = context.scene

        # æœåŠ¡å™¨æ§åˆ¶
        box = layout.box()
        box.label(text="MCP æœåŠ¡å™¨", icon='PREFERENCES')
        
        row = box.row()
        row.prop(scene, "blendermcp_port")
        
        if not scene.blendermcp_server_running:
            box.operator("blendermcp.start_server", text="å¯åŠ¨æœåŠ¡å™¨", icon='PLAY')
        else:
            box.operator("blendermcp.stop_server", text="åœæ­¢æœåŠ¡å™¨", icon='CANCEL')
            box.label(text=f"è¿è¡Œåœ¨ç«¯å£ {scene.blendermcp_port}", icon='CHECKMARK')
        
        # å¯ç”¨å·¥å…·
        box.separator()
        box.label(text="å¯ç”¨å·¥å…·:", icon='INFO')
        col = box.column(align=True)
        col.label(text="â€¢ get_scene_info - è·å–åœºæ™¯ä¿¡æ¯")
        col.label(text="â€¢ get_object_info - è·å–å¯¹è±¡ä¿¡æ¯")
        col.label(text="â€¢ get_viewport_screenshot - è·å–è§†å£æˆªå›¾")
        col.label(text="â€¢ execute_code - æ‰§è¡Œä»£ç ")

# MCP è¿ç®—ç¬¦
class BLENDERMCP_OT_StartServer(bpy.types.Operator):
    bl_idname = "blendermcp.start_server"
    bl_label = "å¯åŠ¨æœåŠ¡å™¨"
    bl_description = "å¯åŠ¨ BlenderMCP æœåŠ¡å™¨"

    def execute(self, context):
        scene = context.scene

        # Create a new server instance
        if not hasattr(bpy.types, "blendermcp_server") or not bpy.types.blendermcp_server:
            bpy.types.blendermcp_server = BlenderMCPServer(port=scene.blendermcp_port)

        # Start the server
        bpy.types.blendermcp_server.start()
        scene.blendermcp_server_running = True

        return {'FINISHED'}

class BLENDERMCP_OT_StopServer(bpy.types.Operator):
    bl_idname = "blendermcp.stop_server"
    bl_label = "åœæ­¢æœåŠ¡å™¨"
    bl_description = "åœæ­¢ BlenderMCP æœåŠ¡å™¨"

    def execute(self, context):
        scene = context.scene

        # Stop the server if it exists
        if hasattr(bpy.types, "blendermcp_server") and bpy.types.blendermcp_server:
            bpy.types.blendermcp_server.stop()
            del bpy.types.blendermcp_server

        scene.blendermcp_server_running = False

        return {'FINISHED'}

class BLENDERMCP_OT_OpenTerms(bpy.types.Operator):
    bl_idname = "blendermcp.open_terms"
    bl_label = "æŸ¥çœ‹æ¡æ¬¾å’Œæ¡ä»¶"
    bl_description = "æ‰“å¼€æ¡æ¬¾å’Œæ¡ä»¶æ–‡æ¡£"

    def execute(self, context):
        # Open the Terms and Conditions on GitHub
        terms_url = "https://github.com/ahujasid/blender-mcp/blob/main/TERMS_AND_CONDITIONS.md"
        try:
            import webbrowser
            webbrowser.open(terms_url)
            self.report({'INFO'}, "æ¡æ¬¾å’Œæ¡ä»¶å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
        except Exception as e:
            self.report({'ERROR'}, f"æ— æ³•æ‰“å¼€æ¡æ¬¾å’Œæ¡ä»¶ï¼š{str(e)}")
        
        return {'FINISHED'}

# BlenderMCP Server ç±»
class BlenderMCPServer:
    def __init__(self, host='localhost', port=9876):
        self.host = host
        self.port = port
        self.running = False
        self.socket = None
        self.server_thread = None

    def start(self):
        if self.running:
            print("Server is already running")
            return

        self.running = True

        try:
            # Create socket
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.socket.bind((self.host, self.port))
            self.socket.listen(1)

            # Start server thread
            self.server_thread = threading.Thread(target=self._server_loop)
            self.server_thread.daemon = True
            self.server_thread.start()

            print(f"BlenderMCP server started on {self.host}:{self.port}")
        except Exception as e:
            print(f"Failed to start server: {str(e)}")
            self.stop()

    def stop(self):
        self.running = False

        # Close socket
        if self.socket:
            try:
                self.socket.close()
            except:
                pass
            self.socket = None

        # Wait for thread to finish
        if self.server_thread:
            try:
                if self.server_thread.is_alive():
                    self.server_thread.join(timeout=1.0)
            except:
                pass
            self.server_thread = None

        print("BlenderMCP server stopped")

    def _server_loop(self):
        """Main server loop in a separate thread"""
        print("Server thread started")
        self.socket.settimeout(1.0)  # Timeout to allow for stopping

        while self.running:
            try:
                # Accept new connection
                try:
                    client, address = self.socket.accept()
                    print(f"Connected to client: {address}")

                    # Handle client in a separate thread
                    client_thread = threading.Thread(
                        target=self._handle_client,
                        args=(client,)
                    )
                    client_thread.daemon = True
                    client_thread.start()
                except socket.timeout:
                    # Just check running condition
                    continue
                except Exception as e:
                    print(f"Error accepting connection: {str(e)}")
                    time.sleep(0.5)
            except Exception as e:
                print(f"Error in server loop: {str(e)}")
                if not self.running:
                    break
                time.sleep(0.5)

        print("Server thread stopped")

    def _handle_client(self, client):
        """Handle connected client"""
        print("Client handler started")
        client.settimeout(None)  # No timeout
        buffer = b''

        try:
            while self.running:
                # Receive data
                try:
                    data = client.recv(8192)
                    if not data:
                        print("Client disconnected")
                        break

                    buffer += data
                    try:
                        # Try to parse command
                        command = json.loads(buffer.decode('utf-8'))
                        buffer = b''

                        # Execute command in Blender's main thread
                        def execute_wrapper():
                            try:
                                response = self.execute_command(command)
                                response_json = json.dumps(response)
                                try:
                                    client.sendall(response_json.encode('utf-8'))
                                except:
                                    print("Failed to send response - client disconnected")
                            except Exception as e:
                                print(f"Error executing command: {str(e)}")
                                traceback.print_exc()
                                try:
                                    error_response = {
                                        "status": "error",
                                        "message": str(e)
                                    }
                                    client.sendall(json.dumps(error_response).encode('utf-8'))
                                except:
                                    pass
                            return None

                        # Schedule execution in main thread
                        bpy.app.timers.register(execute_wrapper, first_interval=0.0)
                    except json.JSONDecodeError:
                        # Incomplete data, wait for more
                        pass
                except Exception as e:
                    print(f"Error receiving data: {str(e)}")
                    break
        except Exception as e:
            print(f"Error in client handler: {str(e)}")
        finally:
            try:
                client.close()
            except:
                pass
            print("Client handler stopped")

    def execute_command(self, command):
        """Execute a command in the main Blender thread"""
        try:
            return self._execute_command_internal(command)

        except Exception as e:
            print(f"Error executing command: {str(e)}")
            traceback.print_exc()
            return {"status": "error", "message": str(e)}

    def _execute_command_internal(self, command):
        """Internal command execution with proper context"""
        cmd_type = command.get("type")
        params = command.get("params", {})

        # Base handlers that are always available
        handlers = {
            "get_scene_info": self.get_scene_info,
            "get_object_info": self.get_object_info,
            "get_viewport_screenshot": self.get_viewport_screenshot,
            "execute_code": self.execute_code,
            "get_selected_nodes_info": self.get_selected_nodes_info,
            "get_all_nodes_info": self.get_all_nodes_info,
            "create_analysis_frame": self.create_analysis_frame,
            "remove_analysis_frame": self.remove_analysis_frame,
            "get_analysis_frame_nodes": self.get_analysis_frame_nodes,
            "get_config_variable": self.get_config_variable,
            "get_all_config_variables": self.get_all_config_variables,
            "create_text_note": self.create_text_note,
            "update_text_note": self.update_text_note,
            "get_text_note": self.get_text_note,
            "delete_text_note": self.delete_text_note,
            "filter_nodes_info": self.filter_nodes_info,
            "get_nodes_info_with_filter": self.get_nodes_info_with_filter,
            "clean_markdown_text": self.clean_markdown_text,
            "get_tools_list": self.get_tools_list,
        }

        handler = handlers.get(cmd_type)
        if handler:
            try:
                print(f"Executing handler for {cmd_type}")
                result = handler(**params)
                print(f"Handler execution complete")
                
                # æ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«é”™è¯¯
                if isinstance(result, dict) and "error" in result:
                    return {"status": "error", "message": result["error"]}
                
                return {"status": "success", "result": result}
            except Exception as e:
                print(f"Error in handler: {str(e)}")
                traceback.print_exc()
                return {"status": "error", "message": str(e)}
        else:
            return {"status": "error", "message": f"Unknown command type: {cmd_type}"}

    def get_scene_info(self):
        """Get information about the current Blender scene"""
        try:
            print("Getting scene info...")
            # Simplify the scene info to reduce data size
            scene_info = {
                "name": bpy.context.scene.name,
                "object_count": len(bpy.context.scene.objects),
                "objects": [],
                "materials_count": len(bpy.data.materials),
            }

            # Collect minimal object information (limit to first 10 objects)
            for i, obj in enumerate(bpy.context.scene.objects):
                if i >= 10:  # Reduced from 20 to 10
                    break

                obj_info = {
                    "name": obj.name,
                    "type": obj.type,
                    # Only include basic location data
                    "location": [round(float(obj.location.x), 2),
                                round(float(obj.location.y), 2),
                                round(float(obj.location.z), 2)],
                }
                scene_info["objects"].append(obj_info)

            print(f"Scene info collected: {len(scene_info['objects'])} objects")
            return scene_info
        except Exception as e:
            print(f"Error in get_scene_info: {str(e)}")
            traceback.print_exc()
            return {"error": str(e)}

    def get_object_info(self, name):
        """Get detailed information about a specific object"""
        from mathutils import Vector
        obj = bpy.data.objects.get(name)
        if not obj:
            raise ValueError(f"Object not found: {name}")

        # Basic object info
        obj_info = {
            "name": obj.name,
            "type": obj.type,
            "location": [obj.location.x, obj.location.y, obj.location.z],
            "rotation": [obj.rotation_euler.x, obj.rotation_euler.y, obj.rotation_euler.z],
            "scale": [obj.scale.x, obj.scale.y, obj.scale.z],
            "visible": obj.visible_get(),
            "materials": [],
        }

        # Add material slots
        for slot in obj.material_slots:
            if slot.material:
                obj_info["materials"].append(slot.material.name)

        # Add mesh data if applicable
        if obj.type == 'MESH' and obj.data:
            mesh = obj.data
            obj_info["mesh"] = {
                "vertices": len(mesh.vertices),
                "edges": len(mesh.edges),
                "polygons": len(mesh.polygons),
            }

        return obj_info

    def get_viewport_screenshot(self, max_size=800, filepath=None, format="png"):
        """
        Capture a screenshot of the current 3D viewport and save it to the specified path.

        Parameters:
        - max_size: Maximum size in pixels for the largest dimension of the image
        - filepath: Path where to save the screenshot file
        - format: Image format (png, jpg, etc.)

        Returns success/error status
        """
        try:
            if not filepath:
                return {"error": "No filepath provided"}

            # Find the active 3D viewport
            area = None
            for a in bpy.context.screen.areas:
                if a.type == 'VIEW_3D':
                    area = a
                    break

            if not area:
                return {"error": "No 3D viewport found"}

            # Take screenshot with proper context override
            with bpy.context.temp_override(area=area):
                bpy.ops.screen.screenshot_area(filepath=filepath)

            # Load and resize if needed
            img = bpy.data.images.load(filepath)
            width, height = img.size

            if max(width, height) > max_size:
                scale = max_size / max(width, height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                img.scale(new_width, new_height)

                # Set format and save
                img.file_format = format.upper()
                img.save()
                width, height = new_width, new_height

            # Cleanup Blender image data
            bpy.data.images.remove(img)

            return {
                "success": True,
                "width": width,
                "height": height,
                "filepath": filepath
            }

        except Exception as e:
            return {"error": str(e)}

    def execute_code(self, code):
        """Execute arbitrary Blender Python code"""
        # This is powerful but potentially dangerous - use with caution
        try:
            # Create a local namespace for execution
            namespace = {"bpy": bpy}

            # Capture stdout during execution, and return it as result
            capture_buffer = io.StringIO()
            with redirect_stdout(capture_buffer):
                exec(code, namespace)

            captured_output = capture_buffer.getvalue()
            return {"executed": True, "result": captured_output}
        except Exception as e:
            raise Exception(f"Code execution error: {str(e)}")

    def get_selected_nodes_info(self):
        """è·å–å½“å‰é€‰ä¸­èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯"""
        import json
        try:
            # æŸ¥æ‰¾èŠ‚ç‚¹ç¼–è¾‘å™¨åŒºåŸŸ
            node_space = None
            node_area = None
            
            # éå†æ‰€æœ‰åŒºåŸŸï¼Œæ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
            for area in bpy.context.screen.areas:
                if area.type == 'NODE_EDITOR':
                    for space in area.spaces:
                        if space.type == 'NODE_EDITOR':
                            node_space = space
                            node_area = area
                            break
                    if node_space:
                        break
            
            if not node_space or not node_space.node_tree:
                return {"error": "No active node tree found. Please open a node tree in the Node Editor."}
            
            node_tree = node_space.node_tree
            
            # å°è¯•å¤šç§æ–¹å¼è·å–é€‰ä¸­èŠ‚ç‚¹
            selected_nodes = []
            
            # æ–¹æ³• 1: ä»èŠ‚ç‚¹æ ‘ç›´æ¥è·å–ï¼ˆéå†æ‰€æœ‰èŠ‚ç‚¹æ£€æŸ¥ select å±æ€§ï¼‰
            selected_nodes = [node for node in node_tree.nodes if node.select]
            
            # æ–¹æ³• 2: å¦‚æœæ–¹æ³• 1 å¤±è´¥ï¼Œå°è¯•ä»ä¸Šä¸‹æ–‡è·å–ï¼ˆä½¿ç”¨è¦†ç›–ä¸Šä¸‹æ–‡ï¼‰
            if not selected_nodes:
                try:
                    override = bpy.context.copy()
                    override['area'] = node_area
                    override['space_data'] = node_space
                    override['node_tree'] = node_tree
                    with bpy.context.temp_override(**override):
                        if hasattr(bpy.context, 'selected_nodes') and bpy.context.selected_nodes:
                            selected_nodes = list(bpy.context.selected_nodes)
                except:
                    pass
            
            # æ–¹æ³• 3: ä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
            if not selected_nodes and hasattr(node_tree, 'nodes'):
                for node in node_tree.nodes:
                    if getattr(node, 'select', False):
                        selected_nodes.append(node)
                        break
                if not selected_nodes and node_tree.nodes.active:
                    selected_nodes = [node_tree.nodes.active]
            
            if not selected_nodes:
                return {"error": "No selected nodes. Please select at least one node."}
            
            # æ„å»ºç»“æœ
            result = {
                "node_tree_type": node_space.tree_type,
                "selected_nodes_count": len(selected_nodes),
                "selected_nodes": []
            }
            
            for node in selected_nodes:
                node_info = {
                    "name": node.name,
                    "name_localized": pgettext_iface(node.name),
                    "label": node.label,
                    "label_localized": pgettext_iface(node.label or node.name),
                    "type": node.bl_idname,
                    "location": (node.location.x, node.location.y),
                    "width": node.width,
                    "height": node.height,
                    "color": node.color[:] if hasattr(node, 'color') else [0, 0, 0],
                    "use_custom_color": getattr(node, 'use_custom_color', False),
                    "inputs": [],
                    "outputs": [],
                }
                
                # è§£æè¾“å…¥ç«¯å£
                for input_socket in node.inputs:
                    input_info = {
                        "name": input_socket.name,
                        "name_localized": pgettext_iface(input_socket.name),
                        "type": input_socket.type,
                        "identifier": input_socket.identifier,
                        "enabled": input_socket.enabled,
                        "hide": input_socket.hide,
                        "hide_value": getattr(input_socket, 'hide_value', False),
                    }
                    if hasattr(input_socket, 'default_value'):
                        try:
                            val = input_socket.default_value
                            if isinstance(val, (int, float, str, bool)):
                                input_info["default_value"] = val
                            elif hasattr(val, '__len__') and len(val) <= 10:
                                input_info["default_value"] = list(val)
                            else:
                                input_info["default_value"] = str(val)[:50] + "..." if len(str(val)) > 50 else str(val)
                        except:
                            input_info["default_value"] = "N/A"
                    
                    # æ£€æŸ¥è¾“å…¥æ˜¯å¦è¿æ¥
                    connected = False
                    for link in node_tree.links:
                        if link.to_socket == input_socket:
                            input_info["connected_from"] = {
                                "node": link.from_node.name,
                                "node_localized": pgettext_iface(link.from_node.name),
                                "socket": link.from_socket.name,
                                "socket_localized": pgettext_iface(link.from_socket.name)
                            }
                            connected = True
                            break
                    input_info["is_connected"] = connected
                    node_info["inputs"].append(input_info)
                
                # è§£æè¾“å‡ºç«¯å£
                for output_socket in node.outputs:
                    output_info = {
                        "name": output_socket.name,
                        "name_localized": pgettext_iface(output_socket.name),
                        "type": output_socket.type,
                        "identifier": output_socket.identifier,
                        "enabled": output_socket.enabled,
                        "hide": output_socket.hide,
                    }
                    if hasattr(output_socket, 'default_value'):
                        try:
                            val = output_socket.default_value
                            if isinstance(val, (int, float, str, bool)):
                                output_info["default_value"] = val
                            elif hasattr(val, '__len__') and len(val) <= 10:
                                output_info["default_value"] = list(val)
                            else:
                                output_info["default_value"] = str(val)[:50] + "..." if len(str(val)) > 50 else str(val)
                        except:
                            output_info["default_value"] = "N/A"
                    
                    # æ£€æŸ¥è¾“å‡ºæ˜¯å¦è¿æ¥
                    connected = False
                    output_info["connected_to"] = []
                    for link in node_tree.links:
                        if link.from_socket == output_socket:
                            output_info["connected_to"].append({
                                "node": link.to_node.name,
                                "node_localized": pgettext_iface(link.to_node.name),
                                "socket": link.to_socket.name,
                                "socket_localized": pgettext_iface(link.to_socket.name)
                            })
                            connected = True
                    output_info["is_connected"] = connected
                    node_info["outputs"].append(output_info)
                
                result["selected_nodes"].append(node_info)
            
            # æ·»åŠ è¿æ¥ä¿¡æ¯
            if hasattr(node_tree, 'links'):
                connections = []
                for link in node_tree.links:
                    if link.from_node in selected_nodes or link.to_node in selected_nodes:
                        connection_info = {
                            "from_node": link.from_node.name,
                            "from_node_localized": pgettext_iface(link.from_node.name),
                            "from_socket": link.from_socket.name,
                            "from_socket_localized": pgettext_iface(link.from_socket.name),
                            "to_node": link.to_node.name,
                            "to_node_localized": pgettext_iface(link.to_node.name),
                            "to_socket": link.to_socket.name,
                            "to_socket_localized": pgettext_iface(link.to_socket.name),
                        }
                        connections.append(connection_info)
                result["connections"] = connections
            
            return result
        except Exception as e:
            traceback.print_exc()
            return {"error": str(e)}

    def get_all_nodes_info(self):
        """è·å–å½“å‰èŠ‚ç‚¹æ ‘ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾èŠ‚ç‚¹ç¼–è¾‘å™¨åŒºåŸŸ
            node_space = None
            node_area = None
            
            # éå†æ‰€æœ‰åŒºåŸŸï¼Œæ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
            for area in bpy.context.screen.areas:
                if area.type == 'NODE_EDITOR':
                    for space in area.spaces:
                        if space.type == 'NODE_EDITOR':
                            node_space = space
                            node_area = area
                            break
                    if node_space:
                        break
            
            if not node_space:
                return {"error": "Not in Node Editor. Please switch to Node Editor view."}
            
            if not node_space.node_tree:
                return {"error": "No active node tree found. Please open or create a node tree."}
            
            node_tree = node_space.node_tree
            result = parse_node_tree_recursive(node_tree)
            return result
        except Exception as e:
            traceback.print_exc()
            return {"error": str(e)}

    def create_analysis_frame(self):
        """åˆ›å»ºåˆ†ææ¡†æ¶ï¼Œå°†é€‰ä¸­çš„èŠ‚ç‚¹åŠ å…¥æ¡†æ¶"""
        try:
            bpy.ops.node.create_analysis_frame()
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            return {
                "status": "success",
                "frame_node_names": ain_settings.analysis_frame_node_names
            }
        except Exception as e:
            return {"error": str(e)}

    def remove_analysis_frame(self):
        """ç§»é™¤åˆ†ææ¡†æ¶"""
        try:
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            node_tree = bpy.context.space_data.node_tree
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¡†æ¶
            frame_node = None
            for node in node_tree.nodes:
                if node.type == 'FRAME' and node.label == "å°†è¦åˆ†æ":
                    frame_node = node
                    break
            
            if frame_node:
                # ç§»é™¤æ¡†æ¶
                node_names = []
                nodes_in_frame = []
                for node in node_tree.nodes:
                    if node.parent == frame_node:
                        node_names.append(node.name)
                        nodes_in_frame.append(node)
                        node.parent = None
                ain_settings.analysis_frame_node_names = ','.join(node_names)
                node_tree.nodes.remove(frame_node)
                
                return {
                    "status": "success",
                    "frame_node_names": ain_settings.analysis_frame_node_names
                }
            else:
                return {"error": "No analysis frame found"}
        except Exception as e:
            return {"error": str(e)}

    def get_analysis_frame_nodes(self):
        """è·å–åˆ†ææ¡†æ¶ä¸­çš„èŠ‚ç‚¹ä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾èŠ‚ç‚¹ç¼–è¾‘å™¨åŒºåŸŸ
            node_space = None
            node_area = None
            
            # éå†æ‰€æœ‰åŒºåŸŸï¼Œæ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
            for area in bpy.context.screen.areas:
                if area.type == 'NODE_EDITOR':
                    for space in area.spaces:
                        if space.type == 'NODE_EDITOR':
                            node_space = space
                            node_area = area
                            break
                    if node_space:
                        break
            
            if not node_space or not node_space.node_tree:
                return {"error": "No active node tree found."}
            
            node_tree = node_space.node_tree
            
            # æŸ¥æ‰¾åˆ†ææ¡†æ¶
            frame_node = None
            for node in node_tree.nodes:
                if node.type == 'FRAME' and node.label == "å°†è¦åˆ†æ":
                    frame_node = node
                    break
            
            if not frame_node:
                return {"error": "No analysis frame found. Please create one first."}
            
            # è·å–æ¡†æ¶ä¸­çš„èŠ‚ç‚¹
            frame_nodes = []
            for node in node_tree.nodes:
                if node.parent == frame_node:
                    frame_nodes.append({
                        "name": node.name,
                        "type": node.bl_idname,
                        "label": node.label,
                        "location": (node.location.x, node.location.y)
                    })
            
            return {
                "status": "success",
                "frame_label": frame_node.label,
                "node_count": len(frame_nodes),
                "nodes": frame_nodes
            }
        except Exception as e:
            traceback.print_exc()
            return {"error": str(e)}

    def get_config_variable(self, variable_name):
        """è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„æŒ‡å®šå˜é‡"""
        try:
            import json
            import os
            
            config_path = os.path.join(os.path.dirname(__file__), "config.json")
            if not os.path.exists(config_path):
                return {"error": "Config file not found"}
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ ¹æ®å˜é‡åè¿”å›å¯¹åº”çš„å€¼
            if variable_name == "identity_presets":
                return config.get("system_message_presets", [])
            elif variable_name == "default_questions":
                return config.get("default_question_presets", [])
            elif variable_name == "output_detail_presets":
                return config.get("output_detail_presets", {})
            elif variable_name == "system_prompt":
                return config.get("ai", {}).get("system_prompt", "")
            elif variable_name == "output_detail_level":
                return config.get("output_detail_level", "medium")
            else:
                return {"error": f"Unknown variable: {variable_name}"}
        except Exception as e:
            return {"error": str(e)}

    def get_all_config_variables(self):
        """è·å–æ‰€æœ‰é…ç½®å˜é‡"""
        try:
            import json
            import os
            
            config_path = os.path.join(os.path.dirname(__file__), "config.json")
            if not os.path.exists(config_path):
                return {"error": "Config file not found"}
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            return {
                "identity_presets": config.get("system_message_presets", []),
                "default_questions": config.get("default_question_presets", []),
                "output_detail_presets": config.get("output_detail_presets", {}),
                "system_prompt": config.get("ai", {}).get("system_prompt", ""),
                "output_detail_level": config.get("output_detail_level", "medium")
            }
        except Exception as e:
            return {"error": str(e)}

    def create_text_note(self, text):
        """åˆ›å»ºæ–‡æœ¬æ³¨è®°èŠ‚ç‚¹"""
        try:
            from backend.ai_note import create_note
            
            success = create_note(text)
            
            if success:
                return {"status": "success", "message": "Text note created"}
            else:
                return {"error": "Failed to create text note"}
        except Exception as e:
            return {"error": str(e)}

    def update_text_note(self, text):
        """æ›´æ–°å½“å‰æ¿€æ´»çš„æ–‡æœ¬æ³¨è®°èŠ‚ç‚¹"""
        try:
            from backend.ai_note import update_active
            
            success = update_active(text)
            
            if success:
                return {"status": "success", "message": "Text note updated"}
            else:
                return {"error": "Failed to update text note"}
        except Exception as e:
            return {"error": str(e)}

    def get_text_note(self):
        """è·å–å½“å‰æ¿€æ´»çš„æ–‡æœ¬æ³¨è®°èŠ‚ç‚¹å†…å®¹"""
        try:
            from backend.ai_note import get_active_note
            
            content = get_active_note()
            
            if content is not None:
                return {"status": "success", "content": content}
            else:
                return {"error": "No active text note found"}
        except Exception as e:
            return {"error": str(e)}

    def delete_text_note(self):
        """åˆ é™¤å½“å‰æ¿€æ´»çš„æ–‡æœ¬æ³¨è®°èŠ‚ç‚¹"""
        try:
            from backend.ai_note import delete_active_note
            
            success = delete_active_note()
            
            if success:
                return {"status": "success", "message": "Text note deleted"}
            else:
                return {"error": "Failed to delete text note"}
        except Exception as e:
            return {"error": str(e)}

    def filter_nodes_info(self, node_info, level):
        """æ ¹æ®ç²¾ç»†åº¦è¿‡æ»¤èŠ‚ç‚¹ä¿¡æ¯"""
        try:
            level_map = {
                "ULTRA_LITE": 0,
                "LITE": 1,
                "STANDARD": 2,
                "FULL": 3
            }
            
            level_value = level_map.get(level, 2)
            filtered = filter_node_description(node_info, level_value)
            
            return {
                "status": "success",
                "level": level,
                "filtered_info": filtered
            }
        except Exception as e:
            return {"error": str(e)}

    def get_nodes_info_with_filter(self, level):
        """è·å–èŠ‚ç‚¹ä¿¡æ¯å¹¶åº”ç”¨è¿‡æ»¤"""
        try:
            level = level or "STANDARD"
            
            # æŸ¥æ‰¾èŠ‚ç‚¹ç¼–è¾‘å™¨åŒºåŸŸ
            node_space = None
            node_area = None
            
            # éå†æ‰€æœ‰åŒºåŸŸï¼Œæ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
            for area in bpy.context.screen.areas:
                if area.type == 'NODE_EDITOR':
                    for space in area.spaces:
                        if space.type == 'NODE_EDITOR':
                            node_space = space
                            node_area = area
                            break
                    if node_space:
                        break
            
            if not node_space:
                return {"error": "Not in Node Editor. Please switch to Node Editor view."}
            
            if not node_space.node_tree:
                return {"error": "No active node tree found. Please open or create a node tree."}
            
            # åˆ›å»ºè¦†ç›–ä¸Šä¸‹æ–‡
            override = bpy.context.copy()
            override['area'] = node_area
            override['space_data'] = node_space
            override['node_tree'] = node_space.node_tree
            
            node_tree = node_space.node_tree
            selected_nodes = []
            
            # å°è¯•å¤šç§æ–¹å¼è·å–é€‰ä¸­èŠ‚ç‚¹
            if hasattr(override, 'selected_nodes'):
                selected_nodes = list(override.selected_nodes)
            
            if not selected_nodes:
                selected_nodes = [node for node in node_tree.nodes if node.select]
            
            if not selected_nodes and hasattr(override, 'active_node') and override.active_node:
                selected_nodes = [override.active_node]
            
            if not selected_nodes:
                return {"error": "No selected nodes. Please select at least one node."}
            
            # è·å–èŠ‚ç‚¹æè¿°
            result = {
                "node_tree_type": node_space.tree_type,
                "selected_nodes_count": len(selected_nodes),
                "selected_nodes": []
            }
            
            for node in selected_nodes:
                node_info = {
                    "name": node.name,
                    "label": node.label,
                    "type": node.bl_idname,
                    "location": (node.location.x, node.location.y),
                    "inputs": [],
                    "outputs": [],
                }
                
                for input_socket in node.inputs:
                    node_info["inputs"].append({
                        "name": input_socket.name,
                        "type": input_socket.type,
                        "identifier": input_socket.identifier,
                    })
                
                for output_socket in node.outputs:
                    node_info["outputs"].append({
                        "name": output_socket.name,
                        "type": output_socket.type,
                        "identifier": output_socket.identifier,
                    })
                
                result["selected_nodes"].append(node_info)
            
            # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
            node_info_json = json.dumps(result, indent=2)
            
            # åº”ç”¨è¿‡æ»¤
            level_map = {
                "ULTRA_LITE": 0,
                "LITE": 1,
                "STANDARD": 2,
                "FULL": 3
            }
            
            level_value = level_map.get(level, 2)
            filtered = filter_node_description(node_info_json, level_value)
            
            return {
                "status": "success",
                "level": level,
                "filtered_info": filtered
            }
        except Exception as e:
            traceback.print_exc()
            return {"error": str(e)}

    def clean_markdown_text(self, text):
        """æ¸…ç†æŒ‡å®šæ–‡æœ¬çš„ Markdown æ ¼å¼"""
        try:
            cleaned = clean_markdown(text)
            
            return {
                "status": "success",
                "original_length": len(text),
                "cleaned_length": len(cleaned),
                "cleaned_text": cleaned
            }
        except Exception as e:
            return {"error": str(e)}

    def get_tools_list(self):
        """è·å–æ‰€æœ‰å¯ç”¨çš„ MCP å·¥å…·åˆ—è¡¨"""
        try:
            tools = [
                {
                    "name": "get_scene_info",
                    "description": "è·å–å½“å‰ Blender åœºæ™¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬åœºæ™¯åç§°ã€å¯¹è±¡æ•°é‡ã€æè´¨æ•°é‡ç­‰",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "get_object_info",
                    "description": "è·å–æŒ‡å®šå¯¹è±¡çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½ç½®ã€æ—‹è½¬ã€ç¼©æ”¾ã€æè´¨ç­‰",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "å¯¹è±¡åç§°"
                            }
                        },
                        "required": ["name"]
                    }
                },
                {
                    "name": "get_viewport_screenshot",
                    "description": "è·å– 3D è§†å£çš„æˆªå›¾",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "execute_code",
                    "description": "æ‰§è¡Œ Blender Python ä»£ç ",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "code": {
                                "type": "string",
                                "description": "è¦æ‰§è¡Œçš„ Python ä»£ç "
                            }
                        },
                        "required": ["code"]
                    }
                },
                {
                    "name": "get_selected_nodes_info",
                    "description": "è·å–å½“å‰é€‰ä¸­èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹åç§°ã€ç±»å‹ã€ä½ç½®ã€è¾“å…¥è¾“å‡ºç«¯å£ã€è¿æ¥å…³ç³»ç­‰",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "get_all_nodes_info",
                    "description": "è·å–å½“å‰æ¿€æ´»èŠ‚ç‚¹æ ‘ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ä¿¡æ¯ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "create_analysis_frame",
                    "description": "åˆ›å»ºåˆ†ææ¡†æ¶ï¼Œå°†é€‰ä¸­çš„èŠ‚ç‚¹åŠ å…¥æ¡†æ¶ä¸­ï¼Œç”¨äºç¡®å®šåˆ†æèŒƒå›´",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "remove_analysis_frame",
                    "description": "ç§»é™¤åˆ†ææ¡†æ¶",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "get_analysis_frame_nodes",
                    "description": "è·å–åˆ†ææ¡†æ¶ä¸­çš„èŠ‚ç‚¹ä¿¡æ¯",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "get_config_variable",
                    "description": "è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„æŒ‡å®šå˜é‡",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "variable_name": {
                                "type": "string",
                                "description": "å˜é‡åç§° (identity_presets, default_questions, output_detail_presets, system_prompt, output_detail_level)",
                                "enum": ["identity_presets", "default_questions", "output_detail_presets", "system_prompt", "output_detail_level"]
                            }
                        },
                        "required": ["variable_name"]
                    }
                },
                {
                    "name": "get_all_config_variables",
                    "description": "è·å–æ‰€æœ‰é…ç½®å˜é‡",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "create_text_note",
                    "description": "åˆ›å»ºæ–‡æœ¬æ³¨è®°èŠ‚ç‚¹",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "text": {
                                "type": "string",
                                "description": "æ–‡æœ¬å†…å®¹"
                            }
                        },
                        "required": ["text"]
                    }
                },
                {
                    "name": "update_text_note",
                    "description": "æ›´æ–°å½“å‰æ¿€æ´»çš„æ–‡æœ¬æ³¨è®°èŠ‚ç‚¹",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "text": {
                                "type": "string",
                                "description": "æ–°çš„æ–‡æœ¬å†…å®¹"
                            }
                        },
                        "required": ["text"]
                    }
                },
                {
                    "name": "get_text_note",
                    "description": "è·å–å½“å‰æ¿€æ´»çš„æ–‡æœ¬æ³¨è®°èŠ‚ç‚¹å†…å®¹",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "delete_text_note",
                    "description": "åˆ é™¤å½“å‰æ¿€æ´»çš„æ–‡æœ¬æ³¨è®°èŠ‚ç‚¹",
                    "inputSchema": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                },
                {
                    "name": "filter_nodes_info",
                    "description": "æ ¹æ®ç²¾ç»†åº¦è¿‡æ»¤èŠ‚ç‚¹ä¿¡æ¯",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "node_info": {
                                "type": "string",
                                "description": "èŠ‚ç‚¹ä¿¡æ¯ JSON å­—ç¬¦ä¸²"
                            },
                            "level": {
                                "type": "string",
                                "description": "ç²¾ç»†åº¦çº§åˆ«",
                                "enum": ["ULTRA_LITE", "LITE", "STANDARD", "FULL"]
                            }
                        },
                        "required": ["node_info", "level"]
                    }
                },
                {
                    "name": "get_nodes_info_with_filter",
                    "description": "è·å–èŠ‚ç‚¹ä¿¡æ¯å¹¶åº”ç”¨è¿‡æ»¤",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "level": {
                                "type": "string",
                                "description": "ç²¾ç»†åº¦çº§åˆ«",
                                "enum": ["ULTRA_LITE", "LITE", "STANDARD", "FULL"]
                            }
                        },
                        "required": []
                    }
                },
                {
                    "name": "clean_markdown_text",
                    "description": "æ¸…ç†æŒ‡å®šæ–‡æœ¬çš„ Markdown æ ¼å¼",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "text": {
                                "type": "string",
                                "description": "è¦æ¸…ç†çš„æ–‡æœ¬"
                            }
                        },
                        "required": ["text"]
                    }
                }
            ]
            
            return {"tools": tools}
        except Exception as e:
            return {"error": str(e)}

# å¤åˆ¶æ–‡æœ¬éƒ¨åˆ†è¿ç®—ç¬¦
class NODE_OT_copy_text_part(bpy.types.Operator):
    bl_idname = "node.copy_text_part"
    bl_label = "åˆ‡æ¢æ–‡æœ¬éƒ¨åˆ†é€‰æ‹©"
    bl_description = "å·¦é”®åˆ‡æ¢é€‰ä¸­çŠ¶æ€ï¼ŒShift+å•å‡»ç›´æ¥å¤åˆ¶"
    bl_options = {'UNDO'}

    part: bpy.props.StringProperty(name="Part", default="")

    def invoke(self, context, event):
        ain_settings = context.scene.ainode_analyzer_settings
        
        # å¦‚æœæ˜¯Shift+å•å‡»ï¼Œç›´æ¥å¤åˆ¶
        if event.shift:
            self.copy_text(context)
            return {'FINISHED'}
        
        # å·¦é”®ç‚¹å‡»ï¼Œåˆ‡æ¢é€‰ä¸­çŠ¶æ€
        # æ£€æŸ¥æ˜¯å¦å·²ç»é€‰ä¸­
        found_index = -1
        for i, item in enumerate(ain_settings.selected_text_parts):
            if item.part_name == self.part:
                found_index = i
                break
        
        if found_index >= 0:
            # å¦‚æœå·²ç»é€‰ä¸­ï¼Œç§»é™¤å®ƒ
            ain_settings.selected_text_parts.remove(found_index)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œæ·»åŠ å®ƒ
            item = ain_settings.selected_text_parts.add()
            item.part_name = self.part
        
        return {'FINISHED'}

    def copy_text(self, context):
        text_block_name = {
            'output_detail': '01-è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯',
            'system_prompt': '02-ç³»ç»Ÿæç¤ºè¯',
            'user_question': '03-ç”¨æˆ·é—®é¢˜',
            'node_data': '04-èŠ‚ç‚¹æ•°æ®'
        }.get(self.part)
        
        if text_block_name and text_block_name in bpy.data.texts:
            text_block = bpy.data.texts[text_block_name]
            content = text_block.as_string()
            if content:
                context.window_manager.clipboard = content
                self.report({'INFO'}, f"å·²å¤åˆ¶{self.part}")

# å¤åˆ¶é€‰ä¸­æ–‡æœ¬è¿ç®—ç¬¦
class NODE_OT_copy_active_text(bpy.types.Operator):
    bl_idname = "node.copy_active_text"
    bl_label = "å¤åˆ¶é€‰ä¸­æ–‡æœ¬"
    bl_description = "å¤åˆ¶æ‰€æœ‰é€‰ä¸­çš„æ–‡æœ¬éƒ¨åˆ†åˆ°å‰ªè´´æ¿"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        
        if len(ain_settings.selected_text_parts) == 0:
            self.report({'WARNING'}, "è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡æœ¬éƒ¨åˆ†")
            return {'CANCELLED'}
        
        all_content = []
        for item in ain_settings.selected_text_parts:
            part = item.part_name
            text_block_name = {
                'output_detail': '01-è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯',
                'system_prompt': '02-ç³»ç»Ÿæç¤ºè¯',
                'user_question': '03-ç”¨æˆ·é—®é¢˜',
                'node_data': '04-èŠ‚ç‚¹æ•°æ®'
            }.get(part)
            
            if text_block_name and text_block_name in bpy.data.texts:
                text_block = bpy.data.texts[text_block_name]
                content = text_block.as_string()
                if content:
                    all_content.append(f"=== {part} ===\n{content}\n")
        
        if all_content:
            combined_content = "\n".join(all_content)
            context.window_manager.clipboard = combined_content
            self.report({'INFO'}, f"å·²å¤åˆ¶ {len(all_content)} ä¸ªéƒ¨åˆ†")
            return {'FINISHED'}
        else:
            self.report({'WARNING'}, "é€‰ä¸­çš„éƒ¨åˆ†å†…å®¹ä¸ºç©º")
            return {'CANCELLED'}

# å¤åˆ¶æ–‡æœ¬ç¼–è¾‘å™¨å†…å®¹è¿ç®—ç¬¦
class NODE_OT_copy_text_to_clipboard(bpy.types.Operator):
    bl_idname = "node.copy_text_to_clipboard"
    bl_label = "å¤åˆ¶æ–‡æœ¬"
    bl_description = "å¤åˆ¶å½“å‰æ–‡æœ¬ç¼–è¾‘å™¨çš„å†…å®¹åˆ°å‰ªè´´æ¿"

    def execute(self, context):
        # è·å–å½“å‰æ´»åŠ¨çš„æ–‡æœ¬ç¼–è¾‘å™¨
        for area in context.screen.areas:
            if area.type == 'TEXT_EDITOR':
                for space in area.spaces:
                    if space.type == 'TEXT_EDITOR' and space.text:
                        content = space.text.as_string()
                        if content:
                            context.window_manager.clipboard = content
                            self.report({'INFO'}, "å·²å¤åˆ¶æ–‡æœ¬å†…å®¹")
                            return {'FINISHED'}
                        else:
                            self.report({'WARNING'}, "æ–‡æœ¬å†…å®¹ä¸ºç©º")
                            return {'CANCELLED'}
        
        self.report({'WARNING'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„æ–‡æœ¬ç¼–è¾‘å™¨")
        return {'CANCELLED'}

# å®ç°èŠ‚ç‚¹è§£æåŠŸèƒ½
def parse_node_tree_recursive(node_tree, depth=0, max_depth=10):
    """
    é€’å½’è§£æèŠ‚ç‚¹æ ‘
    :param node_tree: è¦è§£æçš„èŠ‚ç‚¹æ ‘
    :param depth: å½“å‰é€’å½’æ·±åº¦
    :param max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼Œé˜²æ­¢æ— é™é€’å½’
    :return: è§£æç»“æœçš„å­—å…¸
    """
    if depth >= max_depth:
        return {"error": f"Max recursion depth ({max_depth}) reached"}

    result = {
        "tree_type": node_tree.bl_idname if hasattr(node_tree, 'bl_idname') else "Unknown",
        "nodes": [],
        "groups": {},
        "links": []
    }

    # è§£æèŠ‚ç‚¹
    for node in node_tree.nodes:
        node_info = {
            "name": node.name,
            "name_localized": pgettext_iface(node.name),
            "label": node.label,
            "label_localized": pgettext_iface(node.label or node.name),
            "type": node.bl_idname,
            "location": (node.location.x, node.location.y),
            "width": node.width,
            "height": node.height,
            "color": node.color[:],
            "use_custom_color": node.use_custom_color,
            "inputs": [],
            "outputs": [],
        }

        # è§£æè¾“å…¥ç«¯å£
        for input_idx, input_socket in enumerate(node.inputs):
            input_info = {
                "name": input_socket.name,
                "name_localized": pgettext_iface(input_socket.name),
                "type": input_socket.type,
                "identifier": input_socket.identifier,
                "enabled": input_socket.enabled,
                "hide": input_socket.hide,
                "hide_value": input_socket.hide_value,
            }
            # æ·»åŠ é»˜è®¤å€¼ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
            if hasattr(input_socket, 'default_value'):
                try:
                    # å¤„ç†ä¸åŒç±»å‹çš„é»˜è®¤å€¼
                    val = input_socket.default_value
                    if isinstance(val, (int, float, str, bool)):
                        input_info["default_value"] = val
                    elif hasattr(val, '__len__') and len(val) <= 10:  # å¤„ç†å‘é‡ç­‰åºåˆ—
                        input_info["default_value"] = list(val)
                    else:
                        input_info["default_value"] = str(val)[:50] + "..." if len(str(val)) > 50 else str(val)
                except:
                    input_info["default_value"] = "N/A"

            # æ£€æŸ¥è¾“å…¥æ˜¯å¦è¿æ¥
            connected = False
            for link in node_tree.links:
                if link.to_socket == input_socket:
                    input_info["connected_from"] = {
                        "node": link.from_node.name,
                        "node_localized": pgettext_iface(link.from_node.name),
                        "socket": link.from_socket.name,
                        "socket_localized": pgettext_iface(link.from_socket.name)
                    }
                    connected = True
                    break
            input_info["is_connected"] = connected

            node_info["inputs"].append(input_info)

        # è§£æè¾“å‡ºç«¯å£
        for output_idx, output_socket in enumerate(node.outputs):
            output_info = {
                "name": output_socket.name,
                "name_localized": pgettext_iface(output_socket.name),
                "type": output_socket.type,
                "identifier": output_socket.identifier,
                "enabled": output_socket.enabled,
                "hide": output_socket.hide,
            }
            # æ·»åŠ é»˜è®¤å€¼ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
            if hasattr(output_socket, 'default_value'):
                try:
                    val = output_socket.default_value
                    if isinstance(val, (int, float, str, bool)):
                        output_info["default_value"] = val
                    elif hasattr(val, '__len__') and len(val) <= 10:  # å¤„ç†å‘é‡ç­‰åºåˆ—
                        output_info["default_value"] = list(val)
                    else:
                        output_info["default_value"] = str(val)[:50] + "..." if len(str(val)) > 50 else str(val)
                except:
                    output_info["default_value"] = "N/A"

            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦è¿æ¥
            connected = False
            output_info["connected_to"] = []
            for link in node_tree.links:
                if link.from_socket == output_socket:
                    output_info["connected_to"].append({
                        "node": link.to_node.name,
                        "node_localized": pgettext_iface(link.to_node.name),
                        "socket": link.to_socket.name,
                        "socket_localized": pgettext_iface(link.to_socket.name)
                    })
                    connected = True
            output_info["is_connected"] = connected

            node_info["outputs"].append(output_info)

        # å¦‚æœæ˜¯èŠ‚ç‚¹ç»„ï¼Œé€’å½’è§£æå…¶å†…å®¹
        if node.type == 'GROUP' and node.node_tree:
            node_info["group_content"] = parse_node_tree_recursive(node.node_tree, depth + 1, max_depth)
            result["groups"][node.name] = node_info["group_content"]

        result["nodes"].append(node_info)

    # è§£æè¿æ¥
    for link in node_tree.links:
        link_info = {
            "from_node": link.from_node.name,
            "from_node_localized": pgettext_iface(link.from_node.name),
            "from_socket": link.from_socket.name,
            "from_socket_localized": pgettext_iface(link.from_socket.name),
            "to_node": link.to_node.name,
            "to_node_localized": pgettext_iface(link.to_node.name),
            "to_socket": link.to_socket.name,
            "to_socket_localized": pgettext_iface(link.to_socket.name),
        }
        result["links"].append(link_info)

    return result

def get_selected_nodes_description(context):
    """
    è·å–é€‰ä¸­èŠ‚ç‚¹çš„æè¿°
    :param context: Blenderä¸Šä¸‹æ–‡
    :return: åŒ…å«èŠ‚ç‚¹æè¿°çš„å­—ç¬¦ä¸²
    """
    space = context.space_data

    if not hasattr(space, 'node_tree') or not space.node_tree:
        return "No active node tree found."

    node_tree = space.node_tree
    
    # å°è¯•å¤šç§æ–¹å¼è·å–é€‰ä¸­èŠ‚ç‚¹
    selected_nodes = []
    
    # æ–¹æ³• 1: ä» context.selected_nodes è·å–
    if hasattr(context, 'selected_nodes'):
        selected_nodes = list(context.selected_nodes)
    
    # æ–¹æ³• 2: å¦‚æœæ–¹æ³• 1 å¤±è´¥ï¼Œä»èŠ‚ç‚¹æ ‘ç›´æ¥è·å–
    if not selected_nodes:
        selected_nodes = [node for node in node_tree.nodes if node.select]
    
    # æ–¹æ³• 3: å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
    if not selected_nodes and hasattr(context, 'active_node') and context.active_node:
        selected_nodes = [context.active_node]
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰é€‰ä¸­èŠ‚ç‚¹ï¼Œè¿”å›é”™è¯¯
    if not selected_nodes:
        return "No selected or active nodes to analyze."

    result = {
        "node_tree_type": space.tree_type,
        "selected_nodes_count": len(selected_nodes),
        "selected_nodes": []
    }

    for node in selected_nodes:
        node_info = {
            "name": node.name,
            "name_localized": pgettext_iface(node.name),
            "label": node.label,
            "label_localized": pgettext_iface(node.label or node.name),
            "type": node.bl_idname,
            "location": (node.location.x, node.location.y),
            "width": node.width,
            "height": node.height,
            "color": node.color[:],
            "use_custom_color": node.use_custom_color,
            "inputs": [],
            "outputs": [],
        }

        # è§£æè¾“å…¥ç«¯å£
        for input_idx, input_socket in enumerate(node.inputs):
            input_info = {
                "name": input_socket.name,
                "name_localized": pgettext_iface(input_socket.name),
                "type": input_socket.type,
                "identifier": input_socket.identifier,
                "enabled": input_socket.enabled,
                "hide": input_socket.hide,
                "hide_value": input_socket.hide_value,
            }
            if hasattr(input_socket, 'default_value'):
                try:
                    val = input_socket.default_value
                    if isinstance(val, (int, float, str, bool)):
                        input_info["default_value"] = val
                    elif hasattr(val, '__len__') and len(val) <= 10:  # å¤„ç†å‘é‡ç­‰åºåˆ—
                        input_info["default_value"] = list(val)
                    else:
                        input_info["default_value"] = str(val)[:50] + "..." if len(str(val)) > 50 else str(val)
                except:
                    input_info["default_value"] = "N/A"

            # æ£€æŸ¥è¾“å…¥æ˜¯å¦è¿æ¥
            connected = False
            for link in node_tree.links:
                if link.to_socket == input_socket:
                    input_info["connected_from"] = {
                        "node": link.from_node.name,
                        "node_localized": pgettext_iface(link.from_node.name),
                        "socket": link.from_socket.name,
                        "socket_localized": pgettext_iface(link.from_socket.name)
                    }
                    connected = True
                    break
            input_info["is_connected"] = connected

            node_info["inputs"].append(input_info)

        # è§£æè¾“å‡ºç«¯å£
        for output_idx, output_socket in enumerate(node.outputs):
            output_info = {
                "name": output_socket.name,
                "name_localized": pgettext_iface(output_socket.name),
                "type": output_socket.type,
                "identifier": output_socket.identifier,
                "enabled": output_socket.enabled,
                "hide": output_socket.hide,
            }
            if hasattr(output_socket, 'default_value'):
                try:
                    val = output_socket.default_value
                    if isinstance(val, (int, float, str, bool)):
                        output_info["default_value"] = val
                    elif hasattr(val, '__len__') and len(val) <= 10:  # å¤„ç†å‘é‡ç­‰åºåˆ—
                        output_info["default_value"] = list(val)
                    else:
                        output_info["default_value"] = str(val)[:50] + "..." if len(str(val)) > 50 else str(val)
                except:
                    output_info["default_value"] = "N/A"

            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦è¿æ¥
            connected = False
            output_info["connected_to"] = []
            for link in node_tree.links:
                if link.from_socket == output_socket:
                    output_info["connected_to"].append({
                        "node": link.to_node.name,
                        "node_localized": pgettext_iface(link.to_node.name),
                        "socket": link.to_socket.name,
                        "socket_localized": pgettext_iface(link.to_socket.name)
                    })
                    connected = True
            output_info["is_connected"] = connected

            node_info["outputs"].append(output_info)

        # å¦‚æœæ˜¯èŠ‚ç‚¹ç»„ï¼Œé€’å½’è§£æå…¶å†…å®¹
        if node.type == 'GROUP' and node.node_tree:
            node_info["group_content"] = parse_node_tree_recursive(node.node_tree)

        result["selected_nodes"].append(node_info)

    # æ·»åŠ è¿æ¥ä¿¡æ¯
    if hasattr(node_tree, 'links'):
        connections = []
        for link in node_tree.links:
            if link.from_node in selected_nodes or link.to_node in selected_nodes:
                connection_info = {
                    "from_node": link.from_node.name,
                    "from_node_localized": pgettext_iface(link.from_node.name),
                    "from_socket": link.from_socket.name,
                    "from_socket_localized": pgettext_iface(link.from_socket.name),
                    "to_node": link.to_node.name,
                    "to_node_localized": pgettext_iface(link.to_node.name),
                    "to_socket": link.to_socket.name,
                    "to_socket_localized": pgettext_iface(link.to_socket.name),
                }
                connections.append(connection_info)
        result["connections"] = connections

    return json.dumps(result, indent=2)

# é€‰ä¸­çš„æ–‡æœ¬éƒ¨åˆ†é¡¹
class SelectedTextPartItem(bpy.types.PropertyGroup):
    part_name: bpy.props.StringProperty(name="Part Name", default="")

# AIèŠ‚ç‚¹åˆ†æå™¨è®¾ç½®
class AINodeAnalyzerSettings(PropertyGroup):
    """æ’ä»¶è®¾ç½®å±æ€§ç»„"""

    # åç«¯æœåŠ¡å™¨è®¾ç½®
    enable_backend: BoolProperty(
        name="å¯ç”¨åç«¯",
        description="å¯ç”¨åç«¯æœåŠ¡å™¨ä»¥æ”¯æŒæµè§ˆå™¨é€šä¿¡",
        default=False
    )

    backend_port: IntProperty(
        name="åç«¯ç«¯å£",
        description="åç«¯æœåŠ¡å™¨ç›‘å¬ç«¯å£",
        default=5000,
        min=1024,
        max=65535
    )

    # AIæœåŠ¡å•†é€‰æ‹©
    ai_provider: EnumProperty(
        name="AIæœåŠ¡æä¾›å•†",
        description="é€‰æ‹©AIæœåŠ¡æä¾›å•†",
        items=[
            ('DEEPSEEK', "DeepSeek", "DeepSeek"),
            ('OLLAMA', "Ollama", "Ollama"),
            ('BIGMODEL', "BigModel", "BigModel (æ™ºè°±AI)")
        ],
        default='DEEPSEEK',
        update=_on_provider_update
    )

    # DeepSeekè®¾ç½®
    deepseek_api_key: StringProperty(
        name="DeepSeek APIå¯†é’¥",
        description="DeepSeek APIå¯†é’¥ç”¨äºæ¨¡å‹è®¿é—®",
        subtype='PASSWORD',
        default=""
    )

    deepseek_url: StringProperty(
        name="DeepSeekæœåŠ¡åœ°å€",
        description="DeepSeekæœåŠ¡çš„URLåœ°å€",
        default="https://api.deepseek.com",
        maxlen=2048
    )

    deepseek_model: StringProperty(
        name="DeepSeekæ¨¡å‹",
        description="DeepSeekæ¨¡å‹åç§° (ä¾‹å¦‚: deepseek-reasoner, deepseek-chat)",
        default="deepseek-chat",
        maxlen=256,
        update=_on_model_update
    )

    # é€šç”¨æœåŠ¡é…ç½®
    generic_base_url: StringProperty(
        name="æœåŠ¡åœ°å€",
        description="å½“å‰æœåŠ¡å•†çš„Base URL",
        default="",
        maxlen=2048
    )
    generic_api_key: StringProperty(
        name="APIå¯†é’¥",
        description="å½“å‰æœåŠ¡å•†çš„APIå¯†é’¥",
        subtype='PASSWORD',
        default=""
    )
    generic_model: StringProperty(
        name="æ¨¡å‹",
        description="å½“å‰æœåŠ¡å•†çš„æ¨¡å‹åç§°",
        default="",
        maxlen=256,
        update=_on_model_update
    )

    # Ollamaè®¾ç½®
    ollama_url: StringProperty(
        name="OllamaæœåŠ¡åœ°å€",
        description="OllamaæœåŠ¡çš„URLåœ°å€",
        default="http://localhost:11434",
        maxlen=2048
    )

    ollama_model: StringProperty(
        name="Ollamaæ¨¡å‹",
        description="Ollamaæ¨¡å‹åç§° (ä¾‹å¦‚: llama2, mistral)",
        default="llama2",
        maxlen=256,
        update=_on_model_update
    )

    # BigModelè®¾ç½®
    bigmodel_api_key: StringProperty(
        name="BigModel APIå¯†é’¥",
        description="BigModel (æ™ºè°±AI) APIå¯†é’¥ç”¨äºæ¨¡å‹è®¿é—®",
        subtype='PASSWORD',
        default=""
    )

    bigmodel_url: StringProperty(
        name="BigModelæœåŠ¡åœ°å€",
        description="BigModelæœåŠ¡çš„URLåœ°å€",
        default="https://open.bigmodel.cn/api/paas/v4",
        maxlen=2048
    )

    bigmodel_model: StringProperty(
        name="BigModelæ¨¡å‹",
        description="BigModelæ¨¡å‹åç§° (ä¾‹å¦‚: glm-4, glm-4-flash)",
        default="glm-4",
        maxlen=256,
        update=_on_model_update
    )

    # ç³»ç»Ÿæç¤º
    system_prompt: StringProperty(
        name="ç³»ç»Ÿæç¤º",
        description="AIåŠ©æ‰‹çš„ç³»ç»Ÿæç¤ºä¿¡æ¯",
        default="æ‚¨æ˜¯BlenderèŠ‚ç‚¹çš„ä¸“å®¶ã€‚åˆ†æä»¥ä¸‹èŠ‚ç‚¹ç»“æ„å¹¶æä¾›è§è§£ã€ä¼˜åŒ–æˆ–è§£é‡Šã€‚",
        maxlen=2048
    )


    status_connectivity: StringProperty(name="è¿é€šæ€§", default="æœªçŸ¥")
    status_networking: StringProperty(name="è”ç½‘", default="æœªçŸ¥")
    status_thinking: StringProperty(name="æ€è€ƒ", default="æœªçŸ¥")
    status_model_fetch: StringProperty(name="æ¨¡å‹è·å–", default="æœªçŸ¥")

    # AIå‚æ•°è®¾ç½®
    temperature: FloatProperty(
        name="æ¸©åº¦",
        description="AIå“åº”çš„éšæœºæ€§ (0.0 - 2.0)",
        default=0.7,
        min=0.0,
        max=2.0,
        update=_on_temperature_update
    )

    top_p: FloatProperty(
        name="Top P",
        description="æ ¸é‡‡æ ·é˜ˆå€¼ (0.0 - 1.0)",
        default=1.0,
        min=0.0,
        max=1.0,
        update=_on_top_p_update
    )

    # è®°å¿†åŠŸèƒ½ç›¸å…³è®¾ç½®
    enable_memory: BoolProperty(
        name="å¯ç”¨è®°å¿†",
        description="å¯ç”¨å¯¹è¯è®°å¿†åŠŸèƒ½",
        default=True
    )

    memory_target_k: IntProperty(
        name="è®°å¿†ç›®æ ‡",
        description="è®°å¿†ç›®æ ‡å€¼",
        default=4,
        min=1,
        max=128
    )

    # æ–°å¢å¯¹è¯åŠŸèƒ½ç›¸å…³å±æ€§
    conversation_history: StringProperty(
        name="å¯¹è¯å†å²",
        description="å†…éƒ¨å­˜å‚¨çš„å¯¹è¯å†å²è®°å½•",
        default="",
        maxlen=65536  # å¢åŠ å®¹é‡ä»¥å­˜å‚¨å¤šè½®å¯¹è¯
    )

    # ç”¨æˆ·è¾“å…¥æ–‡æœ¬
    user_input: StringProperty(
        name="æ‚¨çš„é—®é¢˜",
        description="è¾“å…¥å…³äºèŠ‚ç‚¹çš„é—®é¢˜",
        default="",
        maxlen=2048
    )

    # æ˜¾ç¤ºç»™AIçš„æç¤ºå†…å®¹
    preview_content: StringProperty(
        name="é¢„è§ˆå†…å®¹",
        description="å°†è¦å‘é€ç»™AIçš„å†…å®¹é¢„è§ˆ",
        default="",
        maxlen=65536
    )

    # å½“å‰çŠ¶æ€
    current_status: StringProperty(
        name="å½“å‰çŠ¶æ€",
        description="æ’ä»¶å½“å‰è¿è¡ŒçŠ¶æ€",
        default="å°±ç»ª"
    )

    # é»˜è®¤é—®é¢˜
    default_question: StringProperty(
        name="é»˜è®¤é—®é¢˜",
        description="é»˜è®¤çš„èŠ‚ç‚¹åˆ†æé—®é¢˜",
        default="è¯·åˆ†æè¿™äº›èŠ‚ç‚¹çš„åŠŸèƒ½å’Œä¼˜åŒ–å»ºè®®"
    )

    # å›ç­”è¯¦ç»†ç¨‹åº¦è®¾ç½®
    output_detail_level: EnumProperty(
        name="å›ç­”è¯¦ç»†ç¨‹åº¦",
        description="æ§åˆ¶AIå›ç­”çš„è¯¦ç»†ç¨‹åº¦æç¤º",
        items=[
            ('simple', "ç®€çº¦", "ç®€è¦è¯´æ˜ï¼Œä¸éœ€è¦markdownæ ¼å¼"),
            ('medium', "é€‚ä¸­", "æŒ‰å¸¸è§„æ–¹å¼å›ç­”ï¼Œä½¿ç”¨é€‚å½“çš„markdownæ ¼å¼"),
            ('detailed', "è¯¦ç»†", "è¯¦ç»†è¯´æ˜ï¼Œä½¿ç”¨å›¾è¡¨ã€åˆ—è¡¨ã€ä»£ç å—ç­‰markdownæ ¼å¼")
        ],
        default='medium'
    )
    prompt_simple: StringProperty(
        name="ç®€çº¦æç¤º",
        description="ç”¨äºç®€çº¦è¾“å‡ºçš„æç¤ºæŒ‡ä»¤",
        default="è¯·ç®€è¦è¯´æ˜ï¼Œä¸éœ€è¦ä½¿ç”¨markdownæ ¼å¼ï¼Œç®€å•æè¿°å³å¯ã€‚"
    )
    prompt_medium: StringProperty(
        name="é€‚ä¸­æç¤º",
        description="ç”¨äºé€‚ä¸­è¾“å‡ºçš„æç¤ºæŒ‡ä»¤",
        default="è¯·æŒ‰å¸¸è§„æ–¹å¼å›ç­”ï¼Œä½¿ç”¨é€‚å½“çš„markdownæ ¼å¼æ¥ç»„ç»‡å†…å®¹ã€‚"
    )
    prompt_detailed: StringProperty(
        name="è¯¦ç»†æç¤º",
        description="ç”¨äºè¯¦ç»†è¾“å‡ºçš„æç¤ºæŒ‡ä»¤",
        default="è¯·è¯¦ç»†è¯´æ˜ï¼Œä½¿ç”¨å›¾è¡¨ã€åˆ—è¡¨ã€ä»£ç å—ç­‰markdownæ ¼å¼æ¥æ¸…æ™°åœ°è¡¨è¾¾å†…å®¹ã€‚"
    )

    # èŠ‚ç‚¹ç²¾ç»†åº¦è®¾ç½®ï¼ˆæ•°å­—æŒ¡ä½ï¼‰
    node_detail_level: IntProperty(
        name="èŠ‚ç‚¹ç²¾ç»†åº¦",
        description="æ§åˆ¶å‘é€ç»™AIçš„èŠ‚ç‚¹ä¿¡æ¯è¯¦å°½ç¨‹åº¦",
        default=2,
        min=0,
        max=3,
        update=lambda self, context: setattr(self, 'filter_level',
            ['ULTRA_LITE', 'LITE', 'STANDARD', 'FULL'][self.node_detail_level])
    )

    # å›ç­”ç²¾ç»†åº¦è®¾ç½®ï¼ˆæ•°å­—æŒ¡ä½ï¼‰
    response_detail_level: IntProperty(
        name="å›ç­”ç²¾ç»†åº¦",
        description="æ§åˆ¶AIå›ç­”çš„è¯¦ç»†ç¨‹åº¦",
        default=1,
        min=0,
        max=2,
        update=lambda self, context: setattr(self, 'output_detail_level',
            ['simple', 'medium', 'detailed'][self.response_detail_level])
    )

    md_clean_target_text: EnumProperty(
        name="ç›®æ ‡æ–‡æœ¬",
        description="é€‰æ‹©è¦æ¸…ç†/æ¢å¤çš„æ–‡æœ¬æ•°æ®å—",
        items=get_text_items
    )
    identity_key: EnumProperty(
        name="èº«ä»½",
        description="é€‰æ‹©AIèº«ä»½é¢„è®¾",
        items=get_identity_items,
        update=_on_identity_update
    )
    identity_text: StringProperty(
        name="èº«ä»½æ–‡æœ¬",
        description="å½“å‰èº«ä»½å¯¹åº”çš„ç³»ç»Ÿæç¤ºæ–‡æœ¬",
        default="",
        maxlen=4096
    )
    default_question_preset: EnumProperty(
        name="é¢„è®¾é—®é¢˜",
        description="é€‰æ‹©é»˜è®¤é—®é¢˜é¢„è®¾ä»¥å¡«å……è¾“å…¥æ¡†",
        items=get_default_question_items,
        update=_on_default_question_preset_update
    )
    filter_level: EnumProperty(
        name="èŠ‚ç‚¹è¿‡æ»¤çº§åˆ«",
        description="æ§åˆ¶å‘é€ç»™AIçš„èŠ‚ç‚¹ä¿¡æ¯è¯¦å°½ç¨‹åº¦",
        items=[
            ('ULTRA_LITE', "æç®€", "ä»…æœ€å°æ ‡è¯†"),
            ('LITE', "ç®€åŒ–", "ä¿ç•™å¿…è¦çš„IO"),
            ('STANDARD', "å¸¸è§„", "æ¸…é™¤å¯è§†å±æ€§"),
            ('FULL', "å®Œæ•´", "å®Œæ•´ä¸Šä¸‹æ–‡")
        ],
        default='STANDARD'
    )
    enable_thinking: BoolProperty(
        name="æ·±åº¦æ€è€ƒ",
        description="å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼",
        default=False
    )
    enable_web: BoolProperty(
        name="è”ç½‘",
        description="å…è®¸è”ç½‘æ£€ç´¢",
        default=False
    )
    current_model: StringProperty(
        name="å½“å‰æ¨¡å‹",
        description="å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°",
        default="",
        maxlen=256
    )

    # å½“å‰å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models: EnumProperty(
        name="æ¨¡å‹",
        description="å½“å‰å¯ç”¨çš„AIæ¨¡å‹",
        items=get_model_items,
        update=lambda self, context: _on_model_change_update(self)
    )

    # å±•å¼€/æŠ˜å è®¾ç½®é¢æ¿
    show_settings_expanded: BoolProperty(
        name="æ˜¾ç¤ºè®¾ç½®å±•å¼€",
        description="æ§åˆ¶è®¾ç½®é¢æ¿æ˜¯å¦å±•å¼€",
        default=False
    )

    # ç®€åŒ–æ¨¡å¼
    simplified_ui: BoolProperty(
        name="ç®€åŒ–UI",
        description="ç®€åŒ–UIæ˜¾ç¤ºï¼Œåªä¿ç•™é—®é¢˜è¾“å…¥æ¡†å’Œå‘é€æŒ‰é’®",
        default=False
    )

    # æç¤ºä¿¡æ¯ç›¸å…³
    show_help_text: BoolProperty(
        name="æ˜¾ç¤ºå¸®åŠ©æç¤º",
        description="æ˜¾ç¤ºåŠŸèƒ½å¸®åŠ©æç¤ºä¿¡æ¯",
        default=True
    )

    # å¿«é€Ÿå¤åˆ¶ç›¸å…³ - æ”¯æŒå¤šé€‰
    selected_text_parts: CollectionProperty(
        type=SelectedTextPartItem,
        name="é€‰ä¸­çš„æ–‡æœ¬éƒ¨åˆ†",
        description="å½“å‰é€‰ä¸­çš„æ–‡æœ¬éƒ¨åˆ†é›†åˆ"
    )

    # åˆ†ææ¡†æ¶ç›¸å…³ - è®°å½•èŠ‚ç‚¹åç§°
    analysis_frame_node_names: StringProperty(
        name="åˆ†ææ¡†æ¶èŠ‚ç‚¹åç§°",
        description="è®°å½•åˆ†ææ¡†æ¶ä¸­åŒ…å«çš„èŠ‚ç‚¹åç§°ï¼Œç”¨é€—å·åˆ†éš”",
        default=""
    )

    # å½“å‰é€‰ä¸­çš„tabé¢æ¿
    current_tab: EnumProperty(
        name="å½“å‰Tab",
        description="å½“å‰é€‰ä¸­çš„è®¾ç½®tab",
        items=[
            ('IDENTITY', "èº«ä»½", "èº«ä»½é¢„è®¾è®¾ç½®"),
            ('PROMPTS', "æç¤ºè¯", "é»˜è®¤æç¤ºè¯è®¾ç½®"),
            ('DETAIL', "ç²¾ç»†åº¦æ§åˆ¶", "å›ç­”ç²¾ç»†åº¦æ§åˆ¶è®¾ç½®")
        ],
        default='IDENTITY'
    )

    # AIé—®ç­”çŠ¶æ€ç®¡ç†
    ai_question_status: EnumProperty(
        name="AIé—®ç­”çŠ¶æ€",
        description="AIé—®ç­”çš„å½“å‰çŠ¶æ€",
        items=[
            ('IDLE', "ç©ºé—²", "ç­‰å¾…ç”¨æˆ·æé—®"),
            ('PROCESSING', "å¤„ç†ä¸­", "AIæ­£åœ¨å¤„ç†é—®é¢˜"),
            ('STOPPED', "å·²åœæ­¢", "å›ç­”å·²è¢«ç”¨æˆ·åœæ­¢"),
            ('ERROR', "é”™è¯¯", "å‘ç”Ÿé”™è¯¯")
        ],
        default='IDLE'
    )

    # æ˜¯å¦å…è®¸ç»ˆæ­¢å½“å‰è¯·æ±‚
    can_terminate_request: BoolProperty(
        name="å¯ç»ˆæ­¢è¯·æ±‚",
        description="æ˜¯å¦å¯ä»¥ç»ˆæ­¢å½“å‰è¯·æ±‚",
        default=False
    )

class NODE_OT_load_config_from_file(bpy.types.Operator):
    bl_idname = "node.load_config_from_file"
    bl_label = "ä»æ–‡ä»¶åŠ è½½é…ç½®"
    bl_description = "ä»config.jsonåŠ è½½é…ç½®"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        config_path = os.path.join(os.path.dirname(__file__), 'config.json')
        
        if not os.path.exists(config_path):
            self.report({'WARNING'}, "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            return {'CANCELLED'}
            
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
            # Update Blender settings
            if 'port' in config:
                ain_settings.backend_port = config['port']

            if 'ai' in config:
                ai = config['ai']

                # å¤„ç†æ–°çš„providerç»“æ„
                if 'provider' in ai:
                    provider_info = ai['provider']
                    if isinstance(provider_info, dict):
                        if 'name' in provider_info:
                            ain_settings.ai_provider = provider_info['name']
                        if 'model' in provider_info:
                            # æ ¹æ®æä¾›å•†ç±»å‹è®¾ç½®ç›¸åº”çš„æ¨¡å‹
                            # ä½¿ç”¨setattrç»•è¿‡æšä¸¾éªŒè¯
                            if provider_info['name'] == 'DEEPSEEK':
                                setattr(ain_settings, 'deepseek_model', provider_info['model'])
                            elif provider_info['name'] == 'OLLAMA':
                                setattr(ain_settings, 'ollama_model', provider_info['model'])
                            else:
                                setattr(ain_settings, 'generic_model', provider_info['model'])
                    else:
                        # å…¼å®¹æ—§æ ¼å¼
                        ain_settings.ai_provider = ai['provider']

                # åŠ è½½æ¨¡å‹åˆ—è¡¨åˆ°ç¼“å­˜
                if 'deepseek' in ai and 'models' in ai['deepseek']:
                    global deepseek_models_cache
                    deepseek_models_cache[:] = ai['deepseek']['models']
                if 'ollama' in ai and 'models' in ai['ollama']:
                    global ollama_models_cache
                    ollama_models_cache[:] = ai['ollama']['models']
                if 'generic' in ai and 'models' in ai['generic']:
                    global generic_models_cache
                    generic_models_cache[:] = ai['generic']['models']

                # ç¡®ä¿URLå’ŒAPIå¯†é’¥æ­£ç¡®åŠ è½½
                if 'deepseek' in ai:
                    ds = ai['deepseek']
                    if 'url' in ds:
                        ain_settings.deepseek_url = ds['url']
                    if 'api_key' in ds:
                        ain_settings.deepseek_api_key = ds['api_key']
                if 'ollama' in ai:
                    ol = ai['ollama']
                    if 'url' in ol:
                        ain_settings.ollama_url = ol['url']

                # provider configs cache (ä¸ºäº†å…¼å®¹æ€§ä¿ç•™)
                pconfs = ai.get('provider_configs', {})
                if isinstance(pconfs, dict):
                    provider_configs_cache.clear()
                    provider_configs_cache.update(pconfs)
                    
                    # ä»provider_configsåŠ è½½BigModelé…ç½®ï¼ˆå¦‚æœai.bigmodelä¸­æ²¡æœ‰ï¼‰
                    if 'BIGMODEL' in pconfs and isinstance(pconfs['BIGMODEL'], dict):
                        bm_pcfg = pconfs['BIGMODEL']
                        if 'bigmodel' not in ai or not isinstance(ai['bigmodel'], dict):
                            ai['bigmodel'] = {}
                        bm = ai['bigmodel']
                        if 'base_url' in bm_pcfg and not bm.get('url'):
                            bm['url'] = bm_pcfg['base_url']
                        if 'api_key' in bm_pcfg and not bm.get('api_key'):
                            bm['api_key'] = bm_pcfg['api_key']
                        if 'models' in bm_pcfg and not bm.get('models'):
                            bm['models'] = bm_pcfg['models']

                if 'deepseek' in ai:
                    ds = ai['deepseek']
                    if 'api_key' in ds: ain_settings.deepseek_api_key = ds['api_key']
                    if 'url' in ds: ain_settings.deepseek_url = ds['url']  # ç¡®ä¿URLä¹Ÿè¢«è®¾ç½®
                    # å¦‚æœåœ¨providerä¸­æ²¡æœ‰è®¾ç½®æ¨¡å‹ï¼Œåˆ™ä»deepseekéƒ¨åˆ†è·å–
                    if 'model' in ds and not (hasattr(ain_settings, 'deepseek_model') and ain_settings.deepseek_model):
                        setattr(ain_settings, 'deepseek_model', ds['model'])

                if 'ollama' in ai:
                    ol = ai['ollama']
                    if 'url' in ol: ain_settings.ollama_url = ol['url']
                    # å¦‚æœåœ¨providerä¸­æ²¡æœ‰è®¾ç½®æ¨¡å‹ï¼Œåˆ™ä»ollamaéƒ¨åˆ†è·å–
                    if 'model' in ol and not (hasattr(ain_settings, 'ollama_model') and ain_settings.ollama_model):
                        setattr(ain_settings, 'ollama_model', ol['model'])

                # åŠ è½½BigModelé…ç½®
                if 'bigmodel' in ai:
                    bm = ai['bigmodel']
                    if 'url' in bm:
                        ain_settings.bigmodel_url = bm['url']
                    if 'api_key' in bm:
                        ain_settings.bigmodel_api_key = bm['api_key']
                    if 'model' in bm:
                        setattr(ain_settings, 'bigmodel_model', bm['model'])
                    if 'models' in bm:
                        global bigmodel_models_cache
                        bigmodel_models_cache[:] = bm['models']

                if 'system_prompt' in ai: ain_settings.system_prompt = ai['system_prompt']
                if 'temperature' in ai: ain_settings.temperature = ai['temperature']
                if 'top_p' in ai: ain_settings.top_p = ai['top_p']

                # populate generic fields for current provider
                sel = ain_settings.ai_provider
                pcfg = pconfs.get(sel, {}) if isinstance(pconfs, dict) else {}
                ain_settings.generic_base_url = pcfg.get('base_url', "")
                ain_settings.generic_api_key = pcfg.get('api_key', "")
                if sel not in ('DEEPSEEK', 'OLLAMA'):
                    ain_settings.generic_model = (pcfg.get('default_model') or "")
            
            if 'system_message_presets' in config and isinstance(config['system_message_presets'], list):
                system_message_presets_cache.clear()
                system_message_presets_cache.extend(config['system_message_presets'])
                chosen = None
                for idx, it in enumerate(system_message_presets_cache):
                    if it.get('value') == ain_settings.system_prompt:
                        chosen = f"preset_{idx}"
                        break
                # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„é¢„è®¾ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ï¼Œå¦‚æœå­˜åœ¨é¢„è®¾åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼Œå¦åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
                if chosen:
                    ain_settings.identity_key = chosen
                elif system_message_presets_cache:
                    ain_settings.identity_key = "preset_0"
                else:
                    ain_settings.identity_key = ""

                # æ›´æ–°èº«ä»½æ–‡æœ¬
                if (ain_settings.identity_key and
                    ain_settings.identity_key.startswith("preset_") and
                    system_message_presets_cache):
                    try:
                        idx = int(ain_settings.identity_key.split("_")[1])
                        if 0 <= idx < len(system_message_presets_cache):
                            ain_settings.identity_text = system_message_presets_cache[idx].get('value', '')
                    except (ValueError, IndexError):
                        # å¦‚æœè§£æç´¢å¼•å¤±è´¥ï¼Œå°è¯•åŒ¹é…å½“å‰ç³»ç»Ÿæç¤º
                        for idx, it in enumerate(system_message_presets_cache):
                            if it.get('value') == ain_settings.system_prompt:
                                ain_settings.identity_key = f"preset_{idx}"
                                ain_settings.identity_text = it.get('value', '')
                                break

            if 'default_questions' in config and config['default_questions']:
                ain_settings.default_question = config['default_questions'][0]
            if 'default_question_presets' in config and isinstance(config['default_question_presets'], list):
                default_question_presets_cache.clear()
                default_question_presets_cache.extend(config['default_question_presets'])
                if default_question_presets_cache:
                    ain_settings.default_question_preset = "q_0"
            # å›ç­”è¯¦ç»†ç¨‹åº¦æç¤ºè¯»å–ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ output_detail_presetsï¼‰
            odp = config.get('output_detail_presets', {})
            if isinstance(odp, dict):
                ain_settings.prompt_simple = odp.get('simple', ain_settings.prompt_simple)
                ain_settings.prompt_medium = odp.get('medium', ain_settings.prompt_medium)
                ain_settings.prompt_detailed = odp.get('detailed', ain_settings.prompt_detailed)
            lvl = config.get('output_detail_level')
            if isinstance(lvl, str) and lvl in ('simple','medium','detailed'):
                ain_settings.output_detail_level = lvl
                # å°†output_detail_levelæ˜ å°„åˆ°response_detail_level
                level_mapping = {
                    'simple': 0,
                    'medium': 1,
                    'detailed': 2
                }
                ain_settings.response_detail_level = level_mapping.get(lvl, 1)  # é»˜è®¤ä¸º medium (1)

            # è®°å¿†åŠŸèƒ½è®¾ç½®
            if 'ai' in config:
                ai = config['ai']
                if 'memory' in ai:
                    memory = ai['memory']
                    if 'enabled' in memory:
                        ain_settings.enable_memory = memory['enabled']
                    if 'target_k' in memory:
                        ain_settings.memory_target_k = memory['target_k']
            
            # é…ç½®åŠ è½½å®Œæˆåï¼Œè®¾ç½®available_modelsä¸ºå½“å‰æä¾›å•†çš„æ¨¡å‹
            # ä½¿ç”¨setattrç»•è¿‡æšä¸¾éªŒè¯
            if ain_settings.ai_provider == 'DEEPSEEK':
                setattr(ain_settings, 'available_models', ain_settings.deepseek_model)
            elif ain_settings.ai_provider == 'OLLAMA':
                setattr(ain_settings, 'available_models', ain_settings.ollama_model)
            elif ain_settings.ai_provider == 'BIGMODEL':
                setattr(ain_settings, 'available_models', ain_settings.bigmodel_model)
            else:
                setattr(ain_settings, 'available_models', ain_settings.generic_model)

            self.report({'INFO'}, "é…ç½®å·²ä»æ–‡ä»¶åŠ è½½")
        except Exception as e:
            self.report({'ERROR'}, f"åŠ è½½é…ç½®å¤±è´¥: {e}")

        # è§¦å‘UIæ›´æ–°
        for window in context.window_manager.windows:
            for area in window.screen.areas:
                if area.type == 'NODE_EDITOR':
                    for region in area.regions:
                        if region.type == 'UI':
                            region.tag_redraw()
                            break
                    break

        return {'FINISHED'}

class NODE_OT_save_config_to_file(bpy.types.Operator):
    bl_idname = "node.save_config_to_file"
    bl_label = "ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"
    bl_description = "ä¿å­˜å½“å‰é…ç½®åˆ°config.json"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        config_path = os.path.join(os.path.dirname(__file__), 'config.json')
        
        try:
            # Read existing to preserve other fields
            existing_config = {}
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    existing_config = json.load(f)
            
            # Update Port
            existing_config['port'] = ain_settings.backend_port

            # Update AI section
            if 'ai' not in existing_config: existing_config['ai'] = {}
            ai = existing_config['ai']

            # ä½¿ç”¨æ–°çš„providerç»“æ„
            ai['provider'] = {
                'name': ain_settings.ai_provider,
                'model': ''
            }

            # æ ¹æ®å½“å‰æä¾›å•†è®¾ç½®æ¨¡å‹
            if ain_settings.ai_provider == 'DEEPSEEK':
                ai['provider']['model'] = ain_settings.deepseek_model
            elif ain_settings.ai_provider == 'OLLAMA':
                ai['provider']['model'] = ain_settings.ollama_model
            elif ain_settings.ai_provider == 'BIGMODEL':
                ai['provider']['model'] = ain_settings.bigmodel_model
            else:
                ai['provider']['model'] = ain_settings.generic_model

            if 'deepseek' not in ai: ai['deepseek'] = {}
            ai['deepseek']['api_key'] = ain_settings.deepseek_api_key
            ai['deepseek']['model'] = ain_settings.deepseek_model
            ai['deepseek']['url'] = ain_settings.deepseek_url

            if 'ollama' not in ai: ai['ollama'] = {}
            ai['ollama']['url'] = ain_settings.ollama_url
            ai['ollama']['model'] = ain_settings.ollama_model

            if 'bigmodel' not in ai: ai['bigmodel'] = {}
            ai['bigmodel']['api_key'] = ain_settings.bigmodel_api_key
            ai['bigmodel']['model'] = ain_settings.bigmodel_model
            ai['bigmodel']['url'] = ain_settings.bigmodel_url
            if bigmodel_models_cache:
                ai['bigmodel']['models'] = bigmodel_models_cache[:]
            
            ai['system_prompt'] = ain_settings.system_prompt
            ai['temperature'] = ain_settings.temperature
            ai['top_p'] = ain_settings.top_p
            # provider_configs writeback
            if 'provider_configs' not in ai: ai['provider_configs'] = {}
            sel = ain_settings.ai_provider
            pcfg = ai['provider_configs'].get(sel, {})
            
            # æ ¹æ®æä¾›å•†ç±»å‹è®¾ç½®ç›¸åº”çš„é…ç½®
            if sel == 'DEEPSEEK':
                pcfg['base_url'] = ain_settings.deepseek_url
                pcfg['api_key'] = ain_settings.deepseek_api_key
                if deepseek_models_cache:
                    pcfg['models'] = deepseek_models_cache[:]
            elif sel == 'OLLAMA':
                pcfg['base_url'] = ain_settings.ollama_url
                pcfg['api_key'] = ain_settings.generic_api_key  # Ollamaé€šå¸¸ä¸éœ€è¦APIå¯†é’¥
                if ollama_models_cache:
                    pcfg['models'] = ollama_models_cache[:]
            elif sel == 'BIGMODEL':
                pcfg['base_url'] = ain_settings.bigmodel_url
                pcfg['api_key'] = ain_settings.bigmodel_api_key
                if bigmodel_models_cache:
                    pcfg['models'] = bigmodel_models_cache[:]
            else:
                # å¯¹äºå…¶ä»–æä¾›å•†ï¼Œä½¿ç”¨genericå­—æ®µ
                pcfg['base_url'] = ain_settings.generic_base_url
                pcfg['api_key'] = ain_settings.generic_api_key
                if 'models' not in pcfg: pcfg['models'] = []
                dm = (ain_settings.generic_model or "").strip()
                if dm and dm not in pcfg['models']:
                    pcfg['models'].insert(0, dm)
                pcfg['default_model'] = dm
            ai['provider_configs'][sel] = pcfg

            # è®°å¿†åŠŸèƒ½è®¾ç½®
            if 'memory' not in ai: ai['memory'] = {}
            ai['memory']['enabled'] = ain_settings.enable_memory
            ai['memory']['target_k'] = ain_settings.memory_target_k
            
            # Update default questions (keep existing list but maybe update first one?)
            # Or just append? Let's just update the list if empty, or keep as is.
            # User might want to edit the list in the file manually.
            # But let's ensure the current default_question is in the list
            if 'default_questions' not in existing_config: existing_config['default_questions'] = []
            if ain_settings.default_question and ain_settings.default_question not in existing_config['default_questions']:
                existing_config['default_questions'].insert(0, ain_settings.default_question)

            # ä¿å­˜ç³»ç»Ÿæ¶ˆæ¯é¢„è®¾
            if 'system_message_presets' not in existing_config or not existing_config['system_message_presets']:
                # å¦‚æœé…ç½®ä¸­æ²¡æœ‰é¢„è®¾æˆ–ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨ç¼“å­˜ä¸­çš„å€¼
                existing_config['system_message_presets'] = system_message_presets_cache[:]

            # ä¿å­˜é»˜è®¤é—®é¢˜é¢„è®¾
            if 'default_question_presets' not in existing_config or not existing_config['default_question_presets']:
                # å¦‚æœé…ç½®ä¸­æ²¡æœ‰é¢„è®¾æˆ–ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨ç¼“å­˜ä¸­çš„å€¼
                existing_config['default_question_presets'] = default_question_presets_cache[:]

            # å›ç­”è¯¦ç»†ç¨‹åº¦æç¤ºå†™å›ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ output_detail_presetsï¼‰
            existing_config['output_detail_presets'] = {
                'simple': ain_settings.prompt_simple,
                'medium': ain_settings.prompt_medium,
                'detailed': ain_settings.prompt_detailed
            }
            existing_config['output_detail_level'] = ain_settings.output_detail_level

            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(existing_config, f, indent=4, ensure_ascii=False)

            self.report({'INFO'}, "é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶")
        except Exception as e:
            self.report({'ERROR'}, f"ä¿å­˜é…ç½®å¤±è´¥: {e}")

        # è§¦å‘UIæ›´æ–°
        for window in context.window_manager.windows:
            for area in window.screen.areas:
                if area.type == 'NODE_EDITOR':
                    for region in area.regions:
                        if region.type == 'UI':
                            region.tag_redraw()
                            break
                    break

        return {'FINISHED'}

# è®¾ç½®å¼¹çª—é¢æ¿
class AINodeAnalyzerSettingsPopup(bpy.types.Operator):
    bl_idname = "node.settings_popup"
    bl_label = "AIèŠ‚ç‚¹åˆ†æå™¨è®¾ç½®"
    bl_options = {'REGISTER', 'INTERNAL'}

    def execute(self, context):
        return {'FINISHED'}

    def invoke(self, context, event):
        wm = context.window_manager
        # åœ¨å±å¹•ä¸­å¤®æ‰“å¼€å¯¹è¯æ¡†è€Œä¸æ˜¯åœ¨é¼ æ ‡ä½ç½®
        return wm.invoke_props_dialog(self, width=600)

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # æ˜¾ç¤ºå½“å‰Blenderç‰ˆæœ¬å’ŒèŠ‚ç‚¹ç±»å‹ - æ¨ªå‘å¸ƒå±€
        info_row = layout.row(align=True)
        info_row.label(text=f"ç‰ˆæœ¬: {bpy.app.version_string}", icon='BLENDER')

        # ç¡®å®šå½“å‰èŠ‚ç‚¹ç±»å‹
        node_type = "æœªçŸ¥"
        if context.space_data and hasattr(context.space_data, 'tree_type'):
            tree_type = context.space_data.tree_type
            if tree_type == 'GeometryNodeTree':
                node_type = "å‡ ä½•èŠ‚ç‚¹"
            elif tree_type == 'ShaderNodeTree':
                node_type = "æè´¨èŠ‚ç‚¹"
            elif tree_type == 'CompositorNodeTree':
                node_type = "åˆæˆèŠ‚ç‚¹"
            elif tree_type == 'TextureNodeTree':
                node_type = "çº¹ç†èŠ‚ç‚¹"
            elif tree_type == 'WorldNodeTree':
                node_type = "ç¯å¢ƒèŠ‚ç‚¹"

        info_row.label(text=f"ç±»å‹: {node_type}")

        # æ˜¾ç¤ºå½“å‰æ¨¡å‹
        current_model = ""
        try:
            if ain_settings.ai_provider == 'DEEPSEEK':
                current_model = ain_settings.deepseek_model
            elif ain_settings.ai_provider == 'OLLAMA':
                current_model = ain_settings.ollama_model
            elif ain_settings.ai_provider == 'BIGMODEL':
                current_model = ain_settings.bigmodel_model
            else:
                current_model = ain_settings.generic_model
        except:
            current_model = "æœªçŸ¥"

        info_row.label(text=f"æ¨¡å‹: {current_model}")

        # AIæœåŠ¡æä¾›å•†è®¾ç½®
        provider_box = layout.box()
        provider_box.label(text="AIæœåŠ¡æä¾›å•†è®¾ç½®", icon='WORLD_DATA')
        provider_box.prop(ain_settings, "ai_provider")

        # åœ°å€å’Œå¯†é’¥è¡Œ
        addr_row = provider_box.row()
        # æ ¹æ®å½“å‰æä¾›å•†æ˜¾ç¤ºç›¸åº”çš„URLå­—æ®µ
        if ain_settings.ai_provider == 'DEEPSEEK':
            addr_row.prop(ain_settings, "deepseek_url", text="åœ°å€")
        elif ain_settings.ai_provider == 'OLLAMA':
            addr_row.prop(ain_settings, "ollama_url", text="åœ°å€")
        elif ain_settings.ai_provider == 'BIGMODEL':
            addr_row.prop(ain_settings, "bigmodel_url", text="åœ°å€")
        else:
            addr_row.prop(ain_settings, "generic_base_url", text="åœ°å€")
        addr_row.operator("node.reset_provider_url", text="", icon='LOOP_BACK')

        key_row = provider_box.row()
        # æ ¹æ®å½“å‰æä¾›å•†æ˜¾ç¤ºç›¸åº”çš„APIå¯†é’¥å­—æ®µ
        if ain_settings.ai_provider == 'DEEPSEEK':
            key_row.prop(ain_settings, "deepseek_api_key", text="å¯†é’¥")
        elif ain_settings.ai_provider == 'OLLAMA':
            # Ollamaé€šå¸¸ä¸éœ€è¦APIå¯†é’¥ï¼Œæ˜¾ç¤ºç©ºç™½æˆ–é€šç”¨å¯†é’¥å­—æ®µ
            key_row.prop(ain_settings, "generic_api_key", text="å¯†é’¥")  # Ollamaä¸€èˆ¬ä¸éœ€è¦APIå¯†é’¥
        elif ain_settings.ai_provider == 'BIGMODEL':
            key_row.prop(ain_settings, "bigmodel_api_key", text="å¯†é’¥")
        else:
            key_row.prop(ain_settings, "generic_api_key", text="å¯†é’¥")
        # æ·»åŠ æ¸…ç©ºå¯†é’¥æŒ‰é’®
        clear_key_op = key_row.operator("node.clear_api_key", text="", icon='X')

        # æ¨¡å‹è¡Œ - å·¦å³å¸ƒå±€
        model_row = provider_box.row()
        # åˆ›å»ºæ¨¡å‹é€‰æ‹©ä¸‹æ‹‰èœå•
        if ain_settings.ai_provider == 'DEEPSEEK':
            model_row.prop(ain_settings, "deepseek_model", text="æ¨¡å‹")
        elif ain_settings.ai_provider == 'OLLAMA':
            model_row.prop(ain_settings, "ollama_model", text="æ¨¡å‹")
        elif ain_settings.ai_provider == 'BIGMODEL':
            model_row.prop(ain_settings, "bigmodel_model", text="æ¨¡å‹")
        else:
            model_row.prop(ain_settings, "generic_model", text="æ¨¡å‹")
        # åˆ·æ–°æ¨¡å‹æŒ‰é’® - ä»…åœ¨åç«¯æœåŠ¡å™¨è¿è¡Œæ—¶å¯ç”¨
        if server_manager and server_manager.is_running:
            model_row.operator("node.refresh_models", text="", icon='FILE_REFRESH')
            # å¯¹äºBigModelï¼Œæ·»åŠ æµ‹è¯•æ¨¡å‹æŒ‰é’®
            if ain_settings.ai_provider == 'BIGMODEL':
                model_row.operator("node.test_bigmodel_model", text="", icon='CHECKMARK')
        else:
            # å½“æœåŠ¡å™¨æœªè¿è¡Œæ—¶ï¼Œæ˜¾ç¤ºä¸€ä¸ªæç¤ºæŒ‰é’®
            model_row.operator("node.refresh_models_disabled", text="", icon='FILE_REFRESH')

        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹åˆ—è¡¨
        try:
            models_cache = []
            if ain_settings.ai_provider == 'DEEPSEEK':
                models_cache = deepseek_models_cache
            elif ain_settings.ai_provider == 'OLLAMA':
                models_cache = ollama_models_cache
            elif ain_settings.ai_provider == 'BIGMODEL':
                models_cache = bigmodel_models_cache
            else:
                models_cache = generic_models_cache

            if models_cache:
                model_list_box = provider_box.box()
                model_list_box.label(text="å¯ç”¨æ¨¡å‹:", icon='LINENUMBERS_ON')
                for model in models_cache[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªæ¨¡å‹
                    row = model_list_box.row()
                    row.label(text=f"â€¢ {model}")
                    op = row.operator("node.select_model", text="é€‰æ‹©", icon='CHECKMARK')
                    op.model_name = model
                    op.provider = ain_settings.ai_provider
                if len(models_cache) > 10:
                    model_list_box.label(text=f"... è¿˜æœ‰ {len(models_cache) - 10} ä¸ªæ¨¡å‹")
        except:
            # å¦‚æœå‡ºç°é”™è¯¯ï¼Œè·³è¿‡æ¨¡å‹åˆ—è¡¨æ˜¾ç¤º
            pass

        # çŠ¶æ€ä¿¡æ¯å’Œæ£€æµ‹æŒ‰é’®
        status_row = provider_box.row()
        # æ£€æŸ¥åç«¯æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
        if server_manager and server_manager.is_running:
            # æ ¹æ®è¿é€šæ€§çŠ¶æ€è®¾ç½®é¢œè‰²
            if ain_settings.status_connectivity == "å¯ç”¨":
                status_row.label(text=f"è¿é€šæ€§: {ain_settings.status_connectivity}", icon='CHECKMARK')
            else:
                status_row.label(text=f"è¿é€šæ€§: {ain_settings.status_connectivity}", icon='CANCEL')
            status_row.operator("node.test_provider_status", text="æ£€æµ‹è¿é€šæ€§", icon='INFO')
        else:
            status_row.label(text="åç«¯æœªå¯åŠ¨", icon='CANCEL')
            status_row = provider_box.row()
            status_row.label(text="è¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨", icon='ERROR')
            status_row = provider_box.row()
            status_row.operator("node.test_provider_status_disabled", text="æ£€æµ‹è¿é€šæ€§", icon='INFO')

        # Tabé€‰æ‹©æ 
        tab_row = layout.row()
        tab_row.prop_enum(ain_settings, "current_tab", 'IDENTITY')
        tab_row.prop_enum(ain_settings, "current_tab", 'PROMPTS')
        tab_row.prop_enum(ain_settings, "current_tab", 'DETAIL')

        # æ ¹æ®å½“å‰é€‰ä¸­çš„tabæ˜¾ç¤ºç›¸åº”å†…å®¹
        if ain_settings.current_tab == 'IDENTITY':
            # èº«ä»½è®¾ç½®é¢æ¿
            identity_box = layout.box()
            identity_box.label(text="èº«ä»½è®¾ç½®", icon='TEXT')

            # èº«ä»½é¢„è®¾æ¿å—
            identity_subbox = identity_box.box()
            identity_subbox.prop(ain_settings, "identity_key", text="èº«ä»½é¢„è®¾")
            identity_subbox.prop(ain_settings, "system_prompt", text="ç³»ç»Ÿæç¤ºè¯")

        elif ain_settings.current_tab == 'PROMPTS':
            # æç¤ºè¯è®¾ç½®é¢æ¿
            prompt_box = layout.box()
            prompt_box.label(text="æç¤ºè¯è®¾ç½®", icon='TEXT')

            # é»˜è®¤æç¤ºè¯æ¿å—
            question_subbox = prompt_box.box()
            question_subbox.prop(ain_settings, "default_question_preset", text="é»˜è®¤æç¤ºè¯")
            question_subbox.prop(ain_settings, "default_question", text="è‡ªå®šä¹‰é—®é¢˜")

        elif ain_settings.current_tab == 'DETAIL':
            # ç²¾ç»†åº¦æ§åˆ¶é¢æ¿
            detail_box = layout.box()
            detail_box.label(text="ç²¾ç»†åº¦æ§åˆ¶", icon='TEXT')

            # å›ç­”ç²¾ç»†åº¦æ§åˆ¶æ¿å—
            detail_subbox = detail_box.box()
            detail_subbox.prop(ain_settings, "output_detail_level", text="å›ç­”ç²¾ç»†åº¦")

            # æ ¹æ®é€‰æ‹©çš„è¯¦ç»†ç¨‹åº¦æ˜¾ç¤ºå¯¹åº”çš„æç¤ºè¯
            if ain_settings.output_detail_level == 'simple':
                detail_subbox.prop(ain_settings, "prompt_simple", text="ç®€çº¦æç¤º")
            elif ain_settings.output_detail_level == 'medium':
                detail_subbox.prop(ain_settings, "prompt_medium", text="é€‚ä¸­æç¤º")
            elif ain_settings.output_detail_level == 'detailed':
                detail_subbox.prop(ain_settings, "prompt_detailed", text="è¯¦ç»†æç¤º")

        # è®°å¿†ä¸æ€è€ƒåŠŸèƒ½å§‹ç»ˆæ˜¾ç¤ºåœ¨ä¸‹æ–¹
        memory_box = layout.box()
        memory_box.label(text="è®°å¿†ä¸æ€è€ƒ", icon='MEMORY')
        row = memory_box.row()
        row.prop(ain_settings, "enable_memory")
        row.prop(ain_settings, "memory_target_k")
        row = memory_box.row()
        row.prop(ain_settings, "enable_thinking")
        row.prop(ain_settings, "enable_web")

        # åç«¯æœåŠ¡å™¨è®¾ç½®
        server_box = layout.box()
        server_box.label(text="åç«¯æœåŠ¡å™¨è®¾ç½®", icon='WORLD_DATA')
        server_row = server_box.row()
        # ä½¿ç”¨ä¸ä¸»é¢æ¿ç›¸åŒçš„æœåŠ¡å™¨æ§åˆ¶æŒ‰é’®
        try:
            server_row.operator("node.toggle_backend_server", text="å¯åŠ¨" if not (server_manager and server_manager.is_running) else "åœæ­¢", icon='PLAY' if not (server_manager and server_manager.is_running) else 'SNAP_FACE')
        except:
            server_row.operator("node.toggle_backend_server", text="å¯åŠ¨", icon='PLAY')
        server_row.prop(ain_settings, "backend_port", text="ç«¯å£")

        # é…ç½®æ–‡ä»¶æ§åˆ¶
        config_box = layout.box()
        config_box.label(text="é…ç½®ç®¡ç†", icon='FILE_TEXT')
        config_row = config_box.row()
        config_row.operator("node.load_config_from_file", text="é‡è½½é…ç½®", icon='FILE_REFRESH')
        config_row.operator("node.save_config_to_file", text="ä¿å­˜é…ç½®", icon='FILE_TICK')
        config_row.operator("node.reset_settings", text="é‡ç½®é»˜è®¤", icon='LOOP_BACK')


# åˆ‡æ¢åç«¯æœåŠ¡å™¨è¿ç®—ç¬¦
class NODE_OT_toggle_backend_server(bpy.types.Operator):
    bl_idname = "node.toggle_backend_server"
    bl_label = "åˆ‡æ¢åç«¯æœåŠ¡å™¨"
    bl_description = "å¯åŠ¨æˆ–åœæ­¢åç«¯æœåŠ¡å™¨"

    def execute(self, context):
        global server_manager
        ain_settings = context.scene.ainode_analyzer_settings

        if server_manager:
            if server_manager.is_running:
                # åœæ­¢æœåŠ¡å™¨
                server_manager.stop_server()
                ain_settings.current_status = "åç«¯å·²åœæ­¢"
                ain_settings.enable_backend = False  # æ›´æ–°è®¾ç½®ä»¥åæ˜ çŠ¶æ€
                self.report({'INFO'}, "åç«¯æœåŠ¡å™¨å·²åœæ­¢")
            else:
                # å¯åŠ¨æœåŠ¡å™¨
                port = ain_settings.backend_port
                success = server_manager.start_server(port)
                if success:
                    ain_settings.current_status = f"åç«¯å·²å¯åŠ¨ (ç«¯å£: {port})"
                    ain_settings.enable_backend = True  # æ›´æ–°è®¾ç½®ä»¥åæ˜ çŠ¶æ€
                    self.report({'INFO'}, f"åç«¯æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç«¯å£: {port}")
                else:
                    ain_settings.current_status = "åç«¯å¯åŠ¨å¤±è´¥"
                    self.report({'ERROR'}, "åç«¯æœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
        else:
            self.report({'ERROR'}, "åç«¯æœåŠ¡å™¨æœªåˆå§‹åŒ–")

        return {'FINISHED'}

# é€‰æ‹©æ¨¡å‹è¿ç®—ç¬¦
class NODE_OT_select_model(bpy.types.Operator):
    bl_idname = "node.select_model"
    bl_label = "é€‰æ‹©æ¨¡å‹"
    bl_description = "é€‰æ‹©æ­¤æ¨¡å‹ä½œä¸ºå½“å‰æ¨¡å‹"

    model_name: StringProperty()
    provider: StringProperty()

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        if self.provider == 'DEEPSEEK':
            ain_settings.deepseek_model = self.model_name
        elif self.provider == 'OLLAMA':
            ain_settings.ollama_model = self.model_name
        elif self.provider == 'BIGMODEL':
            ain_settings.bigmodel_model = self.model_name
        else:
            ain_settings.generic_model = self.model_name
        self.report({'INFO'}, f"å·²é€‰æ‹©æ¨¡å‹: {self.model_name}")
        return {'FINISHED'}

# å¤åˆ¶èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿è¿ç®—ç¬¦ï¼ˆæ ¹æ®æŒ‰é”®ä¿®é¥°ç¬¦å†³å®šè¡Œä¸ºï¼‰
class NODE_OT_copy_nodes_to_clipboard(bpy.types.Operator):
    bl_idname = "node.copy_nodes_to_clipboard"
    bl_label = "å¤åˆ¶èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿"
    bl_description = "å¤åˆ¶èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿ - ç‚¹å‡»å¤åˆ¶é€‰ä¸­èŠ‚ç‚¹ï¼ŒAlt+ç‚¹å‡»å¤åˆ¶å…¨éƒ¨èŠ‚ç‚¹"

    def invoke(self, context, event):
        # æ£€æµ‹Alté”®æ˜¯å¦æŒ‰ä¸‹
        alt_pressed = event.alt

        # æ ¹æ®æŒ‰é”®æ‰§è¡Œä¸åŒçš„æ“ä½œ
        if alt_pressed:
            # Alt+ç‚¹å‡» - å¤åˆ¶å…¨éƒ¨èŠ‚ç‚¹
            return self.copy_all_nodes(context)
        else:
            # æ™®é€šç‚¹å‡» - å¤åˆ¶é€‰ä¸­èŠ‚ç‚¹
            return self.copy_selected_nodes(context)

    def copy_selected_nodes(self, context):
        # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
            return {'CANCELLED'}

        # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†èŠ‚ç‚¹
        selected_nodes = []

        # æ–¹æ³•1: æ£€æŸ¥ context.selected_nodes
        if hasattr(context, 'selected_nodes'):
            selected_nodes = list(context.selected_nodes)

        # å¦‚æœæ²¡æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
        if not selected_nodes and hasattr(context, 'active_node') and context.active_node:
            selected_nodes = [context.active_node]

        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»å½“å‰èŠ‚ç‚¹æ ‘è·å–
        if not selected_nodes:
            node_tree = context.space_data.node_tree
            for node in node_tree.nodes:
                if getattr(node, 'select', False):  # ä½¿ç”¨getattrç¡®ä¿å±æ€§å­˜åœ¨
                    selected_nodes.append(node)

        if not selected_nodes:
            self.report({'ERROR'}, "æ²¡æœ‰é€‰æ‹©è¦å¤åˆ¶çš„èŠ‚ç‚¹")
            return {'CANCELLED'}

        # è·å–å½“å‰è®¾ç½®
        ain_settings = context.scene.ainode_analyzer_settings
        filter_level = ain_settings.filter_level

        # åˆ›å»ºèŠ‚ç‚¹æè¿°
        fake_context = type('FakeContext', (), {
            'space_data': context.space_data,
            'selected_nodes': selected_nodes,
            'active_node': selected_nodes[0] if selected_nodes else None
        })()

        node_description = get_selected_nodes_description(fake_context)
        filtered_desc = filter_node_description(node_description, filter_level)

        # å¤åˆ¶åˆ°å‰ªè´´æ¿
        if copy_to_clipboard(filtered_desc):
            self.report({'INFO'}, f"å·²å°† {len(selected_nodes)} ä¸ªé€‰ä¸­èŠ‚ç‚¹çš„ä¿¡æ¯å¤åˆ¶åˆ°å‰ªè´´æ¿")
        else:
            self.report({'ERROR'}, "å¤åˆ¶åˆ°å‰ªè´´æ¿å¤±è´¥")

        return {'FINISHED'}

    def copy_all_nodes(self, context):
        # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
            return {'CANCELLED'}

        node_tree = context.space_data.node_tree
        all_nodes = list(node_tree.nodes)

        if not all_nodes:
            self.report({'ERROR'}, "èŠ‚ç‚¹æ ‘ä¸­æ²¡æœ‰èŠ‚ç‚¹")
            return {'CANCELLED'}

        # è·å–å½“å‰è®¾ç½®
        ain_settings = context.scene.ainode_analyzer_settings
        filter_level = ain_settings.filter_level

        # ä½¿ç”¨é€’å½’è§£æå‡½æ•°è·å–å®Œæ•´çš„èŠ‚ç‚¹æ ‘ä¿¡æ¯
        full_node_info = parse_node_tree_recursive(node_tree)
        full_node_json = json.dumps(full_node_info, indent=2, ensure_ascii=False)
        filtered_desc = filter_node_description(full_node_json, filter_level)

        # å¤åˆ¶åˆ°å‰ªè´´æ¿
        if copy_to_clipboard(filtered_desc):
            self.report({'INFO'}, f"å·²å°†èŠ‚ç‚¹æ ‘ä¸­å…¨éƒ¨ {len(all_nodes)} ä¸ªèŠ‚ç‚¹çš„ä¿¡æ¯å¤åˆ¶åˆ°å‰ªè´´æ¿")
        else:
            self.report({'ERROR'}, "å¤åˆ¶åˆ°å‰ªè´´æ¿å¤±è´¥")

        return {'FINISHED'}

# å¤åˆ¶å…¨éƒ¨èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿è¿ç®—ç¬¦
class NODE_OT_copy_all_nodes_to_clipboard(bpy.types.Operator):
    bl_idname = "node.copy_all_nodes_to_clipboard"
    bl_label = "å¤åˆ¶å…¨éƒ¨èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿"
    bl_description = "å¤åˆ¶å½“å‰èŠ‚ç‚¹æ ‘ä¸­çš„å…¨éƒ¨èŠ‚ç‚¹ä¿¡æ¯åˆ°å‰ªè´´æ¿ï¼Œä½¿ç”¨å½“å‰ç²¾ç»†åº¦è®¾ç½®è¿‡æ»¤"

    def execute(self, context):
        # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
            return {'CANCELLED'}

        node_tree = context.space_data.node_tree
        all_nodes = list(node_tree.nodes)

        if not all_nodes:
            self.report({'ERROR'}, "èŠ‚ç‚¹æ ‘ä¸­æ²¡æœ‰èŠ‚ç‚¹")
            return {'CANCELLED'}

        # è·å–å½“å‰è®¾ç½®
        ain_settings = context.scene.ainode_analyzer_settings
        filter_level = ain_settings.filter_level

        # ä½¿ç”¨é€’å½’è§£æå‡½æ•°è·å–å®Œæ•´çš„èŠ‚ç‚¹æ ‘ä¿¡æ¯
        full_node_info = parse_node_tree_recursive(node_tree)
        full_node_json = json.dumps(full_node_info, indent=2, ensure_ascii=False)
        filtered_desc = filter_node_description(full_node_json, filter_level)

        # å¤åˆ¶åˆ°å‰ªè´´æ¿
        if copy_to_clipboard(filtered_desc):
            self.report({'INFO'}, f"å·²å°†èŠ‚ç‚¹æ ‘ä¸­å…¨éƒ¨ {len(all_nodes)} ä¸ªèŠ‚ç‚¹çš„ä¿¡æ¯å¤åˆ¶åˆ°å‰ªè´´æ¿")
        else:
            self.report({'ERROR'}, "å¤åˆ¶åˆ°å‰ªè´´æ¿å¤±è´¥")

        return {'FINISHED'}

# æ¸…ç©ºAPIå¯†é’¥è¿ç®—ç¬¦
class NODE_OT_clear_api_key(bpy.types.Operator):
    bl_idname = "node.clear_api_key"
    bl_label = "æ¸…ç©ºAPIå¯†é’¥"
    bl_description = "æ¸…ç©ºå½“å‰APIå¯†é’¥"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        ain_settings.generic_api_key = ""
        ain_settings.deepseek_api_key = ""
        ain_settings.bigmodel_api_key = ""
        self.report({'INFO'}, "APIå¯†é’¥å·²æ¸…ç©º")
        return {'FINISHED'}

# æµ‹è¯•BigModelæ¨¡å‹æ“ä½œç¬¦
class NODE_OT_test_bigmodel_model(bpy.types.Operator):
    bl_idname = "node.test_bigmodel_model"
    bl_label = "æµ‹è¯•BigModelæ¨¡å‹"
    bl_description = "æµ‹è¯•å½“å‰BigModelæ¨¡å‹æ˜¯å¦å¯ç”¨"
    bl_options = {'REGISTER'}

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        
        if ain_settings.ai_provider != 'BIGMODEL':
            self.report({'WARNING'}, "è¯·å…ˆé€‰æ‹©BigModelä½œä¸ºAIæœåŠ¡æä¾›å•†")
            return {'CANCELLED'}
        
        if not ain_settings.bigmodel_api_key:
            self.report({'WARNING'}, "è¯·å…ˆé…ç½®BigModel APIå¯†é’¥")
            return {'CANCELLED'}
        
        if not server_manager or not server_manager.is_running:
            self.report({'WARNING'}, "è¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨")
            return {'CANCELLED'}
        
        try:
            # è°ƒç”¨åç«¯æµ‹è¯•API
            resp = send_to_backend('/api/test-bigmodel-api', data={
                'api_key': ain_settings.bigmodel_api_key,
                'model': ain_settings.bigmodel_model,
                'base_url': ain_settings.bigmodel_url
            }, method='POST')
            
            if resp and isinstance(resp, dict):
                if resp.get('status') == 'Success':
                    self.report({'INFO'}, f"BigModelæ¨¡å‹æµ‹è¯•æˆåŠŸ: {ain_settings.bigmodel_model}")
                else:
                    error_msg = resp.get('message', 'æœªçŸ¥é”™è¯¯')
                    self.report({'ERROR'}, f"BigModelæ¨¡å‹æµ‹è¯•å¤±è´¥: {error_msg}")
            else:
                self.report({'ERROR'}, "BigModelæ¨¡å‹æµ‹è¯•å¤±è´¥: æ— æ•ˆçš„å“åº”")
        except Exception as e:
            self.report({'ERROR'}, f"BigModelæ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        
        return {'FINISHED'}

# æ‰“å¼€åç«¯ç½‘é¡µè¿ç®—ç¬¦
class NODE_OT_open_backend_webpage(bpy.types.Operator):
    bl_idname = "node.open_backend_webpage"
    bl_label = "æ‰“å¼€åç«¯ç½‘é¡µ"
    bl_description = "åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€åç«¯ç½‘é¡µç•Œé¢"

    def execute(self, context):
        import webbrowser
        global server_manager
        ain_settings = context.scene.ainode_analyzer_settings

        if server_manager and server_manager.is_running:
            port = server_manager.port
            url = f"http://127.0.0.1:{port}"
            webbrowser.open(url)
            self.report({'INFO'}, f"åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {url}")
        else:
            # å¦‚æœæœåŠ¡å™¨æœªè¿è¡Œï¼Œæç¤ºç”¨æˆ·å…ˆå¯åŠ¨
            self.report({'WARNING'}, "è¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨")

        return {'FINISHED'}

# é‡ç½®è®¾ç½®è¿ç®—ç¬¦
class NODE_OT_reset_settings(bpy.types.Operator):
    bl_idname = "node.reset_settings"
    bl_label = "é‡ç½®è®¾ç½®"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings

        # é‡ç½®æ‰€æœ‰è®¾ç½®ä¸ºé»˜è®¤å€¼
        ain_settings.ai_provider = 'DEEPSEEK'
        ain_settings.deepseek_api_key = ""
        ain_settings.deepseek_url = "https://api.deepseek.com"
        ain_settings.deepseek_model = 'deepseek-chat'
        ain_settings.ollama_url = "http://localhost:11434"
        ain_settings.ollama_model = "llama2"
        ain_settings.system_prompt = "æ‚¨æ˜¯BlenderèŠ‚ç‚¹çš„ä¸“å®¶ã€‚åˆ†æä»¥ä¸‹èŠ‚ç‚¹ç»“æ„å¹¶æä¾›è§è§£ã€ä¼˜åŒ–æˆ–è§£é‡Šã€‚"
        ain_settings.user_input = ""
        ain_settings.default_question = "è¯·åˆ†æè¿™äº›èŠ‚ç‚¹çš„åŠŸèƒ½å’Œä¼˜åŒ–å»ºè®®"
        ain_settings.identity_key = ""
        ain_settings.default_question_preset = ""
        ain_settings.generic_base_url = ""
        ain_settings.generic_api_key = ""
        ain_settings.generic_model = ""
        ain_settings.enable_backend = False  # é»˜è®¤ä¸å¯ç”¨åç«¯
        ain_settings.backend_port = 5000
        ain_settings.enable_memory = True  # é»˜è®¤å¯ç”¨è®°å¿†
        ain_settings.memory_target_k = 4  # é»˜è®¤ç›®æ ‡å€¼

        self.report({'INFO'}, "è®¾ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
        return {'FINISHED'}

# è®¾ç½®é»˜è®¤é—®é¢˜è¿ç®—ç¬¦
class NODE_OT_set_default_question(bpy.types.Operator):
    bl_idname = "node.set_default_question"
    bl_label = "è®¾ç½®é»˜è®¤é—®é¢˜"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        ain_settings.user_input = ain_settings.default_question
        self.report({'INFO'}, "å·²è®¾ç½®é»˜è®¤é—®é¢˜")
        return {'FINISHED'}

# æ¸…é™¤é—®é¢˜è¿ç®—ç¬¦
class NODE_OT_clear_question(bpy.types.Operator):
    bl_idname = "node.clear_question"
    bl_label = "æ¸…é™¤é—®é¢˜"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        ain_settings.user_input = ""
        self.report({'INFO'}, "é—®é¢˜å·²æ¸…é™¤")
        return {'FINISHED'}

class NODE_OT_clean_markdown_text(bpy.types.Operator):
    bl_idname = "node.clean_markdown_text"
    bl_label = "æ¸…ç†Markdown"
    bl_description = "æ¸…ç†å½“å‰æ–‡æœ¬æ–‡æ¡£çš„Markdownæ ¼å¼"

    def execute(self, context):
        import bpy
        # è·å–å½“å‰æ´»åŠ¨çš„æ–‡æœ¬å—
        text_block = context.space_data.text
        
        if not text_block:
            self.report({'WARNING'}, "æ²¡æœ‰æ‰“å¼€çš„æ–‡æœ¬æ–‡æ¡£")
            return {'CANCELLED'}
        
        content = text_block.as_string()
        
        # è°ƒç”¨åç«¯æ¸…ç†æ¥å£ä»¥å¤ç”¨Webè¿‡æ»¤é€»è¾‘
        resp = send_to_backend('/api/clean-markdown', data={'content': content}, method='POST')
        cleaned = None
        if resp and isinstance(resp, dict):
            data = resp.get('data') or resp
            cleaned = data.get('cleaned')
        if isinstance(cleaned, str):
            text_block.clear()
            text_block.write(cleaned)
            self.report({'INFO'}, "å·²æ¸…ç†Markdownæ ¼å¼")
            return {'FINISHED'}
        else:
            self.report({'ERROR'}, "æ¸…ç†å¤±è´¥ï¼šåç«¯æœªè¿”å›ç»“æœ")
            return {'CANCELLED'}

def text_header_draw(self, context):
    """åœ¨æ–‡æœ¬ç¼–è¾‘å™¨å¤´éƒ¨æ·»åŠ æ¸…ç†å’Œå¤åˆ¶æŒ‰é’®"""
    layout = self.layout
    layout.separator_spacer()
    layout.operator("node.clean_markdown_text", text="", icon='BRUSH_DATA')
    layout.operator("node.copy_text_to_clipboard", text="", icon='COPY_ID')

# ç»ˆæ­¢AIè¯·æ±‚è¿ç®—ç¬¦
class NODE_OT_test_provider_status(bpy.types.Operator):
    bl_idname = "node.test_provider_status"
    bl_label = "æµ‹è¯•æä¾›å•†è¿é€šæ€§"
    bl_description = "æµ‹è¯•å½“å‰AIæœåŠ¡å•†çš„è¿é€šæ€§"

    def execute(self, context):
        ain = context.scene.ainode_analyzer_settings
        prov = ain.ai_provider
        # 1. connectivity via provider-connectivity
        conn = "ä¸å¯ç”¨"
        try:
            resp_c = send_to_backend('/api/provider-connectivity', data={"provider": prov}, method='POST')
            if resp_c and isinstance(resp_c, dict):
                data_c = resp_c.get('data') or resp_c
                if bool(data_c.get('ok', False)):
                    conn = "å¯ç”¨"
        except Exception:
            pass
        ain.status_connectivity = conn
        self.report({'INFO'}, f"è¿é€šæ€§æµ‹è¯•ç»“æœ: {conn}")
        return {'FINISHED'}

# åˆ›å»ºä¸€ä¸ªå½“æœåŠ¡å™¨æœªè¿è¡Œæ—¶çš„æµ‹è¯•è¿æ¥æ“ä½œ
class NODE_OT_test_provider_status_disabled(bpy.types.Operator):
    bl_idname = "node.test_provider_status_disabled"
    bl_label = "æµ‹è¯•æä¾›å•†è¿é€šæ€§ï¼ˆæœåŠ¡å™¨æœªå¯åŠ¨ï¼‰"
    bl_description = "åç«¯æœåŠ¡å™¨æœªå¯åŠ¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨"

    def execute(self, context):
        self.report({'WARNING'}, "åç«¯æœåŠ¡å™¨æœªå¯åŠ¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨")
        return {'CANCELLED'}

class NODE_OT_stop_ai_request(bpy.types.Operator):
    bl_idname = "node.stop_ai_request"
    bl_label = "ç»ˆæ­¢AIè¯·æ±‚"
    bl_description = "ç»ˆæ­¢å½“å‰æ­£åœ¨è¿›è¡Œçš„AIè¯·æ±‚"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings

        # æ›´æ–°çŠ¶æ€
        ain_settings.ai_question_status = 'STOPPED'
        ain_settings.can_terminate_request = False
        ain_settings.current_status = "è¯·æ±‚å·²ç»ˆæ­¢"

        self.report({'INFO'}, "AIè¯·æ±‚å·²ç»ˆæ­¢")
        return {'FINISHED'}

class NODE_OT_reset_provider_url(bpy.types.Operator):
    bl_idname = "node.reset_provider_url"
    bl_label = "é‡ç½®æœåŠ¡åœ°å€"

    def execute(self, context):
        ain = context.scene.ainode_analyzer_settings
        sel = ain.ai_provider

        # æ ¹æ®æä¾›å•†ç±»å‹é‡ç½®URL
        if sel == 'DEEPSEEK':
            ain.deepseek_url = "https://api.deepseek.com"
        elif sel == 'OLLAMA':
            ain.ollama_url = "http://localhost:11434"
        elif sel == 'BIGMODEL':
            ain.bigmodel_url = "https://open.bigmodel.cn/api/paas/v4"
        else:
            ain.generic_base_url = ""

        self.report({'INFO'}, "å·²é‡ç½®æœåŠ¡åœ°å€")
        return {'FINISHED'}

class NODE_OT_refresh_models(bpy.types.Operator):
    bl_idname = "node.refresh_models"
    bl_label = "åˆ·æ–°æ¨¡å‹åˆ—è¡¨"

    def execute(self, context):
        ain = context.scene.ainode_analyzer_settings
        prov = ain.ai_provider
        try:
            resp = send_to_backend('/api/provider-list-models', data={"provider": prov}, method='POST')
            models = []
            if resp and isinstance(resp, dict):
                data = resp.get('data') or resp
                models = data.get('models') or []

            # æ›´æ–°ç›¸åº”çš„æ¨¡å‹ç¼“å­˜
            if prov == 'DEEPSEEK':
                global deepseek_models_cache
                deepseek_models_cache[:] = models
                if models and ain.deepseek_model not in models:
                    ain.deepseek_model = models[0]  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹
            elif prov == 'OLLAMA':
                global ollama_models_cache
                ollama_models_cache[:] = models
                if models and ain.ollama_model not in models:
                    ain.ollama_model = models[0]  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹
            elif prov == 'BIGMODEL':
                global bigmodel_models_cache
                bigmodel_models_cache[:] = models
                if models and ain.bigmodel_model not in models:
                    ain.bigmodel_model = models[0]  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹
            else:
                global generic_models_cache
                generic_models_cache[:] = models
                if models and ain.generic_model not in models:
                    ain.generic_model = models[0]  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹

            # æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åˆ—è¡¨
            config_path = os.path.join(os.path.dirname(__file__), 'config.json')
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = json.load(f)

                    if 'ai' not in config:
                        config['ai'] = {}

                    # æ›´æ–°ç›¸åº”çš„æ¨¡å‹åˆ—è¡¨åˆ°å¯¹åº”çš„æœåŠ¡å•†é…ç½®ä¸­
                    if prov == 'DEEPSEEK':
                        if 'deepseek' not in config['ai']:
                            config['ai']['deepseek'] = {}
                        config['ai']['deepseek']['models'] = models
                        # åŒæ—¶æ›´æ–°providerä¸­çš„æ¨¡å‹ï¼ˆå¦‚æœå½“å‰ä½¿ç”¨çš„æ˜¯æ­¤æä¾›å•†ï¼‰
                        if (config['ai']['provider']['name'] == 'DEEPSEEK' and
                            models and
                            config['ai']['provider']['model'] not in models):
                            config['ai']['provider']['model'] = models[0] if models else config['ai']['provider']['model']  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹
                    elif prov == 'OLLAMA':
                        if 'ollama' not in config['ai']:
                            config['ai']['ollama'] = {}
                        config['ai']['ollama']['models'] = models
                        # åŒæ—¶æ›´æ–°providerä¸­çš„æ¨¡å‹ï¼ˆå¦‚æœå½“å‰ä½¿ç”¨çš„æ˜¯æ­¤æä¾›å•†ï¼‰
                        if (config['ai']['provider']['name'] == 'OLLAMA' and
                            models and
                            config['ai']['provider']['model'] not in models):
                            config['ai']['provider']['model'] = models[0] if models else config['ai']['provider']['model']  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹
                    elif prov == 'BIGMODEL':
                        if 'bigmodel' not in config['ai']:
                            config['ai']['bigmodel'] = {}
                        config['ai']['bigmodel']['models'] = models
                        # åŒæ—¶æ›´æ–°providerä¸­çš„æ¨¡å‹ï¼ˆå¦‚æœå½“å‰ä½¿ç”¨çš„æ˜¯æ­¤æä¾›å•†ï¼‰
                        if (config['ai']['provider']['name'] == 'BIGMODEL' and
                            models and
                            config['ai']['provider']['model'] not in models):
                            config['ai']['provider']['model'] = models[0] if models else config['ai']['provider']['model']  # è®¾ç½®ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸ºå½“å‰æ¨¡å‹
                    else:
                        # å¯¹äºå…¶ä»–æä¾›å•†ï¼Œå¯ä»¥æ·»åŠ åˆ°genericé…ç½®ä¸­
                        if 'generic' not in config['ai']:
                            config['ai']['generic'] = {}
                        config['ai']['generic']['models'] = models

                    # ä¿å­˜æ›´æ–°åçš„é…ç½®
                    with open(config_path, 'w', encoding='utf-8') as f:
                        json.dump(config, f, indent=4, ensure_ascii=False)

                except Exception as e:
                    print(f"æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {e}")

            ain.status_model_fetch = "å¯ç”¨" if models else "ä¸å¯ç”¨"
            self.report({'INFO'}, f"æ¨¡å‹åˆ·æ–°å®Œæˆï¼Œå…± {len(models)} ä¸ª: {', '.join(models[:5])}{'...' if len(models) > 5 else ''}")
        except Exception as e:
            ain.status_model_fetch = "ä¸å¯ç”¨"
            self.report({'ERROR'}, f"æ¨¡å‹åˆ·æ–°å¤±è´¥: {e}")
        return {'FINISHED'}

# åˆ›å»ºä¸€ä¸ªå½“æœåŠ¡å™¨æœªè¿è¡Œæ—¶çš„åˆ·æ–°æ¨¡å‹æ“ä½œ
class NODE_OT_refresh_models_disabled(bpy.types.Operator):
    bl_idname = "node.refresh_models_disabled"
    bl_label = "åˆ·æ–°æ¨¡å‹åˆ—è¡¨ï¼ˆæœåŠ¡å™¨æœªå¯åŠ¨ï¼‰"
    bl_description = "åç«¯æœåŠ¡å™¨æœªå¯åŠ¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨"

    def execute(self, context):
        self.report({'WARNING'}, "åç«¯æœåŠ¡å™¨æœªå¯åŠ¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨")
        return {'CANCELLED'}

# åˆ›å»ºåˆ†ææ¡†æ¶è¿ç®—ç¬¦
class NODE_OT_create_analysis_frame(bpy.types.Operator):
    bl_idname = "node.create_analysis_frame"
    bl_label = "åˆ›å»ºåˆ†ææ¡†æ¶"
    bl_description = "å°†é€‰ä¸­çš„èŠ‚ç‚¹åŠ å…¥æ¡†æ¶ä»¥ä¾¿ç¡®å®šåˆ†æèŒƒå›´"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
            return {'CANCELLED'}

        node_tree = context.space_data.node_tree

        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ¡†æ¶èŠ‚ç‚¹
        frame_node = None
        for node in node_tree.nodes:
            if node.type == 'FRAME' and node.label == "å°†è¦åˆ†æ":
                frame_node = node
                break

        if frame_node:
            # å¦‚æœå·²ç»å­˜åœ¨æ¡†æ¶ï¼Œåˆ™ç§»é™¤å®ƒå¹¶è®°å½•èŠ‚ç‚¹åç§°
            # è®°å½•æ¡†æ¶ä¸­çš„èŠ‚ç‚¹åç§°
            node_names = []
            nodes_in_frame = []
            for node in node_tree.nodes:
                if node.parent == frame_node:
                    node_names.append(node.name)
                    nodes_in_frame.append(node)
                    node.parent = None  # å°†èŠ‚ç‚¹ä»æ¡†æ¶ä¸­ç§»å‡º
            ain_settings.analysis_frame_node_names = ','.join(node_names)
            node_tree.nodes.remove(frame_node)

            # é€‰æ‹©ä»æ¡†æ¶ä¸­ç§»å‡ºçš„èŠ‚ç‚¹
            for node in node_tree.nodes:
                node.select = False  # å…ˆå–æ¶ˆæ‰€æœ‰é€‰æ‹©
            for node in nodes_in_frame:
                node.select = True  # é€‰æ‹©åˆšä»æ¡†æ¶ä¸­ç§»å‡ºçš„èŠ‚ç‚¹

            self.report({'INFO'}, "å·²ç§»é™¤åˆ†ææ¡†æ¶")
        else:
            # å¦‚æœä¸å­˜åœ¨æ¡†æ¶ï¼Œä¼˜å…ˆä½¿ç”¨å½“å‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œå¦‚æœå½“å‰æ²¡æœ‰é€‰æ‹©èŠ‚ç‚¹æ‰æ¢å¤ä¹‹å‰çš„èŠ‚ç‚¹
            selected_nodes = []

            # æ£€æŸ¥å½“å‰æ˜¯å¦é€‰æ‹©äº†èŠ‚ç‚¹
            current_selected = []
            # æ£€æŸ¥ context.selected_nodes
            if hasattr(context, 'selected_nodes'):
                current_selected = list(context.selected_nodes)

            # å¦‚æœæ²¡æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
            if not current_selected and hasattr(context, 'active_node') and context.active_node:
                current_selected = [context.active_node]

            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»å½“å‰èŠ‚ç‚¹æ ‘è·å–
            if not current_selected:
                for node in node_tree.nodes:
                    if getattr(node, 'select', False):  # ä½¿ç”¨getattrç¡®ä¿å±æ€§å­˜åœ¨
                        current_selected.append(node)

            if current_selected:
                # å¦‚æœå½“å‰æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨å½“å‰é€‰ä¸­çš„èŠ‚ç‚¹
                selected_nodes = current_selected
            elif ain_settings.analysis_frame_node_names:
                # åªæœ‰åœ¨å½“å‰æ²¡æœ‰é€‰ä¸­èŠ‚ç‚¹æ—¶æ‰æ¢å¤ä¹‹å‰çš„èŠ‚ç‚¹
                node_names = ain_settings.analysis_frame_node_names.split(',')
                for node_name in node_names:
                    if node_name in node_tree.nodes:
                        selected_nodes.append(node_tree.nodes[node_name])
            else:
                self.report({'WARNING'}, "æ²¡æœ‰é€‰æ‹©è¦åˆ†æçš„èŠ‚ç‚¹")
                return {'CANCELLED'}

            # å°†èŠ‚ç‚¹åç§°è®°å½•åˆ°è®¾ç½®ä¸­ï¼ˆæ›´æ–°ä¸ºå½“å‰å®é™…ä½¿ç”¨çš„èŠ‚ç‚¹ï¼‰
            node_names = [node.name for node in selected_nodes]
            ain_settings.analysis_frame_node_names = ','.join(node_names)

            # åˆ›å»ºæ¡†æ¶å¹¶åŠ å…¥é€‰ä¸­çš„èŠ‚ç‚¹
            try:
                # é€‰æ‹©è¦åŠ å…¥æ¡†æ¶çš„èŠ‚ç‚¹
                for node in node_tree.nodes:
                    node.select = False  # å…ˆå–æ¶ˆæ‰€æœ‰é€‰æ‹©
                for node in selected_nodes:
                    node.select = True  # é€‰æ‹©æŒ‡å®šèŠ‚ç‚¹

                # ä½¿ç”¨joinæ“ä½œå°†é€‰ä¸­çš„èŠ‚ç‚¹åŠ å…¥æ¡†æ¶
                bpy.ops.node.join()  # è¿™ä¼šå°†é€‰ä¸­çš„èŠ‚ç‚¹åŠ å…¥åˆ°ä¸€ä¸ªæ¡†æ¶ä¸­

                # ç¡®ä¿æ–°åˆ›å»ºçš„æ¡†æ¶è¢«æ‰¾åˆ°å¹¶è®¾ç½®æ ‡ç­¾
                frame_found = None
                for node in node_tree.nodes:
                    if node.type == 'FRAME' and node.select:
                        node.label = "å°†è¦åˆ†æ"
                        frame_found = node
                        break

                # æ¡†æ¶åˆ›å»ºåï¼Œé‡æ–°é€‰æ‹©æ¡†æ¶å†…çš„èŠ‚ç‚¹
                for node in node_tree.nodes:
                    node.select = False  # å…ˆå–æ¶ˆæ‰€æœ‰é€‰æ‹©
                for node in selected_nodes:
                    node.select = True  # é‡æ–°é€‰æ‹©åŸå§‹èŠ‚ç‚¹
                if frame_found:
                    frame_found.select = False  # ä¸é€‰æ‹©æ¡†æ¶æœ¬èº«ï¼Œåªé€‰æ‹©å†…éƒ¨çš„èŠ‚ç‚¹

                self.report({'INFO'}, f"å·²å°† {len(selected_nodes)} ä¸ªèŠ‚ç‚¹åŠ å…¥åˆ†ææ¡†æ¶")
            except Exception as e:
                # å¦‚æœjoinæ“ä½œå¤±è´¥ï¼Œæ‰‹åŠ¨åˆ›å»ºæ¡†æ¶
                frame_node = node_tree.nodes.new(type='NodeFrame')
                frame_node.label = "å°†è¦åˆ†æ"
                # è®¾ç½®æ¡†æ¶ä½ç½®å’Œå¤§å°
                min_x = min([node.location.x for node in selected_nodes])
                max_x = max([node.location.x + node.width for node in selected_nodes])
                min_y = min([node.location.y - node.height for node in selected_nodes])
                max_y = max([node.location.y for node in selected_nodes])

                frame_node.location = (min_x - 20, max_y + 20)
                frame_node.width = max_x - min_x + 40
                frame_node.height = max_y - min_y + 40

                # å°†é€‰ä¸­èŠ‚ç‚¹ç§»åˆ°æ¡†æ¶å†…
                for node in selected_nodes:
                    node.parent = frame_node

                # é‡æ–°é€‰æ‹©èŠ‚ç‚¹ï¼ˆå› ä¸ºåˆ›å»ºæ¡†æ¶åï¼ŒèŠ‚ç‚¹ä»ç„¶è¢«é€‰ä¸­ï¼‰
                for node in node_tree.nodes:
                    node.select = False  # å…ˆå–æ¶ˆæ‰€æœ‰é€‰æ‹©
                for node in selected_nodes:
                    node.select = True  # é€‰æ‹©è¿™äº›èŠ‚ç‚¹

                print(f"Error during join operation: {e}")  # è¾“å‡ºé”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•

                self.report({'INFO'}, f"å·²å°† {len(selected_nodes)} ä¸ªèŠ‚ç‚¹åŠ å…¥åˆ†ææ¡†æ¶")

        return {'FINISHED'}

# åˆ·æ–°å†…å®¹åˆ°æ–‡æœ¬ç¼–è¾‘å™¨è¿ç®—ç¬¦
class NODE_OT_refresh_to_text(bpy.types.Operator):
    bl_idname = "node.refresh_to_text"
    bl_label = "åˆ·æ–°åˆ°æ–‡æœ¬ç¼–è¾‘å™¨"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        
        # Create or update text block
        text_block_name = "AINodeRefreshContent"
        if text_block_name in bpy.data.texts:
            text_block = bpy.data.texts[text_block_name]
            text_block.clear()
        else:
            text_block = bpy.data.texts.new(name=text_block_name)

        # Check for active node tree
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            # Write status to text block so frontend knows
            text_block.write("")  # Clear content
            
            # Push to server
            push_blender_content_to_server(context)
            return {'FINISHED'}

        # Check for selected nodes
        selected_nodes = []

        # Method 1: Check context.selected_nodes
        if hasattr(context, 'selected_nodes'):
            selected_nodes = list(context.selected_nodes)

        # If no selected nodes, use active node
        if not selected_nodes and hasattr(context, 'active_node') and context.active_node:
            selected_nodes = [context.active_node]

        # If still no nodes, try to get from current node tree
        if not selected_nodes:
            node_tree = context.space_data.node_tree
            for node in node_tree.nodes:
                if getattr(node, 'select', False):
                    selected_nodes.append(node)

        # If no nodes selected and no user input
        if not selected_nodes and not ain_settings.user_input:
            # Write status to text block
            text_block.write("No nodes selected.")
            
            # Push to server
            push_blender_content_to_server()
            return {'FINISHED'}

        # Get current node type
        node_type = "æœªçŸ¥"
        if context.space_data and hasattr(context.space_data, 'tree_type'):
            tree_type = context.space_data.tree_type
            if tree_type == 'GeometryNodeTree':
                node_type = "å‡ ä½•èŠ‚ç‚¹"
            elif tree_type == 'ShaderNodeTree':
                node_type = "æè´¨èŠ‚ç‚¹"
            elif tree_type == 'CompositorNodeTree':
                node_type = "åˆæˆèŠ‚ç‚¹"
            elif tree_type == 'TextureNodeTree':
                node_type = "çº¹ç†èŠ‚ç‚¹"
            elif tree_type == 'WorldNodeTree':
                node_type = "ç¯å¢ƒèŠ‚ç‚¹"
        # åœ¨åˆ·æ–°ä¸å‘é€æ—¶æ›´æ–°èŠ‚ç‚¹ç±»å‹ï¼Œé¿å…åœ¨UIç»˜åˆ¶ä¸­å†™å…¥

        # å†™å…¥å†…å®¹ - ä»…å†™å…¥èŠ‚ç‚¹æè¿°ï¼Œä¸åŒ…å«å…ƒæ•°æ®å¤´
        # å…ƒæ•°æ®å°†é€šè¿‡push_blender_content_to_serverå•ç‹¬å‘é€

        # è·å–å½“å‰é€‰ä¸­èŠ‚ç‚¹çš„æè¿°ï¼ˆç›´æ¥ä»å½“å‰ä¸Šä¸‹æ–‡è·å–ï¼Œè€Œä¸æ˜¯ä½¿ç”¨é¢„è§ˆå†…å®¹ï¼‰
        if selected_nodes:
            fake_context = type('FakeContext', (), {
                'space_data': context.space_data,
                'selected_nodes': selected_nodes,
                'active_node': selected_nodes[0] if selected_nodes else None
            })()

            node_description = get_selected_nodes_description(fake_context)
            # ä¿å­˜åŸå§‹èŠ‚ç‚¹æ•°æ®ï¼ˆä¸è¿‡æ»¤ï¼‰
            raw_json = json.dumps(json.loads(node_description), indent=2, ensure_ascii=False)
            # è¿‡æ»¤åçš„èŠ‚ç‚¹æ•°æ®
            filtered = filter_node_description(node_description, ain_settings.filter_level)
            instr = get_output_detail_instruction(ain_settings)
            hdr = f"è¯¦ç»†ç¨‹åº¦:\n{instr}\n\n" if instr else ""
            combined = f"{hdr}ç³»ç»Ÿæç¤º:\n{ain_settings.system_prompt}\n\né—®é¢˜:\n{ain_settings.user_input}\n\nèŠ‚ç‚¹ç»“æ„:\n{filtered}"
            text_block.write(combined)
            ain_settings.preview_content = combined
            
            print(f"[DEBUG] æœ‰é€‰ä¸­èŠ‚ç‚¹ {len(selected_nodes)} ä¸ªï¼Œå¼€å§‹æ‹†åˆ†åˆ°5ä¸ªæ–‡æœ¬å—...")
            
            # æ‹†åˆ†ä¸º5ä¸ªç‹¬ç«‹æ–‡æœ¬å—ï¼ˆå¸¦ç¼–å·å‰ç¼€ï¼Œç¡®ä¿é¡ºåºï¼‰
            # 0. åŸå§‹èŠ‚ç‚¹æ•°æ®ï¼ˆä¸è¿‡æ»¤ï¼Œç”¨äºWebç«¯è¿‡æ»¤ï¼‰
            original_data_block_name = "00-åŸå§‹èŠ‚ç‚¹æ•°æ®"
            if original_data_block_name in bpy.data.texts:
                original_data_block = bpy.data.texts[original_data_block_name]
                original_data_block.clear()
            else:
                original_data_block = bpy.data.texts.new(name=original_data_block_name)
            original_data_block.write(raw_json)
            print(f"[DEBUG] å·²å†™å…¥ {original_data_block_name}")
            
            # 1. è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯
            output_detail_block_name = "01-è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯"
            if output_detail_block_name in bpy.data.texts:
                output_detail_block = bpy.data.texts[output_detail_block_name]
                output_detail_block.clear()
            else:
                output_detail_block = bpy.data.texts.new(name=output_detail_block_name)
            output_detail_block.write(instr if instr else "")
            print(f"[DEBUG] å·²å†™å…¥ {output_detail_block_name}")
            
            # 2. ç³»ç»Ÿæç¤ºè¯ï¼ˆèº«ä»½æç¤ºè¯ï¼‰
            system_prompt_block_name = "02-ç³»ç»Ÿæç¤ºè¯"
            if system_prompt_block_name in bpy.data.texts:
                system_prompt_block = bpy.data.texts[system_prompt_block_name]
                system_prompt_block.clear()
            else:
                system_prompt_block = bpy.data.texts.new(name=system_prompt_block_name)
            system_prompt_block.write(ain_settings.system_prompt)
            print(f"[DEBUG] å·²å†™å…¥ {system_prompt_block_name}")
            
            # 3. ç”¨æˆ·é—®é¢˜
            user_question_block_name = "03-ç”¨æˆ·é—®é¢˜"
            if user_question_block_name in bpy.data.texts:
                user_question_block = bpy.data.texts[user_question_block_name]
                user_question_block.clear()
            else:
                user_question_block = bpy.data.texts.new(name=user_question_block_name)
            user_question_block.write(ain_settings.user_input)
            print(f"[DEBUG] å·²å†™å…¥ {user_question_block_name}")
            
            # 4. èŠ‚ç‚¹æ•°æ®ï¼ˆè¿‡æ»¤åçš„ï¼Œç”¨äºå‘é€ç»™AIï¼‰
            raw_data_block_name = "04-èŠ‚ç‚¹æ•°æ®"
            if raw_data_block_name in bpy.data.texts:
                raw_data_block = bpy.data.texts[raw_data_block_name]
                raw_data_block.clear()
            else:
                raw_data_block = bpy.data.texts.new(name=raw_data_block_name)
            raw_data_block.write(filtered)
            print(f"[DEBUG] å·²å†™å…¥ {raw_data_block_name}")
        else:
            print(f"[DEBUG] æ²¡æœ‰é€‰ä¸­èŠ‚ç‚¹ï¼Œä¿ç•™å…¶ä»–éƒ¨åˆ†ï¼Œåªæ¸…ç©ºèŠ‚ç‚¹æ•°æ®...")
            instr = get_output_detail_instruction(ain_settings)
            hdr = f"è¯¦ç»†ç¨‹åº¦:\n{instr}\n\n" if instr else ""
            combined = f"{hdr}ç³»ç»Ÿæç¤º:\n{ain_settings.system_prompt}\n\né—®é¢˜:\n{ain_settings.user_input}\n\nèŠ‚ç‚¹ç»“æ„:\nNo nodes selected."
            text_block.write(combined)
            ain_settings.preview_content = combined
            
            # åªæ¸…ç©ºèŠ‚ç‚¹æ•°æ®ï¼Œä¿ç•™å…¶ä»–éƒ¨åˆ†
            # 0. åŸå§‹èŠ‚ç‚¹æ•°æ®ï¼ˆæ¸…ç©ºï¼‰
            original_data_block_name = "00-åŸå§‹èŠ‚ç‚¹æ•°æ®"
            if original_data_block_name in bpy.data.texts:
                original_data_block = bpy.data.texts[original_data_block_name]
                original_data_block.clear()
            else:
                original_data_block = bpy.data.texts.new(name=original_data_block_name)
            
            # 1. è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯
            output_detail_block_name = "01-è¾“å‡ºè¯¦ç»†ç¨‹åº¦æç¤ºè¯"
            if output_detail_block_name in bpy.data.texts:
                output_detail_block = bpy.data.texts[output_detail_block_name]
                output_detail_block.clear()
                output_detail_block.write(instr if instr else "")
            else:
                output_detail_block = bpy.data.texts.new(name=output_detail_block_name)
                output_detail_block.write(instr if instr else "")
            
            # 2. ç³»ç»Ÿæç¤ºè¯ï¼ˆèº«ä»½æç¤ºè¯ï¼‰
            system_prompt_block_name = "02-ç³»ç»Ÿæç¤ºè¯"
            if system_prompt_block_name in bpy.data.texts:
                system_prompt_block = bpy.data.texts[system_prompt_block_name]
                system_prompt_block.clear()
                system_prompt_block.write(ain_settings.system_prompt)
            else:
                system_prompt_block = bpy.data.texts.new(name=system_prompt_block_name)
                system_prompt_block.write(ain_settings.system_prompt)
            
            # 3. ç”¨æˆ·é—®é¢˜
            user_question_block_name = "03-ç”¨æˆ·é—®é¢˜"
            if user_question_block_name in bpy.data.texts:
                user_question_block = bpy.data.texts[user_question_block_name]
                user_question_block.clear()
                user_question_block.write(ain_settings.user_input)
            else:
                user_question_block = bpy.data.texts.new(name=user_question_block_name)
                user_question_block.write(ain_settings.user_input)
            
            # 4. èŠ‚ç‚¹æ•°æ®ï¼ˆæ¸…ç©ºï¼Œå› ä¸ºæ²¡æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼‰
            raw_data_block_name = "04-èŠ‚ç‚¹æ•°æ®"
            if raw_data_block_name in bpy.data.texts:
                raw_data_block = bpy.data.texts[raw_data_block_name]
                raw_data_block.clear()
            else:
                raw_data_block = bpy.data.texts.new(name=raw_data_block_name)

        self.report({'INFO'}, f"å†…å®¹å·²åˆ·æ–°åˆ°æ–‡æœ¬å— '{text_block_name}'")

        # å°è¯•å°†å†…å®¹æ¨é€åˆ°åç«¯æœåŠ¡å™¨
        try:
            success = push_blender_content_to_server(context)
            if success:
                print("å·²å°†åˆ·æ–°å†…å®¹æ¨é€åˆ°åç«¯æœåŠ¡å™¨")
            else:
                print("æ¨é€å†…å®¹åˆ°åç«¯æœåŠ¡å™¨å¤±è´¥ï¼ŒæœåŠ¡å™¨å¯èƒ½æœªå¯åŠ¨")
        except Exception as e:
            print(f"æ¨é€å†…å®¹æ—¶å‡ºé”™: {e}")

        return {'FINISHED'}

# æ˜¾ç¤ºå®Œæ•´é¢„è§ˆå†…å®¹è¿ç®—ç¬¦
class NODE_OT_show_full_preview(bpy.types.Operator):
    bl_idname = "node.show_full_preview"
    bl_label = "åœ¨æ–‡æœ¬ç¼–è¾‘å™¨ä¸­æ˜¾ç¤ºå®Œæ•´é¢„è§ˆ"

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings

        if ain_settings.preview_content:
            # åˆ›å»ºæˆ–æ›´æ–°æ–‡æœ¬å—ä»¥æ˜¾ç¤ºå®Œæ•´é¢„è§ˆ
            text_block_name = "AINodeFullPreview"
            if text_block_name in bpy.data.texts:
                text_block = bpy.data.texts[text_block_name]
                text_block.clear()
            else:
                text_block = bpy.data.texts.new(name=text_block_name)

            # è·å–å½“å‰èŠ‚ç‚¹ç±»å‹å’ŒBlenderç‰ˆæœ¬
            node_type = "æœªçŸ¥"
            if context.space_data and hasattr(context.space_data, 'tree_type'):
                tree_type = context.space_data.tree_type
                if tree_type == 'GeometryNodeTree':
                    node_type = "å‡ ä½•èŠ‚ç‚¹"
                elif tree_type == 'ShaderNodeTree':
                    node_type = "æè´¨èŠ‚ç‚¹"
                elif tree_type == 'CompositorNodeTree':
                    node_type = "åˆæˆèŠ‚ç‚¹"
                elif tree_type == 'TextureNodeTree':
                    node_type = "çº¹ç†èŠ‚ç‚¹"
                elif tree_type == 'WorldNodeTree':
                    node_type = "ç¯å¢ƒèŠ‚ç‚¹"

            text_block.write(f"AIèŠ‚ç‚¹åˆ†æå™¨å®Œæ•´å†…å®¹é¢„è§ˆ\n")
            text_block.write(f"Blenderç‰ˆæœ¬: {bpy.app.version_string}\n")
            text_block.write(f"å½“å‰èŠ‚ç‚¹ç±»å‹: {node_type}\n")
            text_block.write("="*50 + "\n\n")
            text_block.write(ain_settings.preview_content)

            self.report({'INFO'}, f"å®Œæ•´é¢„è§ˆå·²ä¿å­˜åˆ°æ–‡æœ¬å— '{text_block_name}'")
        else:
            self.report({'WARNING'}, "æ²¡æœ‰é¢„è§ˆå†…å®¹å¯æ˜¾ç¤º")

        return {'FINISHED'}

# AIåˆ†æåŸºç±»
class AIBaseOperator:
    """AIåˆ†æåŸºç±»ï¼ŒåŒ…å«é€šç”¨çš„APIè°ƒç”¨æ–¹æ³•"""

    def perform_analysis(self, node_description, settings):
        """æ‰§è¡ŒAIåˆ†æ"""
        try:
            # æ ¹æ®AIæä¾›å•†è°ƒç”¨ç›¸åº”çš„API
            if settings.ai_provider == 'DEEPSEEK':
                return self.call_deepseek_api(node_description, settings)
            elif settings.ai_provider == 'OLLAMA':
                return self.call_ollama_api(node_description, settings)
            else:
                return None
        except Exception as e:
            print(f"Error in perform_analysis: {str(e)}")
            return None

    def call_deepseek_api(self, node_description, settings):
        """è°ƒç”¨DeepSeek API"""
        if not settings.deepseek_api_key.strip():
            return "DeepSeek API Keyæ˜¯å¿…éœ€çš„ã€‚"

        try:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {settings.deepseek_api_key}'
            }

            system_message = settings.system_prompt
            user_message = f"åˆ†æä»¥ä¸‹BlenderèŠ‚ç‚¹ç»“æ„å¹¶æä¾›è§è§£ã€ä¼˜åŒ–æˆ–è§£é‡Š:\n\n{node_description}"

            data = {
                "model": settings.deepseek_model,
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }

            import requests
            response = requests.post(
                'https://api.deepseek.com/chat/completions',
                headers=headers,
                json=data,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    return result['choices'][0]['message']['content']
                else:
                    return f"æ„å¤–çš„APIå“åº”æ ¼å¼: {result}"
            else:
                return f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}"
        except Exception as e:
            return f"è°ƒç”¨DeepSeek APIæ—¶å‡ºé”™: {str(e)}"

    def call_ollama_api(self, node_description, settings):
        """è°ƒç”¨Ollama API"""
        try:
            import requests

            # æ„å»ºOllama API URL
            url = f"{settings.ollama_url}/api/generate"

            system_message = settings.system_prompt
            prompt = f"System: {system_message}\n\nUser: åˆ†æä»¥ä¸‹BlenderèŠ‚ç‚¹ç»“æ„å¹¶æä¾›è§è§£ã€ä¼˜åŒ–æˆ–è§£é‡Š:\n\n{node_description}\n\nAssistant:"

            data = {
                "model": settings.ollama_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7
                }
            }

            response = requests.post(url, json=data, timeout=60)

            if response.status_code == 200:
                result = response.json()
                if 'response' in result:
                    return result['response']
                else:
                    return f"æ„å¤–çš„APIå“åº”æ ¼å¼: {result}"
            else:
                return f"Ollama APIé”™è¯¯: {response.status_code} - {response.text}"
        except Exception as e:
            return f"è°ƒç”¨Ollama APIæ—¶å‡ºé”™: {str(e)}"

# å®ç°AIåˆ†æè¿ç®—ç¬¦
class NODE_OT_analyze_with_ai(AIBaseOperator, Operator):
    bl_idname = "node.analyze_with_ai"
    bl_label = "ä½¿ç”¨AIåˆ†æé€‰ä¸­çš„èŠ‚ç‚¹"
    bl_description = "å°†é€‰ä¸­çš„èŠ‚ç‚¹å‘é€ç»™AIè¿›è¡Œåˆ†æ"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings

        # æ›´æ–°çŠ¶æ€
        ain_settings.current_status = "æ­£åœ¨åˆ†æèŠ‚ç‚¹..."

        # ç›´æ¥åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œè·å–å½“å‰èŠ‚ç‚¹ä¿¡æ¯
        # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
            ain_settings.current_status = "é”™è¯¯ï¼šæœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘"
            return {'CANCELLED'}

        # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†èŠ‚ç‚¹
        # å°è¯•å¤šç§æ–¹å¼è·å–é€‰ä¸­çš„èŠ‚ç‚¹
        selected_nodes = []

        # æ–¹æ³•1: æ£€æŸ¥ context.selected_nodes
        if hasattr(context, 'selected_nodes'):
            selected_nodes = list(context.selected_nodes)

        # å¦‚æœæ²¡æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
        if not selected_nodes and hasattr(context, 'active_node') and context.active_node:
            selected_nodes = [context.active_node]

        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»å½“å‰èŠ‚ç‚¹æ ‘è·å–
        if not selected_nodes:
            node_tree = context.space_data.node_tree
            for node in node_tree.nodes:
                if getattr(node, 'select', False):  # ä½¿ç”¨getattrç¡®ä¿å±æ€§å­˜åœ¨
                    selected_nodes.append(node)

        if not selected_nodes:
            self.report({'ERROR'}, "æ²¡æœ‰é€‰æ‹©è¦åˆ†æçš„èŠ‚ç‚¹")
            ain_settings.current_status = "é”™è¯¯ï¼šæ²¡æœ‰é€‰æ‹©è¦åˆ†æçš„èŠ‚ç‚¹"
            return {'CANCELLED'}

        # åˆ›å»ºé¢„è§ˆå†…å®¹ï¼ˆå®æ—¶åˆ›å»ºæœ€æ–°çš„èŠ‚ç‚¹ä¿¡æ¯ï¼‰
        fake_context = type('FakeContext', (), {
            'space_data': context.space_data,
            'selected_nodes': selected_nodes,
            'active_node': selected_nodes[0] if selected_nodes else None
        })()

        node_description = get_selected_nodes_description(fake_context)
        filtered_desc = filter_node_description(node_description, ain_settings.filter_level)
        instr = get_output_detail_instruction(ain_settings)
        hdr = f"è¯¦ç»†ç¨‹åº¦:\n{instr}\n\n" if instr else ""
        preview_content = f"{hdr}ç³»ç»Ÿæç¤º:\n{ain_settings.system_prompt}\n\nèŠ‚ç‚¹ç»“æ„:\n{filtered_desc}"
        ain_settings.preview_content = preview_content  # æ›´æ–°é¢„è§ˆå†…å®¹

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼Œä»¥é¿å…é˜»å¡UI
        import threading
        # ä¿å­˜å½“å‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        self.current_space_data = context.space_data
        self.selected_nodes = selected_nodes
        self.active_node = selected_nodes[0] if selected_nodes else None
        thread = threading.Thread(target=self.run_analysis)
        thread.start()
        return {'FINISHED'}

    def run_analysis(self):
        """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒAIåˆ†æ"""
        import bpy
        try:
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
            if not self.current_space_data or not hasattr(self.current_space_data, 'node_tree') or not self.current_space_data.node_tree:
                self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
                ain_settings.current_status = "é”™è¯¯ï¼šæœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘"
                return {'CANCELLED'}

            # ä½¿ç”¨ä¿å­˜çš„èŠ‚ç‚¹ä¿¡æ¯
            selected_nodes = self.selected_nodes

            # å…è®¸ä¸é€‰æ‹©èŠ‚ç‚¹ä¹Ÿèƒ½å‘é€é—®é¢˜
            if not selected_nodes:
                # æ²¡æœ‰é€‰æ‹©èŠ‚ç‚¹ï¼Œåªå‘é€é—®é¢˜ï¼Œä¸åŒ…å«èŠ‚ç‚¹ä¿¡æ¯
                pass
            else:
                # æœ‰é€‰æ‹©èŠ‚ç‚¹ï¼Œè·å–èŠ‚ç‚¹æè¿°
                # ç”±äºåœ¨åå°çº¿ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥ä½¿ç”¨contextï¼Œéœ€è¦ä½¿ç”¨å½“å‰ç©ºé—´æ•°æ®
                # åˆ›å»ºä¸€ä¸ªç®€åŒ–ä¸Šä¸‹æ–‡ç”¨äºèŠ‚ç‚¹æè¿°å‡½æ•°
                fake_context = type('FakeContext', (), {
                    'space_data': self.current_space_data,
                    'selected_nodes': selected_nodes,
                    'active_node': self.active_node
                })()

                node_description = get_selected_nodes_description(fake_context)
                filtered_desc = filter_node_description(node_description, ain_settings.filter_level)

            # åˆ›å»ºæ–‡æœ¬å—ä»¥æ˜¾ç¤ºç»“æœ
            text_block_name = "AINodeAnalysisResult"
            if text_block_name in bpy.data.texts:
                text_block = bpy.data.texts[text_block_name]
                text_block.clear()
            else:
                text_block = bpy.data.texts.new(name=text_block_name)

            # ç¡®å®šå½“å‰èŠ‚ç‚¹ç±»å‹
            node_type = "æœªçŸ¥"
            tree_type = self.current_space_data.tree_type
            if tree_type == 'GeometryNodeTree':
                node_type = "å‡ ä½•èŠ‚ç‚¹"
            elif tree_type == 'ShaderNodeTree':
                node_type = "æè´¨èŠ‚ç‚¹"
            elif tree_type == 'CompositorNodeTree':
                node_type = "åˆæˆèŠ‚ç‚¹"
            elif tree_type == 'TextureNodeTree':
                node_type = "çº¹ç†èŠ‚ç‚¹"
            elif tree_type == 'WorldNodeTree':
                node_type = "ç¯å¢ƒèŠ‚ç‚¹"

            text_block.write(f"AIèŠ‚ç‚¹åˆ†æç»“æœ\n")
            text_block.write(f"Blenderç‰ˆæœ¬: {bpy.app.version_string}\n")
            text_block.write(f"èŠ‚ç‚¹ç±»å‹: {node_type}\n")
            text_block.write("="*50 + "\n\n")

            # å¦‚æœæ²¡æœ‰é€‰æ‹©èŠ‚ç‚¹ï¼Œåªå‘é€é—®é¢˜
            if not selected_nodes:
                text_block.write("èŠ‚ç‚¹ç»“æ„: æœªé€‰æ‹©èŠ‚ç‚¹\n")
                filtered_desc = "æœªé€‰æ‹©èŠ‚ç‚¹"
            else:
                text_block.write("èŠ‚ç‚¹ç»“æ„:\n")
                text_block.write(filtered_desc)

            # æ ¹æ®AIæä¾›å•†æ˜¾ç¤ºç›¸å…³ä¿¡æ¯
            text_block.write(f"\n\nAIæœåŠ¡æä¾›å•†: {ain_settings.ai_provider}\n")
            if ain_settings.ai_provider == 'DEEPSEEK':
                text_block.write(f"æ¨¡å‹: {ain_settings.deepseek_model}\n")
            elif ain_settings.ai_provider == 'OLLAMA':
                text_block.write(f"æ¨¡å‹: {ain_settings.ollama_model}\n")
                text_block.write(f"åœ°å€: {ain_settings.ollama_url}\n")

            # ç”Ÿæˆåˆ†æç»“æœ
            analysis_result = self.perform_analysis(filtered_desc, ain_settings)
            if analysis_result:
                text_block.write(f"\n\nåˆ†æç»“æœ:\n")
                text_block.write(analysis_result)
                ain_settings.current_status = "å®Œæˆ"
                self.report({'INFO'}, f"èŠ‚ç‚¹åˆ†æå®Œæˆã€‚è¯·åœ¨'{text_block_name}'æ–‡æœ¬å—ä¸­æŸ¥çœ‹ç»“æœã€‚")
            else:
                text_block.write(f"\n\næ²¡æœ‰åˆ†æç»“æœ (å¯èƒ½APIå¯†é’¥ç¼ºå¤±æˆ–APIæœªå®ç°)\n")
                ain_settings.current_status = "å®Œæˆï¼ˆæ— ç»“æœï¼‰"
                self.report({'WARNING'}, f"èŠ‚ç‚¹ç»“æ„å·²æ˜¾ç¤ºã€‚è¯·åœ¨'{text_block_name}'æ–‡æœ¬å—ä¸­æŸ¥çœ‹ç»“æœã€‚")

        except Exception as e:
            self.report({'ERROR'}, f"AIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            ain_settings.current_status = f"é”™è¯¯: {str(e)}"

# æ–°å¢å¯¹è¯åŠŸèƒ½è¿ç®—ç¬¦
class NODE_OT_ask_ai(AIBaseOperator, Operator):
    bl_idname = "node.ask_ai"
    bl_label = "å‘AIè¯¢é—®èŠ‚ç‚¹é—®é¢˜"
    bl_description = "å…³äºé€‰ä¸­èŠ‚ç‚¹æå‡ºå…·ä½“é—®é¢˜"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        user_question = ain_settings.user_input.strip()

        if not user_question:
            self.report({'WARNING'}, "è¯·è¾“å…¥é—®é¢˜")
            return {'CANCELLED'}

        # æ›´æ–°çŠ¶æ€
        ain_settings.current_status = "æ­£åœ¨å‘AIæé—®..."
        ain_settings.ai_question_status = 'PROCESSING'
        ain_settings.can_terminate_request = True

        # ç›´æ¥åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œè·å–å½“å‰èŠ‚ç‚¹ä¿¡æ¯
        # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if not context.space_data or not hasattr(context.space_data, 'node_tree') or not context.space_data.node_tree:
            self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
            ain_settings.current_status = "é”™è¯¯ï¼šæœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘"
            ain_settings.ai_question_status = 'ERROR'
            ain_settings.can_terminate_request = False
            return {'CANCELLED'}

        # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†èŠ‚ç‚¹
        # å°è¯•å¤šç§æ–¹å¼è·å–é€‰ä¸­çš„èŠ‚ç‚¹
        selected_nodes = []

        # æ–¹æ³•1: æ£€æŸ¥ context.selected_nodes
        if hasattr(context, 'selected_nodes'):
            selected_nodes = list(context.selected_nodes)

        # å¦‚æœæ²¡æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
        if not selected_nodes and hasattr(context, 'active_node') and context.active_node:
            selected_nodes = [context.active_node]

        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»å½“å‰èŠ‚ç‚¹æ ‘è·å–
        if not selected_nodes:
            node_tree = context.space_data.node_tree
            for node in node_tree.nodes:
                if getattr(node, 'select', False):  # ä½¿ç”¨getattrç¡®ä¿å±æ€§å­˜åœ¨
                    selected_nodes.append(node)

        # å…è®¸ä¸é€‰æ‹©èŠ‚ç‚¹ä¹Ÿèƒ½å‘é€é—®é¢˜
        # å¦‚æœæ²¡æœ‰é€‰æ‹©èŠ‚ç‚¹ï¼Œselected_nodes å°†ä¸ºç©ºåˆ—è¡¨

        # åˆ›å»ºé¢„è§ˆå†…å®¹ï¼ˆå®æ—¶åˆ›å»ºæœ€æ–°çš„èŠ‚ç‚¹ä¿¡æ¯ï¼‰
        fake_context = type('FakeContext', (), {
            'space_data': context.space_data,
            'selected_nodes': selected_nodes,
            'active_node': selected_nodes[0] if selected_nodes else None
        })()

        node_description = get_selected_nodes_description(fake_context)
        filtered_desc = filter_node_description(node_description, ain_settings.filter_level)
        instr = get_output_detail_instruction(ain_settings)
        hdr = f"è¯¦ç»†ç¨‹åº¦:\n{instr}\n\n" if instr else ""
        preview_content = f"{hdr}ç³»ç»Ÿæç¤º:\n{ain_settings.system_prompt}\n\né—®é¢˜:\n{user_question}\n\nèŠ‚ç‚¹ç»“æ„:\n{filtered_desc}"
        ain_settings.preview_content = preview_content  # æ›´æ–°é¢„è§ˆå†…å®¹

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼Œä»¥é¿å…é˜»å¡UI
        import threading
        # ä¿å­˜å½“å‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        self.current_space_data = context.space_data
        self.selected_nodes = selected_nodes
        self.active_node = selected_nodes[0] if selected_nodes else None
        self.user_question = user_question
        thread = threading.Thread(target=self.run_ask_analysis)
        thread.start()
        return {'FINISHED'}

    # æ—§ç‰ˆ run_ask_analysis å·²ç§»é™¤ï¼Œä½¿ç”¨ä¸‹æ–¹ç»Ÿä¸€å®ç°

    def run_ask_analysis(self):
        """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒAIé—®ç­”"""
        import bpy
        import requests
        try:
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
            if not self.current_space_data or not hasattr(self.current_space_data, 'node_tree') or not self.current_space_data.node_tree:
                self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
                ain_settings.current_status = "é”™è¯¯ï¼šæœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘"
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}

            # ä½¿ç”¨ä¿å­˜çš„èŠ‚ç‚¹ä¿¡æ¯
            selected_nodes = self.selected_nodes

            # å…è®¸ä¸é€‰æ‹©èŠ‚ç‚¹ä¹Ÿèƒ½å‘é€é—®é¢˜
            if not selected_nodes:
                # æ²¡æœ‰é€‰æ‹©èŠ‚ç‚¹ï¼Œåªå‘é€é—®é¢˜ï¼Œä¸åŒ…å«èŠ‚ç‚¹ä¿¡æ¯
                filtered_desc = "æœªé€‰æ‹©èŠ‚ç‚¹"
            else:
                # æœ‰é€‰æ‹©èŠ‚ç‚¹ï¼Œè·å–èŠ‚ç‚¹æè¿°
                fake_context = type('FakeContext', (), {
                    'space_data': self.current_space_data,
                    'selected_nodes': selected_nodes,
                    'active_node': self.active_node
                })()

                node_description = get_selected_nodes_description(fake_context)
                filtered_desc = filter_node_description(node_description, ain_settings.filter_level)

            # åˆ›å»ºæ–‡æœ¬å—ä»¥æ˜¾ç¤ºç»“æœ
            text_block_name = "AINodeAnalysisResult"
            if text_block_name in bpy.data.texts:
                text_block = bpy.data.texts[text_block_name]
                text_block.clear()
            else:
                text_block = bpy.data.texts.new(name=text_block_name)

            base_url = f"http://127.0.0.1:{server_manager.port}" if (server_manager and server_manager.is_running) else ""
            if not base_url:
                self.report({'ERROR'}, "åç«¯æœªå¯åŠ¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨")
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}
            payload = {
                "question": (get_output_detail_instruction(ain_settings) + "\n\n" + self.user_question).strip(),
                "content": filtered_desc,
                "ai_provider": ain_settings.ai_provider,
                "ai_model": ain_settings.deepseek_model if ain_settings.ai_provider == 'DEEPSEEK' else (ain_settings.ollama_model if ain_settings.ai_provider == 'OLLAMA' else (ain_settings.bigmodel_model if ain_settings.ai_provider == 'BIGMODEL' else ain_settings.generic_model)),
                "ai": {
                    "thinking": {"enabled": bool(getattr(ain_settings, 'enable_thinking', False))},
                    "networking": {"enabled": True},
                    "memory": {"enabled": bool(getattr(ain_settings, 'enable_memory', True)), "target_k": getattr(ain_settings, 'memory_target_k', 4)}
                },
                "nodeContextActive": True
            }
            
            # å¯¹äºBigModelï¼Œå¦‚æœå¯ç”¨æ·±åº¦æ€è€ƒï¼Œåœ¨é—®é¢˜ä¸­æ·»åŠ æ·±åº¦æ€è€ƒæŒ‡ä»¤
            if ain_settings.ai_provider == 'BIGMODEL' and getattr(ain_settings, 'enable_thinking', False):
                thinking_instruction = "\n\nã€æ·±åº¦æ€è€ƒæ¨¡å¼ã€‘è¯·é€æ­¥åˆ†æé—®é¢˜ï¼Œå±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š1. ç†è§£é—®é¢˜ 2. åˆ†æå…³é”®ç‚¹ 3. æ¨ç†è¿‡ç¨‹ 4. å¾—å‡ºç»“è®ºã€‚"
                payload["question"] = thinking_instruction + "\n\n" + payload["question"]
            
            url = base_url + "/api/stream-analyze"
            try:
                with requests.post(url, json=payload, timeout=300, stream=True) as r:
                    if r.status_code != 200:
                        self.report({'ERROR'}, f"åç«¯é”™è¯¯: {r.status_code}")
                        ain_settings.ai_question_status = 'ERROR'
                        ain_settings.can_terminate_request = False
                        return {'CANCELLED'}
                    wrote_thinking_header = False
                    for line in r.iter_lines():
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»ˆæ­¢è¯·æ±‚
                        if ain_settings.ai_question_status == 'STOPPED':
                            self.report({'INFO'}, "è¯·æ±‚å·²è¢«ç”¨æˆ·ç»ˆæ­¢")
                            ain_settings.can_terminate_request = False
                            return {'CANCELLED'}

                        if not line:
                            continue
                        s = line.decode('utf-8')
                        if s.startswith("data: "):
                            if s.strip() == "data: [DONE]":
                                break
                            try:
                                j = json.loads(s[6:])
                                t = j.get('type')
                                c = j.get('content', '')

                                # å†æ¬¡æ£€æŸ¥ç»ˆæ­¢çŠ¶æ€
                                if ain_settings.ai_question_status == 'STOPPED':
                                    self.report({'INFO'}, "è¯·æ±‚å·²è¢«ç”¨æˆ·ç»ˆæ­¢")
                                    ain_settings.can_terminate_request = False
                                    return {'CANCELLED'}

                                if t == 'thinking':
                                    if not wrote_thinking_header:
                                        text_block.write(f"\n\n[æ€è€ƒ]\n")
                                        wrote_thinking_header = True
                                    # ç›´æ¥å†™å…¥å¢é‡ï¼Œä¸é¢å¤–æ¢è¡Œ
                                    text_block.write(c)
                                elif t == 'chunk':
                                    text_block.write(c)
                                elif t == 'error':
                                    self.report({'ERROR'}, c)
                            except Exception:
                                text_block.write(s + "\n")

                    # æ£€æŸ¥æ˜¯å¦æ˜¯å› ç”¨æˆ·ç»ˆæ­¢è€Œç»“æŸ
                    if ain_settings.ai_question_status != 'STOPPED':
                        ain_settings.current_status = "å®Œæˆ"
                        ain_settings.ai_question_status = 'IDLE'

                        # å°†ç»“æœä¿å­˜ä¸ºæ³¨é‡ŠèŠ‚ç‚¹
                        self.create_annotation_node(context, text_block.as_string())

                        self.report({'INFO'}, f"é—®é¢˜å·²å›ç­”ã€‚ç»“æœå·²ä¿å­˜ä¸ºæ³¨é‡ŠèŠ‚ç‚¹ã€‚")

                    ain_settings.can_terminate_request = False
            except Exception as e:
                self.report({'ERROR'}, f"è¯·æ±‚åç«¯æ—¶å‡ºé”™: {str(e)}")
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}

        except Exception as e:
            self.report({'ERROR'}, f"AIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            ain_settings.current_status = f"é”™è¯¯: {str(e)}"
            ain_settings.ai_question_status = 'ERROR'
            ain_settings.can_terminate_request = False

    def perform_analysis(self, node_description, settings):
        """æ‰§è¡ŒAIåˆ†æ"""
        try:
            # æ ¹æ®AIæä¾›å•†è°ƒç”¨ç›¸åº”çš„API
            if settings.ai_provider == 'DEEPSEEK':
                return self.call_deepseek_api(node_description, settings)
            elif settings.ai_provider == 'OLLAMA':
                return self.call_ollama_api(node_description, settings)
            else:
                return None
        except Exception as e:
            print(f"Error in perform_analysis: {str(e)}")
            return None

    def call_deepseek_api(self, node_description, settings):
        """è°ƒç”¨DeepSeek API"""
        if not settings.deepseek_api_key.strip():
            return "DeepSeek API Key is required."

        try:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {settings.deepseek_api_key}'
            }

            system_message = settings.system_prompt

            # Check if input already has structure/question format to avoid duplication
            if "èŠ‚ç‚¹ç»“æ„:" in node_description and "é—®é¢˜:" in node_description:
                 user_message = node_description
            else:
                 user_message = f"Analyze the following Blender node structure and provide insights, optimizations, or explanations:\n\n{node_description}"

            data = {
                "model": settings.deepseek_model,
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }

            import requests
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    return result['choices'][0]['message']['content']
                else:
                    return f"Unexpected API response format: {result}"
            else:
                return f"DeepSeek API error: {response.status_code} - {response.text}"
        except Exception as e:
            return f"Error calling DeepSeek API: {str(e)}"

    def create_annotation_node(self, context, content):
        """åˆ›å»ºæ³¨é‡ŠèŠ‚ç‚¹å¹¶æ·»åŠ å†…å®¹"""
        try:
            # è·å–å½“å‰èŠ‚ç‚¹ç¼–è¾‘å™¨çš„èŠ‚ç‚¹æ ‘
            if not context.space_data or not hasattr(context.space_data, 'node_tree'):
                print("æ— æ³•è·å–èŠ‚ç‚¹æ ‘")
                return

            node_tree = context.space_data.node_tree
            if not node_tree:
                print("èŠ‚ç‚¹æ ‘ä¸ºç©º")
                return

            # åˆ›å»ºæ³¨é‡ŠèŠ‚ç‚¹
            annotation_node = node_tree.nodes.new(type='NodeFrame')
            annotation_node.label = "AIåˆ†æç»“æœ"
            annotation_node.use_custom_color = True
            annotation_node.color = (0.2, 0.6, 1.0)  # è“è‰²ç³»

            # è®¾ç½®èŠ‚ç‚¹ä½ç½®ï¼ˆåœ¨è§†å›¾ä¸­å¿ƒæˆ–ç¨å¾®åç§»ï¼‰
            if context.area and context.region:
                # è·å–å½“å‰é¼ æ ‡ä½ç½®æˆ–è§†å›¾ä¸­å¿ƒä½œä¸ºå‚è€ƒç‚¹
                annotation_node.location = (0, 0)  # é»˜è®¤ä½ç½®ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´

            # å°†AIåˆ†æç»“æœä½œä¸ºæ³¨é‡Šå†…å®¹
            # ç”±äºFrameèŠ‚ç‚¹ä¸èƒ½ç›´æ¥æ˜¾ç¤ºé•¿æ–‡æœ¬ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–‡æœ¬å—æ¥å­˜å‚¨è¯¦ç»†å†…å®¹
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            annotation_content = f"AIåˆ†æç»“æœ - {timestamp}\n\n{content}"

            # åˆ›å»ºæˆ–æ›´æ–°æ–‡æœ¬å—
            text_block_name = "AI_Annotation_Content"
            if text_block_name in bpy.data.texts:
                text_block = bpy.data.texts[text_block_name]
                text_block.clear()
            else:
                text_block = bpy.data.texts.new(name=text_block_name)

            text_block.write(annotation_content)

            # åœ¨æ³¨é‡ŠèŠ‚ç‚¹ä¸Šæ˜¾ç¤ºéƒ¨åˆ†å†…å®¹ä½œä¸ºæ ‡ç­¾
            # é™åˆ¶æ˜¾ç¤ºçš„å­—ç¬¦æ•°ä»¥é€‚åº”èŠ‚ç‚¹å¤§å°
            preview_content = content[:100] + "..." if len(content) > 100 else content
            annotation_node.label = f"AIåˆ†æ: {preview_content}"

        except Exception as e:
            print(f"åˆ›å»ºæ³¨é‡ŠèŠ‚ç‚¹æ—¶å‡ºé”™: {e}")

class AINodeAnalyzer_MT_question_options_all(bpy.types.Menu):
    """AI Node Analyzer é—®é¢˜é€‰é¡¹å­èœå• - å…¨éƒ¨èŠ‚ç‚¹"""
    bl_label = "é—®é¢˜"
    bl_idname = "AINODE_MT_question_options_all"

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # æ˜¾ç¤ºé¢„è®¾é—®é¢˜é€‰é¡¹
        if default_question_presets_cache:
            for idx, preset in enumerate(default_question_presets_cache):
                label = preset.get('label', f'é—®é¢˜ {idx+1}')
                op_preset = layout.operator("node.ask_ai_context", text=label, icon='DOT')
                # ä¼ é€’èŠ‚ç‚¹èŒƒå›´å’Œé—®é¢˜ç±»å‹
                op_preset.node_scope = 'ALL'
                op_preset.question_type = 'PRESET'
                op_preset.question_index = idx

        # æ·»åŠ æ‰‹åŠ¨è¾“å…¥é—®é¢˜é€‰é¡¹
        manual_op = layout.operator("node.ask_ai_context", text="æ‰‹åŠ¨è¾“å…¥é—®é¢˜", icon='TEXT')
        manual_op.node_scope = 'ALL'
        manual_op.question_type = 'MANUAL'

class AINodeAnalyzer_MT_question_options_none(bpy.types.Menu):
    """AI Node Analyzer é—®é¢˜é€‰é¡¹å­èœå• - æ— èŠ‚ç‚¹"""
    bl_label = "é—®é¢˜"
    bl_idname = "AINODE_MT_question_options_none"

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # æ˜¾ç¤ºé¢„è®¾é—®é¢˜é€‰é¡¹
        if default_question_presets_cache:
            for idx, preset in enumerate(default_question_presets_cache):
                label = preset.get('label', f'é—®é¢˜ {idx+1}')
                op_preset = layout.operator("node.ask_ai_context", text=label, icon='DOT')
                # ä¼ é€’èŠ‚ç‚¹èŒƒå›´å’Œé—®é¢˜ç±»å‹
                op_preset.node_scope = 'NONE'
                op_preset.question_type = 'PRESET'
                op_preset.question_index = idx

        # æ·»åŠ æ‰‹åŠ¨è¾“å…¥é—®é¢˜é€‰é¡¹
        manual_op = layout.operator("node.ask_ai_context", text="æ‰‹åŠ¨è¾“å…¥é—®é¢˜", icon='TEXT')
        manual_op.node_scope = 'NONE'
        manual_op.question_type = 'MANUAL'

class AINodeAnalyzer_MT_question_options_selected(bpy.types.Menu):
    """AI Node Analyzer é—®é¢˜é€‰é¡¹å­èœå• - é€‰ä¸­èŠ‚ç‚¹"""
    bl_label = "é—®é¢˜"
    bl_idname = "AINODE_MT_question_options_selected"

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # æ˜¾ç¤ºé¢„è®¾é—®é¢˜é€‰é¡¹
        if default_question_presets_cache:
            for idx, preset in enumerate(default_question_presets_cache):
                label = preset.get('label', f'é—®é¢˜ {idx+1}')
                op_preset = layout.operator("node.ask_ai_context", text=label, icon='DOT')
                # ä¼ é€’èŠ‚ç‚¹èŒƒå›´å’Œé—®é¢˜ç±»å‹
                op_preset.node_scope = 'SELECTED'
                op_preset.question_type = 'PRESET'
                op_preset.question_index = idx

        # æ·»åŠ æ‰‹åŠ¨è¾“å…¥é—®é¢˜é€‰é¡¹
        manual_op = layout.operator("node.ask_ai_context", text="æ‰‹åŠ¨è¾“å…¥é—®é¢˜", icon='TEXT')
        manual_op.node_scope = 'SELECTED'
        manual_op.question_type = 'MANUAL'

# å³é”®èœå•åŠŸèƒ½
class AINodeAnalyzer_MT_context_menu(bpy.types.Menu):
    """AI Node Analyzer å³é”®èœå•"""
    bl_label = "AIèŠ‚ç‚¹åˆ†æå™¨"
    bl_idname = "AINODE_MT_context_menu"

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # å¤åˆ¶èŠ‚ç‚¹ä¿¡æ¯é€‰é¡¹
        copy_row = layout.row(align=True)
        copy_op = copy_row.operator("node.copy_nodes_to_clipboard", text="å¤åˆ¶èŠ‚ç‚¹", icon='COPY_ID')

        layout.separator()

        # æŒ‰ç…§å…¨é€‰èŠ‚ç‚¹æé—®
        all_row = layout.row(align=True)
        all_op = all_row.operator("node.ask_ai_context", text="åˆ†æå…¨éƒ¨èŠ‚ç‚¹", icon='SELECT_EXTEND')
        all_op.node_scope = 'ALL'
        all_op.question_type = 'PRESET_SELECTOR'  # ç‰¹æ®Šç±»å‹ï¼Œè¡¨ç¤ºéœ€è¦æ˜¾ç¤ºå­èœå•
        # æ·»åŠ é—®é¢˜é€‰é¡¹å­èœå•
        all_row.menu("AINODE_MT_question_options_all", text="", icon='TRIA_RIGHT')

        # é€‰æ‹©ä¸ä½¿ç”¨èŠ‚ç‚¹è¿›è¡Œæé—®
        layout.separator()
        none_row = layout.row(align=True)
        none_op = none_row.operator("node.ask_ai_context", text="ä¸ä½¿ç”¨èŠ‚ç‚¹", icon='CANCEL')
        none_op.node_scope = 'NONE'
        none_op.question_type = 'PRESET_SELECTOR'  # ç‰¹æ®Šç±»å‹ï¼Œè¡¨ç¤ºéœ€è¦æ˜¾ç¤ºå­èœå•
        # æ·»åŠ é—®é¢˜é€‰é¡¹å­èœå•
        none_row.menu("AINODE_MT_question_options_none", text="", icon='TRIA_RIGHT')

        # æŒ‰ç…§æ‰€é€‰çš„èŠ‚ç‚¹è¿›è¡Œæé—®
        layout.separator()
        selected_row = layout.row(align=True)
        selected_op = selected_row.operator("node.ask_ai_context", text="åˆ†æé€‰ä¸­èŠ‚ç‚¹", icon='NODE')
        selected_op.node_scope = 'SELECTED'
        selected_op.question_type = 'PRESET_SELECTOR'  # ç‰¹æ®Šç±»å‹ï¼Œè¡¨ç¤ºéœ€è¦æ˜¾ç¤ºå­èœå•
        # æ·»åŠ é—®é¢˜é€‰é¡¹å­èœå•
        selected_row.menu("AINODE_MT_question_options_selected", text="", icon='TRIA_RIGHT')


# å³é”®èœå•æ“ä½œç¬¦
class NODE_OT_ask_ai_context(bpy.types.Operator):
    """å³é”®èœå•AIæé—®æ“ä½œç¬¦"""
    bl_idname = "node.ask_ai_context"
    bl_label = "AIæé—®"
    bl_description = "ä½¿ç”¨AIåˆ†æèŠ‚ç‚¹"
    bl_options = {'REGISTER', 'UNDO'}

    # èŠ‚ç‚¹èŒƒå›´é€‰é¡¹
    node_scope: EnumProperty(
        name="èŠ‚ç‚¹èŒƒå›´",
        description="é€‰æ‹©è¦åˆ†æçš„èŠ‚ç‚¹èŒƒå›´",
        items=[
            ('ALL', "å…¨éƒ¨èŠ‚ç‚¹", "åˆ†æå½“å‰èŠ‚ç‚¹æ ‘ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹"),
            ('NONE', "æ— èŠ‚ç‚¹", "ä¸ä¼ é€’ä»»ä½•èŠ‚ç‚¹ä¿¡æ¯ï¼Œä»…åŸºäºé—®é¢˜è¿›è¡Œå›ç­”"),
            ('SELECTED', "é€‰ä¸­èŠ‚ç‚¹", "ä»…åˆ†æå½“å‰é€‰ä¸­çš„èŠ‚ç‚¹"),
        ],
        default='SELECTED'
    )

    # é—®é¢˜ç±»å‹é€‰é¡¹
    question_type: StringProperty(
        name="é—®é¢˜ç±»å‹",
        description="é—®é¢˜ç±»å‹ï¼ˆæ‰‹åŠ¨è¾“å…¥æˆ–é¢„è®¾ï¼‰",
        default='MANUAL'
    )

    # é¢„è®¾é—®é¢˜ç´¢å¼•
    question_index: IntProperty(
        name="é¢„è®¾é—®é¢˜ç´¢å¼•",
        description="é¢„è®¾é—®é¢˜çš„ç´¢å¼•",
        default=0
    )

    def execute(self, context):
        from bpy.app.translations import pgettext_iface
        ain_settings = context.scene.ainode_analyzer_settings

        # æ£€æŸ¥AIæ˜¯å¦æ­£åœ¨å¤„ç†ä¸­
        if ain_settings.ai_question_status == 'PROCESSING':
            self.report({'WARNING'}, "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨åå†è¯•")
            return {'CANCELLED'}

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šç±»å‹ï¼Œéœ€è¦æ˜¾ç¤ºå­èœå•
        if self.question_type == 'PRESET_SELECTOR':
            # è¿™ç§æƒ…å†µä¸åº”è¯¥ç›´æ¥æ‰§è¡Œï¼Œè€Œæ˜¯åº”è¯¥æ˜¾ç¤ºå­èœå•
            # ä½†åœ¨Blenderä¸­ï¼Œèœå•é¡¹çš„æ‰§è¡Œä¼šè§¦å‘è¿™ä¸ªå‡½æ•°
            # æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ£€æŸ¥æ˜¯å¦æ˜¯è¿™ç§æƒ…å†µ
            # å®é™…ä¸Šï¼Œå½“ç”¨æˆ·ç‚¹å‡»å¸¦ç®­å¤´çš„èœå•é¡¹æ—¶ï¼Œä¼šç›´æ¥æ˜¾ç¤ºå­èœå•
            # è€Œä¸ä¼šæ‰§è¡Œè¿™ä¸ªå‡½æ•°
            # æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦å¤„ç†å®é™…çš„é€‰æ‹©é¡¹
            return {'FINISHED'}

        # è·å–èŠ‚ç‚¹ä¿¡æ¯
        node_tree = None
        selected_nodes = []
        all_nodes = []

        # æ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
        if context.space_data and hasattr(context.space_data, 'node_tree') and context.space_data.node_tree:
            node_tree = context.space_data.node_tree
            all_nodes = list(node_tree.nodes)

            # è·å–é€‰ä¸­çš„èŠ‚ç‚¹
            if hasattr(context, 'selected_nodes'):
                selected_nodes = list(context.selected_nodes)
            else:
                # å¤‡é€‰æ–¹æ¡ˆï¼šéå†æ‰€æœ‰èŠ‚ç‚¹æŸ¥æ‰¾é€‰ä¸­çš„
                for node in all_nodes:
                    if getattr(node, 'select', False):
                        selected_nodes.append(node)

            # å¦‚æœæ²¡æœ‰é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨æ´»åŠ¨èŠ‚ç‚¹
            if not selected_nodes and hasattr(context, 'active_node') and context.active_node:
                selected_nodes = [context.active_node]

        # æ ¹æ®node_scopeç¡®å®šè¦åˆ†æçš„èŠ‚ç‚¹
        nodes_to_analyze = []
        if self.node_scope == 'ALL' and node_tree:
            nodes_to_analyze = all_nodes
        elif self.node_scope == 'SELECTED':
            nodes_to_analyze = selected_nodes
        elif self.node_scope == 'NONE':
            # ä¸ä½¿ç”¨èŠ‚ç‚¹ï¼Œnodes_to_analyzeä¿æŒä¸ºç©º
            pass

        # è·å–é—®é¢˜å†…å®¹
        question = ""
        if self.question_type == 'MANUAL':
            # å¼¹å‡ºå¯¹è¯æ¡†è®©ç”¨æˆ·è¾“å…¥é—®é¢˜
            ain_settings.ai_question_status = 'PROCESSING'
            ain_settings.can_terminate_request = True
            ain_settings.current_status = "ç­‰å¾…ç”¨æˆ·è¾“å…¥é—®é¢˜..."

            # ä¿å­˜å½“å‰ä¸Šä¸‹æ–‡å’ŒèŠ‚ç‚¹ä¿¡æ¯ï¼Œä»¥ä¾¿åœ¨ç¡®è®¤åä½¿ç”¨
            self.temp_context = {
                'node_tree': node_tree,
                'nodes_to_analyze': nodes_to_analyze,
                'context': context
            }

            # å¼¹å‡ºè¾“å…¥å¯¹è¯æ¡†
            bpy.ops.wm.call_panel(name="AINODE_PT_question_input_popup")
            return {'FINISHED'}
        elif self.question_type == 'PRESET':
            # ä»é¢„è®¾ä¸­è·å–é—®é¢˜
            if 0 <= self.question_index < len(default_question_presets_cache):
                preset = default_question_presets_cache[self.question_index]
                question = preset.get('value', '')
            else:
                self.report({'ERROR'}, "é¢„è®¾é—®é¢˜ç´¢å¼•è¶…å‡ºèŒƒå›´")
                return {'CANCELLED'}

        # å¦‚æœæ˜¯é¢„è®¾é—®é¢˜ï¼Œç›´æ¥æ‰§è¡Œåˆ†æ
        if question:
            self.execute_analysis(context, nodes_to_analyze, question)

        return {'FINISHED'}

    def execute_analysis(self, context, nodes_to_analyze, question):
        """æ‰§è¡ŒAIåˆ†æ"""
        from bpy.app.translations import pgettext_iface
        ain_settings = context.scene.ainode_analyzer_settings

        # æ›´æ–°çŠ¶æ€
        ain_settings.ai_question_status = 'PROCESSING'
        ain_settings.can_terminate_request = True
        ain_settings.current_status = "æ­£åœ¨å‘AIæé—®..."

        # å¦‚æœæ²¡æœ‰è¦åˆ†æçš„èŠ‚ç‚¹ï¼Œä½†é€‰æ‹©äº†èŠ‚ç‚¹èŒƒå›´ï¼Œåˆ™æŠ¥å‘Šé”™è¯¯
        if self.node_scope != 'NONE' and not nodes_to_analyze:
            self.report({'ERROR'}, "æ²¡æœ‰æ‰¾åˆ°è¦åˆ†æçš„èŠ‚ç‚¹")
            ain_settings.ai_question_status = 'ERROR'
            ain_settings.can_terminate_request = False
            return

        # åˆ›å»ºèŠ‚ç‚¹æè¿°
        node_description = ""
        if self.node_scope == 'NONE':
            # ä¸ä½¿ç”¨èŠ‚ç‚¹ä¿¡æ¯
            node_description = "æ— èŠ‚ç‚¹ä¿¡æ¯"
        else:
            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ¥è·å–èŠ‚ç‚¹æè¿°
            fake_context = type('FakeContext', (), {
                'space_data': context.space_data,
                'selected_nodes': nodes_to_analyze,
                'active_node': nodes_to_analyze[0] if nodes_to_analyze else None
            })()

            node_description = get_selected_nodes_description(fake_context)
            node_description = filter_node_description(node_description, ain_settings.filter_level)

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼Œä»¥é¿å…é˜»å¡UI
        import threading
        # ä¿å­˜å½“å‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        self.current_space_data = context.space_data
        self.nodes_to_analyze = nodes_to_analyze
        self.active_node = nodes_to_analyze[0] if nodes_to_analyze else None
        self.user_question = question
        self.node_description = node_description
        thread = threading.Thread(target=self.run_ask_analysis)
        thread.start()

    def run_ask_analysis(self):
        """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒAIé—®ç­”"""
        import bpy
        import requests
        try:
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            # é¦–å…ˆæ£€æŸ¥å½“å‰ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ç¼–è¾‘å™¨
            if not self.current_space_data or not hasattr(self.current_space_data, 'node_tree') or not self.current_space_data.node_tree:
                self.report({'ERROR'}, "æœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘")
                ain_settings.current_status = "é”™è¯¯ï¼šæœªæ‰¾åˆ°æ´»åŠ¨çš„èŠ‚ç‚¹æ ‘"
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}

            # ä½¿ç”¨ä¿å­˜çš„èŠ‚ç‚¹ä¿¡æ¯
            nodes_to_analyze = self.nodes_to_analyze

            if self.node_scope != 'NONE' and not nodes_to_analyze:
                self.report({'ERROR'}, "æ²¡æœ‰é€‰æ‹©è¦åˆ†æçš„èŠ‚ç‚¹")
                ain_settings = bpy.context.scene.ainode_analyzer_settings
                ain_settings.current_status = "é”™è¯¯ï¼šæ²¡æœ‰é€‰æ‹©è¦åˆ†æçš„èŠ‚ç‚¹"
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}

            # è·å–èŠ‚ç‚¹æè¿°
            filtered_desc = self.node_description

            text_block_name = "AINodeAnalysisResult"
            if text_block_name in bpy.data.texts:
                text_block = bpy.data.texts[text_block_name]
            else:
                text_block = bpy.data.texts.new(name=text_block_name)
            base_url = f"http://127.0.0.1:{server_manager.port}" if (server_manager and server_manager.is_running) else ""
            if not base_url:
                self.report({'ERROR'}, "åç«¯æœªå¯åŠ¨ï¼Œè¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡å™¨")
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}
            payload = {
                "question": (get_output_detail_instruction(ain_settings) + "\n\n" + self.user_question).strip(),
                "content": filtered_desc,
                "ai_provider": ain_settings.ai_provider,
                "ai_model": ain_settings.deepseek_model if ain_settings.ai_provider == 'DEEPSEEK' else (ain_settings.ollama_model if ain_settings.ai_provider == 'OLLAMA' else (ain_settings.bigmodel_model if ain_settings.ai_provider == 'BIGMODEL' else ain_settings.generic_model)),
                "ai": {
                    "thinking": {"enabled": bool(getattr(ain_settings, 'enable_thinking', False))},
                    "networking": {"enabled": True},
                    "memory": {"enabled": bool(getattr(ain_settings, 'enable_memory', True)), "target_k": getattr(ain_settings, 'memory_target_k', 4)}
                },
                "nodeContextActive": True
            }
            
            # å¯¹äºBigModelï¼Œå¦‚æœå¯ç”¨æ·±åº¦æ€è€ƒï¼Œåœ¨é—®é¢˜ä¸­æ·»åŠ æ·±åº¦æ€è€ƒæŒ‡ä»¤
            if ain_settings.ai_provider == 'BIGMODEL' and getattr(ain_settings, 'enable_thinking', False):
                thinking_instruction = "\n\nã€æ·±åº¦æ€è€ƒæ¨¡å¼ã€‘è¯·é€æ­¥åˆ†æé—®é¢˜ï¼Œå±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š1. ç†è§£é—®é¢˜ 2. åˆ†æå…³é”®ç‚¹ 3. æ¨ç†è¿‡ç¨‹ 4. å¾—å‡ºç»“è®ºã€‚"
                payload["question"] = thinking_instruction + "\n\n" + payload["question"]
            
            url = base_url + "/api/stream-analyze"
            try:
                with requests.post(url, json=payload, timeout=300, stream=True) as r:
                    if r.status_code != 200:
                        self.report({'ERROR'}, f"åç«¯é”™è¯¯: {r.status_code}")
                        ain_settings.ai_question_status = 'ERROR'
                        ain_settings.can_terminate_request = False
                        return {'CANCELLED'}
                    wrote_thinking_header = False
                    for line in r.iter_lines():
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»ˆæ­¢è¯·æ±‚
                        if ain_settings.ai_question_status == 'STOPPED':
                            self.report({'INFO'}, "è¯·æ±‚å·²è¢«ç”¨æˆ·ç»ˆæ­¢")
                            ain_settings.can_terminate_request = False
                            return {'CANCELLED'}

                        if not line:
                            continue
                        s = line.decode('utf-8')
                        if s.startswith("data: "):
                            if s.strip() == "data: [DONE]":
                                break
                            try:
                                j = json.loads(s[6:])
                                t = j.get('type')
                                c = j.get('content', '')

                                # å†æ¬¡æ£€æŸ¥ç»ˆæ­¢çŠ¶æ€
                                if ain_settings.ai_question_status == 'STOPPED':
                                    self.report({'INFO'}, "è¯·æ±‚å·²è¢«ç”¨æˆ·ç»ˆæ­¢")
                                    ain_settings.can_terminate_request = False
                                    return {'CANCELLED'}

                                if t == 'thinking':
                                    if not wrote_thinking_header:
                                        text_block.write(f"\n\n[æ€è€ƒ]\n")
                                        wrote_thinking_header = True
                                    # ç›´æ¥å†™å…¥å¢é‡ï¼Œä¸é¢å¤–æ¢è¡Œ
                                    text_block.write(c)
                                elif t == 'chunk':
                                    text_block.write(c)
                                elif t == 'error':
                                    self.report({'ERROR'}, c)
                            except Exception:
                                text_block.write(s + "\n")

                    # æ£€æŸ¥æ˜¯å¦æ˜¯å› ç”¨æˆ·ç»ˆæ­¢è€Œç»“æŸ
                    if ain_settings.ai_question_status != 'STOPPED':
                        ain_settings.current_status = "å®Œæˆ"
                        ain_settings.ai_question_status = 'IDLE'

                        # å°†ç»“æœä¿å­˜ä¸ºæ³¨é‡ŠèŠ‚ç‚¹
                        self.create_annotation_node(context, text_block.as_string())

                        self.report({'INFO'}, f"é—®é¢˜å·²å›ç­”ã€‚ç»“æœå·²ä¿å­˜ä¸ºæ³¨é‡ŠèŠ‚ç‚¹ã€‚")

                    ain_settings.can_terminate_request = False
            except Exception as e:
                self.report({'ERROR'}, f"è¯·æ±‚åç«¯æ—¶å‡ºé”™: {str(e)}")
                ain_settings.ai_question_status = 'ERROR'
                ain_settings.can_terminate_request = False
                return {'CANCELLED'}

        except Exception as e:
            self.report({'ERROR'}, f"AIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            ain_settings = bpy.context.scene.ainode_analyzer_settings
            ain_settings.current_status = f"é”™è¯¯: {str(e)}"
            ain_settings.ai_question_status = 'ERROR'
            ain_settings.can_terminate_request = False


# é—®é¢˜è¾“å…¥å¼¹çª—é¢æ¿
class AINODE_PT_question_input_popup(bpy.types.Panel):
    """é—®é¢˜è¾“å…¥å¼¹çª—é¢æ¿"""
    bl_label = "è¾“å…¥é—®é¢˜"
    bl_idname = "AINODE_PT_question_input_popup"
    bl_space_type = 'NODE_EDITOR'
    bl_region_type = 'WINDOW'
    bl_options = {'DEFAULT_CLOSED'}

    def draw(self, context):
        layout = self.layout
        scene = context.scene
        ain_settings = scene.ainode_analyzer_settings

        # é—®é¢˜è¾“å…¥æ¡†
        layout.prop(ain_settings, "user_input", text="é—®é¢˜")

        # ç¡®è®¤å’Œå–æ¶ˆæŒ‰é’®
        row = layout.row()
        row.operator("node.confirm_question_input", text="ç¡®è®¤", icon='CHECKMARK')
        row.operator("node.cancel_question_input", text="å–æ¶ˆ", icon='X')


# ç¡®è®¤é—®é¢˜è¾“å…¥æ“ä½œç¬¦
class NODE_OT_confirm_question_input(bpy.types.Operator):
    """ç¡®è®¤é—®é¢˜è¾“å…¥"""
    bl_idname = "node.confirm_question_input"
    bl_label = "ç¡®è®¤é—®é¢˜è¾“å…¥"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        question = ain_settings.user_input.strip()

        if not question:
            self.report({'WARNING'}, "è¯·è¾“å…¥é—®é¢˜")
            return {'CANCELLED'}

        # è¿™é‡Œéœ€è¦è·å–ä¹‹å‰ä¿å­˜çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥æ‰§è¡Œåˆ†æ
        # ç”±äºåœ¨UIçº¿ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®OPERATORå†…éƒ¨çš„ä¸´æ—¶å˜é‡
        # æ‰€ä»¥éœ€è¦é€šè¿‡åœºæ™¯å±æ€§æˆ–å…¶ä»–æ–¹å¼ä¼ é€’ä¿¡æ¯
        self.report({'INFO'}, f"é—®é¢˜å·²ç¡®è®¤: {question}")
        return {'FINISHED'}


# å–æ¶ˆé—®é¢˜è¾“å…¥æ“ä½œç¬¦
class NODE_OT_cancel_question_input(bpy.types.Operator):
    """å–æ¶ˆé—®é¢˜è¾“å…¥"""
    bl_idname = "node.cancel_question_input"
    bl_label = "å–æ¶ˆé—®é¢˜è¾“å…¥"
    bl_options = {'REGISTER', 'UNDO'}

    def execute(self, context):
        ain_settings = context.scene.ainode_analyzer_settings
        ain_settings.ai_question_status = 'IDLE'
        ain_settings.can_terminate_request = False
        ain_settings.current_status = "å°±ç»ª"

        self.report({'INFO'}, "å·²å–æ¶ˆé—®é¢˜è¾“å…¥")
        return {'FINISHED'}


# æ³¨å†Œå‡½æ•°
        """è°ƒç”¨Ollama API"""
        try:
            import requests

            # æ„å»ºOllama API URL
            url = f"{settings.ollama_url}/api/generate"

            system_message = settings.system_prompt
            
            # Check if input already has structure/question format to avoid duplication
            if "èŠ‚ç‚¹ç»“æ„:" in node_description and "é—®é¢˜:" in node_description:
                 prompt = f"System: {system_message}\n\nUser: {node_description}\n\nAssistant:"
            else:
                 prompt = f"System: {system_message}\n\nUser: Analyze the following Blender node structure and provide insights, optimizations, or explanations:\n\n{node_description}\n\nAssistant:"

            data = {
                "model": settings.ollama_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7
                }
            }

            response = requests.post(url, json=data, timeout=60)

            if response.status_code == 200:
                result = response.json()
                if 'response' in result:
                    return result['response']
                else:
                    return f"Unexpected API response format: {result}"
            else:
                return f"Ollama API error: {response.status_code} - {response.text}"
        except Exception as e:
            return f"Error calling Ollama API: {str(e)}"

# æ³¨å†Œå‡½æ•°
def register():
    print("å¼€å§‹æ³¨å†ŒAI Node Analyzeræ’ä»¶...")
    
    # æ³¨å†Œå¿«é€Ÿå¤åˆ¶ç›¸å…³ç±»ï¼ˆå¿…é¡»åœ¨AINodeAnalyzerSettingsä¹‹å‰ï¼‰
    bpy.utils.register_class(SelectedTextPartItem)
    
    # æ³¨å†Œè®¾ç½®å±æ€§
    bpy.utils.register_class(AINodeAnalyzerSettings)
    bpy.types.Scene.ainode_analyzer_settings = PointerProperty(type=AINodeAnalyzerSettings)

    # æ³¨å†Œåå¥½è®¾ç½®
    bpy.utils.register_class(AINodeAnalyzerPreferences)

    # æ³¨å†Œé¢æ¿
    bpy.utils.register_class(NODE_PT_ai_analyzer)

    # æ³¨å†Œè¿ç®—ç¬¦
    bpy.utils.register_class(NODE_OT_analyze_with_ai)
    bpy.utils.register_class(NODE_OT_ask_ai)
    bpy.utils.register_class(AINodeAnalyzerSettingsPopup)
    bpy.utils.register_class(NODE_OT_reset_settings)
    bpy.utils.register_class(NODE_OT_show_full_preview)
    bpy.utils.register_class(NODE_OT_set_default_question)
    bpy.utils.register_class(NODE_OT_clear_question)
    bpy.utils.register_class(NODE_OT_refresh_to_text)
    bpy.utils.register_class(NODE_OT_create_analysis_frame)
    bpy.utils.register_class(NODE_OT_load_config_from_file)
    bpy.utils.register_class(NODE_OT_save_config_to_file)
    # æ³¨å†ŒèŠ‚ç‚¹ä¿¡æ¯å¤åˆ¶åˆ°å‰ªè´´æ¿è¿ç®—ç¬¦
    bpy.utils.register_class(NODE_OT_copy_nodes_to_clipboard)
    # æ³¨å†Œåç«¯æœåŠ¡å™¨ç›¸å…³è¿ç®—ç¬¦
    bpy.utils.register_class(NODE_OT_toggle_backend_server)
    bpy.utils.register_class(NODE_OT_open_backend_webpage)
    bpy.utils.register_class(NODE_OT_test_provider_status)
    bpy.utils.register_class(NODE_OT_test_provider_status_disabled)
    bpy.utils.register_class(NODE_OT_stop_ai_request)
    bpy.utils.register_class(NODE_OT_reset_provider_url)
    bpy.utils.register_class(NODE_OT_refresh_models)
    bpy.utils.register_class(NODE_OT_refresh_models_disabled)
    bpy.utils.register_class(NODE_OT_clean_markdown_text)
    bpy.utils.register_class(NODE_OT_clear_api_key)
    bpy.utils.register_class(NODE_OT_select_model)
    
    # æ³¨å†Œå¿«é€Ÿå¤åˆ¶ç›¸å…³ç±»ï¼ˆé¢æ¿å’Œè¿ç®—ç¬¦ï¼‰
    bpy.utils.register_class(NODE_PT_quick_copy)
    bpy.utils.register_class(NODE_OT_copy_text_part)
    bpy.utils.register_class(NODE_OT_copy_active_text)
    bpy.utils.register_class(NODE_OT_copy_text_to_clipboard)

    # æ³¨å†Œ MCP é¢æ¿ç›¸å…³ç±»
    print("=" * 50)
    print("å¼€å§‹æ³¨å†Œ MCP é¢æ¿...")
    print("=" * 50)
    try:
        # æ³¨å†Œ MCP ç›¸å…³çš„å±æ€§
        bpy.types.Scene.blendermcp_port = bpy.props.IntProperty(
            name="ç«¯å£",
            description="BlenderMCP æœåŠ¡å™¨çš„ç«¯å£",
            default=9876,
            min=1024,
            max=65535
        )

        bpy.types.Scene.blendermcp_server_running = bpy.props.BoolProperty(
            name="æœåŠ¡å™¨è¿è¡Œä¸­",
            default=False
        )

        # æ³¨å†Œ MCP è¿ç®—ç¬¦å’Œé¢æ¿
        print("æ­£åœ¨æ³¨å†Œ MCP ç±»...")
        bpy.utils.register_class(BLENDERMCP_PT_Panel)
        bpy.utils.register_class(BLENDERMCP_OT_StartServer)
        bpy.utils.register_class(BLENDERMCP_OT_StopServer)

        print("MCP é¢æ¿å·²æ³¨å†Œ")
        
        # è‡ªåŠ¨å¯åŠ¨ MCP æœåŠ¡å™¨
        print("æ­£åœ¨å¯åŠ¨ MCP æœåŠ¡å™¨...")
        try:
            print("åˆ›å»º BlenderMCPServer å®ä¾‹...")
            if not hasattr(bpy.types, "blendermcp_server") or not bpy.types.blendermcp_server:
                bpy.types.blendermcp_server = BlenderMCPServer(port=9876)
                print("BlenderMCPServer å®ä¾‹å·²åˆ›å»º")
            
            print("è°ƒç”¨ start() æ–¹æ³•...")
            bpy.types.blendermcp_server.start()
            
            # ä½¿ç”¨å»¶è¿Ÿæ‰§è¡Œæ¥è®¾ç½® scene å±æ€§
            def set_server_running():
                try:
                    if hasattr(bpy.context, 'scene'):
                        bpy.context.scene.blendermcp_server_running = True
                except:
                    pass
                return None
            
            bpy.app.timers.register(set_server_running, first_interval=0.1)
            print("MCP æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£ 9876")
        except Exception as e:
            print(f"MCP æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc()
    except Exception as e:
        print(f"MCP é¢æ¿æ³¨å†Œå¤±è´¥: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
    print("=" * 50)

    # æ³¨å†Œå³é”®èœå•ç›¸å…³ç±»
    bpy.utils.register_class(AINodeAnalyzer_MT_context_menu)
    bpy.utils.register_class(AINodeAnalyzer_MT_question_options_all)
    bpy.utils.register_class(AINodeAnalyzer_MT_question_options_none)
    bpy.utils.register_class(AINodeAnalyzer_MT_question_options_selected)
    bpy.utils.register_class(NODE_OT_ask_ai_context)
    bpy.utils.register_class(AINODE_PT_question_input_popup)
    bpy.utils.register_class(NODE_OT_confirm_question_input)
    bpy.utils.register_class(NODE_OT_cancel_question_input)

    # æ·»åŠ æ¸…ç†å’Œå¤åˆ¶æŒ‰é’®åˆ°æ–‡æœ¬ç¼–è¾‘å™¨å¤´éƒ¨
    bpy.types.TEXT_HT_header.append(text_header_draw)

    print("æ’ä»¶UIç»„ä»¶æ³¨å†Œå®Œæˆï¼Œå¼€å§‹åˆå§‹åŒ–åç«¯æœåŠ¡å™¨...")
    # åˆå§‹åŒ–åç«¯æœåŠ¡å™¨ï¼ˆä½†ä¸è‡ªåŠ¨å¯åŠ¨ï¼‰
    if initialize_backend():
        print("åç«¯æœåŠ¡å™¨åˆå§‹åŒ–æˆåŠŸ")
    else:
        print("åç«¯æœåŠ¡å™¨åˆå§‹åŒ–å¤±è´¥")

    # å¯åŠ¨åˆ·æ–°æ£€æŸ¥å™¨
    start_refresh_checker()
    print("åˆ·æ–°æ£€æŸ¥å™¨å·²å¯åŠ¨")

    # æ·»åŠ å³é”®èœå•åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
    bpy.types.NODE_MT_context_menu.append(draw_ainode_menu)


# å…¨å±€å˜é‡æ¥è·Ÿè¸ªå®šæ—¶å™¨
refresh_checker_timer = None


def draw_ainode_menu(self, context):
    """åœ¨èŠ‚ç‚¹ç¼–è¾‘å™¨å³é”®èœå•ä¸­æ·»åŠ AI Node Analyzeré€‰é¡¹"""
    if context.area.type == 'NODE_EDITOR':
        self.layout.menu(AINodeAnalyzer_MT_context_menu.bl_idname, icon='PLUGIN')


# æ³¨é”€å‡½æ•°

def refresh_checker():
    """å®šæ—¶æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªå‰ç«¯çš„è¯·æ±‚ï¼ˆåŒ…æ‹¬åˆ·æ–°è¯·æ±‚å’Œå†…å®¹æ¨é€ï¼‰"""
    global server_manager
    if server_manager and server_manager.is_running:
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªå‰ç«¯çš„åˆ·æ–°è¯·æ±‚
            response_json = send_to_backend('/api/check-refresh-request', method='GET')
            
            data = {}
            if response_json:
                if 'data' in response_json:
                    data = response_json['data']
                else:
                    data = response_json

            if data and data.get('requested', False):
                # å¦‚æœæœ‰åˆ·æ–°è¯·æ±‚ï¼Œæ‰§è¡ŒBlenderä¸­çš„åˆ·æ–°æ“ä½œ
                print("æ£€æµ‹åˆ°å‰ç«¯åˆ·æ–°è¯·æ±‚ï¼Œæ­£åœ¨æ‰§è¡ŒBlenderåˆ·æ–°æ“ä½œ...")

                # æ‰¾åˆ°åˆé€‚çš„å·¥ä½œåŒºåŸŸæ¥æ‰§è¡Œæ“ä½œ
                # éå†æ‰€æœ‰çª—å£å’ŒåŒºåŸŸæ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
                found_node_editor = False
                for window in bpy.context.window_manager.windows:
                    for area in window.screen.areas:
                        if area.type == 'NODE_EDITOR':
                            # æ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨ï¼Œæ‰§è¡Œåˆ·æ–°æ“ä½œ
                            region = next((r for r in area.regions if r.type == 'WINDOW'), None)
                            if not region and area.regions: region = area.regions[-1]
                            
                            try:
                                # Use temp_override for Blender 3.2+
                                if hasattr(bpy.context, 'temp_override'):
                                    with bpy.context.temp_override(window=window, area=area, region=region, screen=window.screen, scene=bpy.context.scene):
                                        bpy.ops.node.refresh_to_text()
                                else:
                                    # Legacy override
                                    override = {
                                        'window': window,
                                        'screen': window.screen,
                                        'area': area,
                                        'region': region,
                                        'scene': bpy.context.scene,
                                        'workspace': window.workspace
                                    }
                                    bpy.ops.node.refresh_to_text(override)
                                    
                                print("Blenderåˆ·æ–°æ“ä½œæ‰§è¡Œå®Œæˆ")
                                found_node_editor = True
                            except Exception as e:
                                print(f"æ‰§è¡Œåˆ·æ–°æ“ä½œå¤±è´¥: {e}")
                            
                            break
                    if found_node_editor:
                        break
                
                if not found_node_editor:
                    print("æœªæ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨ï¼Œå°è¯•ä½¿ç”¨é€šç”¨ä¸Šä¸‹æ–‡åˆ·æ–°æˆ–æç¤ºç”¨æˆ·")
                    # å³ä½¿æ²¡æœ‰èŠ‚ç‚¹ç¼–è¾‘å™¨ï¼Œæˆ‘ä»¬ä¹Ÿåº”è¯¥å°è¯•æ›´æ–°æ–‡æœ¬å—ï¼Œå‘Šè¯‰å‰ç«¯æ²¡æœ‰é€‰ä¸­èŠ‚ç‚¹
                    try:
                        text_block_name = "AINodeRefreshContent"
                        if text_block_name in bpy.data.texts:
                            text_block = bpy.data.texts[text_block_name]
                            text_block.clear()
                        else:
                            text_block = bpy.data.texts.new(name=text_block_name)
                        
                        text_block.write("No active node editor found.")
                        
                        # æ¨é€æ›´æ–°åˆ°åç«¯
                        push_blender_content_to_server()
                        print("å·²æ¨é€æ— èŠ‚ç‚¹çŠ¶æ€åˆ°åç«¯")
                    except Exception as e:
                        print(f"å¤„ç†æ— èŠ‚ç‚¹ç¼–è¾‘å™¨çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
            # å¤„ç†è®¾ç½®æ›´æ–°
            if data and data.get('updates'):
                updates = data['updates']
                print(f"æ”¶åˆ°è®¾ç½®æ›´æ–°: {updates}")
                
                # Check for reload_config flag
                if updates.get('reload_config'):
                    print("Received reload config request")
                    try:
                        # å°è¯•æ‰¾åˆ°èŠ‚ç‚¹ç¼–è¾‘å™¨
                        found_editor = False
                        for window in bpy.context.window_manager.windows:
                            for area in window.screen.areas:
                                if area.type == 'NODE_EDITOR':
                                    override = {'window': window, 'area': area, 'region': area.regions[-1], 'scene': bpy.context.scene}
                                    bpy.ops.node.load_config_from_file(override)
                                    found_editor = True
                                    break
                            if found_editor: break
                        
                        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ä»»æ„åŒºåŸŸï¼ˆé…ç½®åŠ è½½ä¸åº”ä¾èµ–äºèŠ‚ç‚¹ç¼–è¾‘å™¨ï¼‰
                        if not found_editor and bpy.context.window_manager.windows:
                            window = bpy.context.window_manager.windows[0]
                            if window.screen.areas:
                                area = window.screen.areas[0]
                                override = {'window': window, 'area': area, 'region': area.regions[-1], 'scene': bpy.context.scene}
                                # æ³¨æ„ï¼šå¦‚æœload_config_from_fileå†…éƒ¨æ£€æŸ¥äº†space_dataï¼Œè¿™å¯èƒ½ä¼šå¤±è´¥ã€‚
                                # ä½†é€šå¸¸é…ç½®åŠ è½½åªæ¶‰åŠsceneå±æ€§ã€‚
                                try:
                                    if hasattr(bpy.context, 'temp_override'):
                                        with bpy.context.temp_override(**override):
                                            bpy.ops.node.load_config_from_file()
                                    else:
                                        bpy.ops.node.load_config_from_file(override)
                                    print("å·²é€šè¿‡é€šç”¨ä¸Šä¸‹æ–‡é‡æ–°åŠ è½½é…ç½®")
                                except Exception as e:
                                    print(f"é€šç”¨ä¸Šä¸‹æ–‡åŠ è½½é…ç½®å¤±è´¥: {e}")
                    except Exception as e:
                        print(f"Failed to auto-reload config: {e}")
                
                for scene in bpy.data.scenes:
                    settings = scene.ainode_analyzer_settings
                    if 'system_prompt' in updates:
                        settings.system_prompt = updates['system_prompt']
                    if 'default_question' in updates:
                        settings.default_question = updates['default_question']
                print("è®¾ç½®æ›´æ–°å·²åº”ç”¨")

            # æ£€æŸ¥æ˜¯å¦æœ‰ä»Webæ¨é€çš„å†…å®¹éœ€è¦å¤„ç†
            content_response = send_to_backend('/api/get-web-content', method='GET')
            if content_response and content_response.get('has_content', False):
                content = content_response.get('content', '')
                question = content_response.get('question', '')

                print("æ£€æµ‹åˆ°ä»Webæ¨é€çš„å†…å®¹ï¼Œæ­£åœ¨å¤„ç†...")

                # æ›´æ–°å½“å‰åœºæ™¯çš„AINodeAnalyzerè®¾ç½®
                for scene in bpy.data.scenes:
                    ain_settings = scene.ainode_analyzer_settings
                    if question:
                        ain_settings.user_input = question  # æ›´æ–°é—®é¢˜è¾“å…¥æ¡†
                        print(f"å·²æ›´æ–°é—®é¢˜è¾“å…¥æ¡†ä¸º: {question[:50]}...")

                # å¦‚æœæœ‰å†…å®¹ï¼Œæ›´æ–°AINodeRefreshContentæ–‡æœ¬å—
                # å¦‚æœåŒæ—¶æœ‰èŠ‚ç‚¹å†…å®¹å’Œé—®é¢˜ï¼Œå°†å®ƒä»¬ç»„åˆèµ·æ¥
                combined_content = ""
                if content:
                    combined_content = content
                if question:
                    if combined_content:
                        combined_content += f"\n\nç”¨æˆ·é—®é¢˜:\n{question}"
                    else:
                        combined_content = f"ç”¨æˆ·é—®é¢˜:\n{question}"

                if combined_content:
                    text_block_name = "AINodeRefreshContent"
                    if text_block_name in bpy.data.texts:
                        text_block = bpy.data.texts[text_block_name]
                        text_block.clear()
                        text_block.write(combined_content)
                    else:
                        text_block = bpy.data.texts.new(name=text_block_name)
                        text_block.write(combined_content)
                    print(f"å·²æ›´æ–°AINodeRefreshContentæ–‡æœ¬å—")

                    # åŒæ—¶æ¨é€åˆ°åç«¯æœåŠ¡å™¨ï¼Œç¡®ä¿å‰ç«¯è·å–åˆ°çš„æ˜¯æœ€æ–°å†…å®¹
                    # å°è¯•æ„å»ºä¸Šä¸‹æ–‡
                    ctx = None
                    try:
                        if bpy.context.window_manager.windows:
                            win = bpy.context.window_manager.windows[0]
                            ctx = type('Context', (), {'window_manager': bpy.context.window_manager, 'window': win, 'screen': win.screen, 'scene': bpy.context.scene, 'view_layer': win.view_layer})()
                    except:
                        pass
                    push_blender_content_to_server(ctx)

        except Exception as e:
            print(f"æ£€æŸ¥å‰ç«¯è¯·æ±‚æ—¶å‡ºé”™: {e}")

        try:
            analysis_response = send_to_backend('/api/get-analysis-result', method='GET')
            if analysis_response and analysis_response.get('has_content', False):
                result_text = analysis_response.get('result', '')
                question_text = analysis_response.get('question', '')
                text_block_name = "AINodeAnalysisResult"
                if text_block_name in bpy.data.texts:
                    text_block = bpy.data.texts[text_block_name]
                else:
                    text_block = bpy.data.texts.new(name=text_block_name)
                existing = text_block.as_string()
                if question_text and (question_text in existing):
                    pass
                else:
                    text_block.write(f"\n\n{'='*50}\n")
                    if question_text:
                        text_block.write(f"æé—®: {question_text}\n")
                    text_block.write(f"å›ç­”: {result_text}\n")
                send_to_backend('/api/clear-analysis-result', method='POST')
        except Exception:
            pass

    # æ£€æŸ¥å½“å‰æ´»åŠ¨çš„èŠ‚ç‚¹ç¼–è¾‘å™¨å¹¶è‡ªåŠ¨åˆ‡æ¢èº«ä»½é¢„è®¾
    try:
        for window in bpy.context.window_manager.windows:
            for area in window.screen.areas:
                if area.type == 'NODE_EDITOR':
                    space_data = area.spaces.active
                    if space_data and hasattr(space_data, 'tree_type'):
                        tree_type = space_data.tree_type

                        # ä¸ºå½“å‰åœºæ™¯è®¾ç½®è‡ªåŠ¨èº«ä»½é¢„è®¾
                        current_scene = window.scene
                        ain_settings = current_scene.ainode_analyzer_settings

                        if tree_type and system_message_presets_cache:
                            auto_identity_idx = get_auto_identity_for_node_type(tree_type)
                            if auto_identity_idx is not None:
                                auto_identity_key = f"preset_{auto_identity_idx}"
                                # åªæœ‰å½“å½“å‰é€‰æ‹©ä¸æ˜¯è‡ªåŠ¨åŒ¹é…çš„é¢„è®¾æ—¶æ‰æ›´æ–°
                                if ain_settings.identity_key != auto_identity_key:
                                    ain_settings.identity_key = auto_identity_key
                                    # è§¦å‘æ›´æ–°
                                    ain_settings.identity_text = system_message_presets_cache[auto_identity_idx].get('value', '')
                                    ain_settings.system_prompt = system_message_presets_cache[auto_identity_idx].get('value', '')
                    break
    except Exception as e:
        print(f"è‡ªåŠ¨åˆ‡æ¢èº«ä»½é¢„è®¾æ—¶å‡ºé”™: {e}")

    # ç»§ç»­ä¸‹ä¸€æ¬¡æ£€æŸ¥ - æ¯1ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œä»¥æé«˜å“åº”é€Ÿåº¦
    return 1.0

def start_refresh_checker():
    """å¯åŠ¨åˆ·æ–°æ£€æŸ¥å™¨"""
    global refresh_checker_timer
    if refresh_checker_timer is None:
        # ä½¿ç”¨bpy.app.timersæ¥åˆ›å»ºä¸€ä¸ªå®šæœŸæ‰§è¡Œçš„å‡½æ•°
        refresh_checker_timer = bpy.app.timers.register(refresh_checker, persistent=True)
        print("åˆ·æ–°æ£€æŸ¥å™¨å·²å¯åŠ¨")

def stop_refresh_checker():
    """åœæ­¢åˆ·æ–°æ£€æŸ¥å™¨"""
    global refresh_checker_timer
    if refresh_checker_timer and bpy.app.timers.is_registered(refresh_checker_timer):
        bpy.app.timers.unregister(refresh_checker_timer)
        refresh_checker_timer = None
        print("åˆ·æ–°æ£€æŸ¥å™¨å·²åœæ­¢")

# æ³¨é”€å‡½æ•°
def unregister():
    print("å¼€å§‹æ³¨é”€AI Node Analyzeræ’ä»¶...")
    # åœæ­¢åˆ·æ–°æ£€æŸ¥å™¨
    stop_refresh_checker()
    # åœæ­¢åç«¯æœåŠ¡å™¨
    global server_manager
    if server_manager and server_manager.is_running:
        server_manager.stop_server()
        print("åç«¯æœåŠ¡å™¨å·²åœæ­¢")

    # æ³¨é”€è¿ç®—ç¬¦
    bpy.utils.unregister_class(NODE_OT_create_analysis_frame)
    bpy.utils.unregister_class(NODE_OT_refresh_to_text)
    bpy.utils.unregister_class(NODE_OT_clear_question)
    bpy.utils.unregister_class(NODE_OT_set_default_question)
    bpy.utils.unregister_class(NODE_OT_show_full_preview)
    bpy.utils.unregister_class(NODE_OT_reset_settings)
    bpy.utils.unregister_class(AINodeAnalyzerSettingsPopup)
    bpy.utils.unregister_class(NODE_OT_ask_ai)
    bpy.utils.unregister_class(NODE_OT_analyze_with_ai)
    bpy.utils.unregister_class(NODE_OT_load_config_from_file)
    bpy.utils.unregister_class(NODE_OT_save_config_to_file)
    # æ³¨é”€èŠ‚ç‚¹ä¿¡æ¯å¤åˆ¶åˆ°å‰ªè´´æ¿è¿ç®—ç¬¦
    bpy.utils.unregister_class(NODE_OT_copy_nodes_to_clipboard)
    # æ³¨é”€åç«¯æœåŠ¡å™¨ç›¸å…³è¿ç®—ç¬¦
    bpy.utils.unregister_class(NODE_OT_toggle_backend_server)
    bpy.utils.unregister_class(NODE_OT_open_backend_webpage)
    bpy.utils.unregister_class(NODE_OT_test_provider_status)
    bpy.utils.unregister_class(NODE_OT_test_provider_status_disabled)
    bpy.utils.unregister_class(NODE_OT_stop_ai_request)
    bpy.utils.unregister_class(NODE_OT_reset_provider_url)
    bpy.utils.unregister_class(NODE_OT_refresh_models)
    bpy.utils.unregister_class(NODE_OT_refresh_models_disabled)
    bpy.utils.unregister_class(NODE_OT_clean_markdown_text)
    bpy.utils.unregister_class(NODE_OT_clear_api_key)
    bpy.utils.unregister_class(NODE_OT_select_model)
    
    # æ³¨é”€å¿«é€Ÿå¤åˆ¶ç›¸å…³ç±»ï¼ˆé¢æ¿å’Œè¿ç®—ç¬¦ï¼‰
    bpy.utils.unregister_class(NODE_PT_quick_copy)
    bpy.utils.unregister_class(NODE_OT_copy_text_part)
    bpy.utils.unregister_class(NODE_OT_copy_active_text)
    bpy.utils.unregister_class(NODE_OT_copy_text_to_clipboard)

    # æ³¨é”€ MCP é¢æ¿
    print("å¼€å§‹æ³¨é”€ MCP é¢æ¿...")
    try:
        # åœæ­¢ MCP æœåŠ¡å™¨
        print("æ­£åœ¨åœæ­¢ MCP æœåŠ¡å™¨...")
        try:
            if hasattr(bpy.types, "blendermcp_server") and bpy.types.blendermcp_server:
                bpy.types.blendermcp_server.stop()
                del bpy.types.blendermcp_server
                print("MCP æœåŠ¡å™¨å·²åœæ­¢")
        except Exception as e:
            print(f"åœæ­¢ MCP æœåŠ¡å™¨æ—¶å‡ºé”™: {e}", file=sys.stderr)
        
        bpy.utils.unregister_class(BLENDERMCP_PT_Panel)
        bpy.utils.unregister_class(BLENDERMCP_OT_StartServer)
        bpy.utils.unregister_class(BLENDERMCP_OT_StopServer)

        # åˆ é™¤ MCP å±æ€§
        del bpy.types.Scene.blendermcp_port
        del bpy.types.Scene.blendermcp_server_running

        print("MCP é¢æ¿å·²æ³¨é”€")
    except Exception as e:
        print(f"MCP é¢æ¿æ³¨é”€å¤±è´¥: {e}", file=sys.stderr)

    # æ³¨é”€å³é”®èœå•ç›¸å…³ç±»
    bpy.utils.unregister_class(AINodeAnalyzer_MT_context_menu)
    bpy.utils.unregister_class(AINodeAnalyzer_MT_question_options_all)
    bpy.utils.unregister_class(AINodeAnalyzer_MT_question_options_none)
    bpy.utils.unregister_class(AINodeAnalyzer_MT_question_options_selected)
    bpy.utils.unregister_class(NODE_OT_ask_ai_context)
    bpy.utils.unregister_class(AINODE_PT_question_input_popup)
    bpy.utils.unregister_class(NODE_OT_confirm_question_input)
    bpy.utils.unregister_class(NODE_OT_cancel_question_input)

    # ä»æ–‡æœ¬ç¼–è¾‘å™¨å¤´éƒ¨ç§»é™¤æ¸…ç†å’Œå¤åˆ¶æŒ‰é’®
    bpy.types.TEXT_HT_header.remove(text_header_draw)

    # æ³¨é”€é¢æ¿
    bpy.utils.unregister_class(NODE_PT_ai_analyzer)

    # æ³¨é”€åå¥½è®¾ç½®
    bpy.utils.unregister_class(AINodeAnalyzerPreferences)

    # ä»èŠ‚ç‚¹ç¼–è¾‘å™¨ç§»é™¤å³é”®èœå•
    bpy.types.NODE_MT_context_menu.remove(draw_ainode_menu)

    # åˆ é™¤è®¾ç½®å±æ€§
    del bpy.types.Scene.ainode_analyzer_settings
    bpy.utils.unregister_class(AINodeAnalyzerSettings)
    
    # æ³¨é”€å¿«é€Ÿå¤åˆ¶ç›¸å…³ç±»ï¼ˆPropertyGroupå¿…é¡»åœ¨æœ€åæ³¨é”€ï¼‰
    bpy.utils.unregister_class(SelectedTextPartItem)
    
    print("æ’ä»¶å·²æ³¨é”€å®Œæˆ")


if __name__ == "__main__":
    register()
